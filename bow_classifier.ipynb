{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag-of-words document classification\n",
    "\n",
    "* BoW is the simplest way to do classification: Feature vector goes in, decision falls out.\n",
    "\n",
    "* Feature vector: a vector with as many dimensions as we have unique features, and a non-zero value set for every feature present in our example\n",
    "* Binary features: 1/0\n",
    "\n",
    "In the following we work with the IMDB data, have a look on [how to read it in](read_imdb.ipynb). Here we just read the ready data in.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"This movie doesn't even deserve a one. This was an utter waste of time. It was a waste of film and money. It was not offensive but everything was provocative and disgusting. My spoiler is one that I think should be read by everyone. There is full frontal nudity and disgusting language. But not only that, there is NO plot line, the actors are terrible, the accents are horrible, the actors are small time and I was even EXCITED to watch this movie!   The only reason I rented it was for Brian van Holt (who got only a fifteen second part, by the way). I think this might have been a mistake on the directors and editors parts but they repeated the same segments two or three times, adding only a new sentence.  A film similar to this is Eraser Head, possibly the most disturbing movie in existence. There is no plot line, and is not funny. Although it isn't trying to be funny. DO NOT WATCH EITHER MOVIE.\", 'class': 'neg'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "with open(\"data/imdb_train.json\") as f:\n",
    "    data=json.load(f)\n",
    "random.shuffle(data) #play it safe!\n",
    "print(data[0]) #Every item is a dictionary with `text` and `class` keys, here's the first one:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn on this data, we will need a few steps:\n",
    "\n",
    "* Build a data matrix with dimensionality (number of examples, number of possible features), and a value for each feature, 0/1 for binary features\n",
    "* Build a class label matrix (number of examples, number of classes) with the correct labels for the examples, setting 1 for the correct class, and 0 for others\n",
    "\n",
    "It is quite useless to do all this ourselves, so we will use ready-made classes and functions mostly from scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"This movie doesn't even deserve a one. This was an utter waste of time. It was a waste of film and money. It was not offensive but everything was provocative and disgusting. My spoiler is one that I think should be read by everyone. There is full frontal nudity and disgusting language. But not only that, there is NO plot line, the actors are terrible, the accents are horrible, the actors are small time and I was even EXCITED to watch this movie!   The only reason I rented it was for Brian van Holt (who got only a fifteen second part, by the way). I think this might have been a mistake on the directors and editors parts but they repeated the same segments two or three times, adding only a new sentence.  A film similar to this is Eraser Head, possibly the most disturbing movie in existence. There is no plot line, and is not funny. Although it isn't trying to be funny. DO NOT WATCH EITHER MOVIE.\", \"I don't have words to describe how good this movie is. Only a genius like Amrita Pritam could have written such a real depiction of the days of partition. The movie kept haunting me for many days.  Urmila did the role of her life in this movie. She put life in the role of Puroo and Manoj Vajpai did no less in his role as Rashid. It is hard to imagine anyone other than these two doing the role of Puroo and Rashid. The Punjabi costumes looked so natural on Urmila and Manoj looked like a natural Punjabi Mussalmaan.  Sandhali Sinha as Lajjo and Suri as Ramchand did fabulous job. Priyanshu Chattarjee did good work as Triloki.  Some of the scenes you just can't get out of your mind. When Puroo meets Lajjo for the first time, it brings tears to your eyes. The climax is just killer. I was expecting a tragic ending but thankfully, the ending was wonderful.  This movie is in the same category as Pakeezah, Mughal-e-Azam, Banaras etc. Not to be missed.\"]\n",
      "['neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "# We need to gather the texts, into a list\n",
    "texts=[one_example[\"text\"] for one_example in data]\n",
    "labels=[one_example[\"class\"] for one_example in data]\n",
    "print(texts[:2])\n",
    "print(labels[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape= (25000, 100000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer=CountVectorizer(max_features=100000,binary=True,ngram_range=(1,2))\n",
    "feature_matrix=vectorizer.fit_transform(texts)\n",
    "print(\"shape=\",feature_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the feature matrix done! Next thing we need is the class labels to be predicted in one-hot encoding. This means:\n",
    "\n",
    "* one row for every example\n",
    "* one column for every possible class label\n",
    "* exactly one column has 1 for every example, corresponding to the desired class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_numbers shape= (25000,)\n",
      "class labels ['neg' 'pos']\n",
      "classes_1hot [[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "label_encoder=LabelEncoder() #Turns class labels into integers\n",
    "one_hot_encoder=OneHotEncoder(sparse=False) #Turns class integers into one-hot encoding\n",
    "class_numbers=label_encoder.fit_transform(labels)\n",
    "print(\"class_numbers shape=\",class_numbers.shape)\n",
    "print(\"class labels\",label_encoder.classes_) #this will let us translate back from indices to labels\n",
    "#And now yet the one-hot encoding\n",
    "classes_1hot=one_hot_encoder.fit_transform(class_numbers.reshape(-1,1)) #running without reshape tells you to reshape\n",
    "print(\"classes_1hot\",classes_1hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The data is ready, we need to build the network now\n",
    "* Input\n",
    "* Hidden Dense layer with some kind of non-linearity, and a suitable number of nodes\n",
    "* Output Dense layer with the softmax activation (normalizes output to distribution) and as many nodes as there are classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ginter/venv-jupyter/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "example_count,feature_count=feature_matrix.shape\n",
    "example_count2,class_count=classes_1hot.shape\n",
    "assert example_count==example_count2 #sanity check\n",
    "\n",
    "inp=Input(shape=(feature_count,))\n",
    "hidden=Dense(200,activation=\"tanh\")(inp)\n",
    "outp=Dense(class_count,activation=\"softmax\")(hidden)\n",
    "model=Model(inputs=[inp], outputs=[outp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...it's **this** simple...!\n",
    "\n",
    "Once the model is constructed it needs to be compiled, for that we need to know:\n",
    "* which optimizer we want to use (sgd is fine to begin with)\n",
    "* what is the loss (categorial_crossentropy for multiclass of the kind we have is the right choice)\n",
    "* which metrics to measure, accuracy is an okay choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"sgd\",loss=\"categorical_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A compiled model can be fitted on data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n",
      "22500/22500 [==============================] - 19s 866us/step - loss: 0.5197 - acc: 0.7956 - val_loss: 0.4354 - val_acc: 0.8404\n",
      "Epoch 2/10\n",
      "22500/22500 [==============================] - 18s 805us/step - loss: 0.3767 - acc: 0.8648 - val_loss: 0.3664 - val_acc: 0.8616\n",
      "Epoch 3/10\n",
      "22500/22500 [==============================] - 19s 840us/step - loss: 0.3185 - acc: 0.8849 - val_loss: 0.3338 - val_acc: 0.8712\n",
      "Epoch 4/10\n",
      "22500/22500 [==============================] - 18s 807us/step - loss: 0.2819 - acc: 0.8976 - val_loss: 0.3145 - val_acc: 0.8764\n",
      "Epoch 5/10\n",
      "22500/22500 [==============================] - 18s 797us/step - loss: 0.2542 - acc: 0.9106 - val_loss: 0.3007 - val_acc: 0.8812\n",
      "Epoch 6/10\n",
      "22500/22500 [==============================] - 18s 786us/step - loss: 0.2317 - acc: 0.9206 - val_loss: 0.2915 - val_acc: 0.8832\n",
      "Epoch 7/10\n",
      "22500/22500 [==============================] - 18s 785us/step - loss: 0.2128 - acc: 0.9284 - val_loss: 0.2844 - val_acc: 0.8884\n",
      "Epoch 8/10\n",
      "22500/22500 [==============================] - 17s 769us/step - loss: 0.1964 - acc: 0.9357 - val_loss: 0.2798 - val_acc: 0.8868\n",
      "Epoch 9/10\n",
      "22500/22500 [==============================] - 18s 798us/step - loss: 0.1814 - acc: 0.9437 - val_loss: 0.2762 - val_acc: 0.8868\n",
      "Epoch 10/10\n",
      "22500/22500 [==============================] - 18s 795us/step - loss: 0.1682 - acc: 0.9492 - val_loss: 0.2726 - val_acc: 0.8876\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(feature_matrix,classes_1hot,batch_size=100,verbose=1,epochs=10,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8403999996185303, 0.8616000008583069, 0.8711999988555909, 0.8764000010490417, 0.8812000012397766, 0.883199999332428, 0.8884000039100647, 0.8868000030517578, 0.8868000030517578, 0.8876000022888184]\n"
     ]
    }
   ],
   "source": [
    "print(hist.history[\"val_acc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We ran for 10 epochs of training\n",
    "* Made it to 88.7% accuracy on the validation and 94.9% accuracy on the training data\n",
    "\n",
    "* But we do not have the model saved, so let's fix that and get the whole thing done\n",
    "* What constitutes a model (ie what we need to run the model on new data)\n",
    "  - The feature dictionary in the vectorizer\n",
    "  - The list of classes in their correct order\n",
    "  - The structure of the network\n",
    "  - The weights the network learned\n",
    "\n",
    "* Do all these things, and run again. This time we also increase the number of epochs to 30, see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22500 samples, validate on 2500 samples\n",
      "Epoch 1/30\n",
      "22500/22500 [==============================] - 21s 934us/step - loss: 0.5398 - acc: 0.7895 - val_loss: 0.4551 - val_acc: 0.8412\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.45507, saving model to models/imdb_bow.weights.h5\n",
      "Epoch 2/30\n",
      "22500/22500 [==============================] - 16s 705us/step - loss: 0.3961 - acc: 0.8579 - val_loss: 0.3810 - val_acc: 0.8588\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.45507 to 0.38103, saving model to models/imdb_bow.weights.h5\n",
      "Epoch 3/30\n",
      "22500/22500 [==============================] - 25s 1ms/step - loss: 0.3332 - acc: 0.8783 - val_loss: 0.3440 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.38103 to 0.34400, saving model to models/imdb_bow.weights.h5\n",
      "Epoch 4/30\n",
      "22500/22500 [==============================] - 19s 833us/step - loss: 0.2941 - acc: 0.8919 - val_loss: 0.3221 - val_acc: 0.8740\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.34400 to 0.32214, saving model to models/imdb_bow.weights.h5\n",
      "Epoch 5/30\n",
      "22500/22500 [==============================] - 22s 986us/step - loss: 0.2649 - acc: 0.9035 - val_loss: 0.3070 - val_acc: 0.8776\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.32214 to 0.30702, saving model to models/imdb_bow.weights.h5\n",
      "Epoch 6/30\n",
      "22500/22500 [==============================] - 16s 724us/step - loss: 0.2418 - acc: 0.9134 - val_loss: 0.2965 - val_acc: 0.8816\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.30702 to 0.29654, saving model to models/imdb_bow.weights.h5\n",
      "Epoch 7/30\n",
      "22500/22500 [==============================] - 20s 867us/step - loss: 0.2218 - acc: 0.9228 - val_loss: 0.2895 - val_acc: 0.8856\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.29654 to 0.28953, saving model to models/imdb_bow.weights.h5\n",
      "Epoch 8/30\n",
      "22500/22500 [==============================] - 18s 780us/step - loss: 0.2047 - acc: 0.9306 - val_loss: 0.2866 - val_acc: 0.8856\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.28953 to 0.28661, saving model to models/imdb_bow.weights.h5\n",
      "Epoch 9/30\n",
      "22500/22500 [==============================] - 17s 741us/step - loss: 0.1896 - acc: 0.9379 - val_loss: 0.2790 - val_acc: 0.8904\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.28661 to 0.27901, saving model to models/imdb_bow.weights.h5\n",
      "Epoch 10/30\n",
      "22500/22500 [==============================] - 23s 1ms/step - loss: 0.1758 - acc: 0.9451 - val_loss: 0.2804 - val_acc: 0.8908\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/30\n",
      "22500/22500 [==============================] - 17s 734us/step - loss: 0.1634 - acc: 0.9509 - val_loss: 0.2751 - val_acc: 0.8900\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.27901 to 0.27506, saving model to models/imdb_bow.weights.h5\n",
      "Epoch 12/30\n",
      "22500/22500 [==============================] - 18s 787us/step - loss: 0.1522 - acc: 0.9563 - val_loss: 0.2740 - val_acc: 0.8924\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.27506 to 0.27401, saving model to models/imdb_bow.weights.h5\n",
      "Epoch 13/30\n",
      "22500/22500 [==============================] - 16s 720us/step - loss: 0.1419 - acc: 0.9607 - val_loss: 0.2715 - val_acc: 0.8940\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.27401 to 0.27151, saving model to models/imdb_bow.weights.h5\n",
      "Epoch 14/30\n",
      "22500/22500 [==============================] - 18s 804us/step - loss: 0.1324 - acc: 0.9648 - val_loss: 0.2705 - val_acc: 0.8936\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.27151 to 0.27054, saving model to models/imdb_bow.weights.h5\n",
      "Epoch 15/30\n",
      "22500/22500 [==============================] - 16s 733us/step - loss: 0.1238 - acc: 0.9684 - val_loss: 0.2704 - val_acc: 0.8940\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.27054 to 0.27044, saving model to models/imdb_bow.weights.h5\n",
      "Epoch 16/30\n",
      "22500/22500 [==============================] - 18s 783us/step - loss: 0.1159 - acc: 0.9720 - val_loss: 0.2716 - val_acc: 0.8924\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/30\n",
      "22500/22500 [==============================] - 17s 777us/step - loss: 0.1083 - acc: 0.9753 - val_loss: 0.2707 - val_acc: 0.8940\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/30\n",
      "22500/22500 [==============================] - 20s 898us/step - loss: 0.1016 - acc: 0.9784 - val_loss: 0.2710 - val_acc: 0.8940\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/30\n",
      "22500/22500 [==============================] - 18s 787us/step - loss: 0.0951 - acc: 0.9808 - val_loss: 0.2750 - val_acc: 0.8924\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/30\n",
      "22500/22500 [==============================] - 18s 797us/step - loss: 0.0895 - acc: 0.9827 - val_loss: 0.2745 - val_acc: 0.8940\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/30\n",
      "22500/22500 [==============================] - 18s 797us/step - loss: 0.0840 - acc: 0.9857 - val_loss: 0.2744 - val_acc: 0.8944\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/30\n",
      "22500/22500 [==============================] - 16s 727us/step - loss: 0.0791 - acc: 0.9871 - val_loss: 0.2757 - val_acc: 0.8936\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/30\n",
      "22500/22500 [==============================] - 17s 765us/step - loss: 0.0745 - acc: 0.9890 - val_loss: 0.2806 - val_acc: 0.8928\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/30\n",
      "22500/22500 [==============================] - 20s 889us/step - loss: 0.0701 - acc: 0.9903 - val_loss: 0.2787 - val_acc: 0.8932\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/30\n",
      "22500/22500 [==============================] - 21s 954us/step - loss: 0.0662 - acc: 0.9916 - val_loss: 0.2812 - val_acc: 0.8944\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 26/30\n",
      "22500/22500 [==============================] - 16s 723us/step - loss: 0.0625 - acc: 0.9925 - val_loss: 0.2830 - val_acc: 0.8952\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 27/30\n",
      "22500/22500 [==============================] - 17s 750us/step - loss: 0.0592 - acc: 0.9935 - val_loss: 0.2841 - val_acc: 0.8940\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 28/30\n",
      "22500/22500 [==============================] - 18s 783us/step - loss: 0.0560 - acc: 0.9939 - val_loss: 0.2870 - val_acc: 0.8928\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/30\n",
      "22500/22500 [==============================] - 16s 712us/step - loss: 0.0531 - acc: 0.9949 - val_loss: 0.2881 - val_acc: 0.8960\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 30/30\n",
      "22500/22500 [==============================] - 19s 866us/step - loss: 0.0503 - acc: 0.9954 - val_loss: 0.2911 - val_acc: 0.8924\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "def save_model(file_name,model,label_encoder,vectorizer):\n",
    "    \"\"\"Saves model structure and vocabularies\"\"\"\n",
    "    model_json = model.to_json()\n",
    "    with open(file_name+\".model.json\", \"w\") as f:\n",
    "        print(model_json,file=f)\n",
    "    with open(file_name+\".vocabularies.json\",\"w\") as f:\n",
    "        classes=list(label_encoder.classes_)\n",
    "        vocab=dict(((str(w),int(idx)) for w,idx in vectorizer.vocabulary_.items())) #must turn numpy objects to python ones\n",
    "        json.dump((classes,vocab),f,indent=2)\n",
    "        \n",
    "example_count,feature_count=feature_matrix.shape\n",
    "example_count2,class_count=classes_1hot.shape\n",
    "assert example_count==example_count2 #sanity check\n",
    "\n",
    "inp=Input(shape=(feature_count,))\n",
    "hidden=Dense(200,activation=\"tanh\")(inp)\n",
    "outp=Dense(class_count,activation=\"softmax\")(hidden)\n",
    "model=Model(inputs=[inp], outputs=[outp])\n",
    "model.compile(optimizer=\"sgd\",loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "\n",
    "# Save model and vocabularies, can be done before training\n",
    "save_model(\"models/imdb_bow\",model,label_encoder,vectorizer)\n",
    "# Callback function to save weights during training, if validation loss goes down\n",
    "save_cb=ModelCheckpoint(filepath=\"models/imdb_bow.weights.h5\", monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "hist=model.fit(feature_matrix,classes_1hot,batch_size=100,verbose=1,epochs=30,validation_split=0.1,callbacks=[save_cb])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "* We put together a program to train a neural network classifier for sentiment detector\n",
    "* We learned the necessary code/techniques to save models, and feed the training with data in just the right format\n",
    "* We observed the training across epochs\n",
    "* We saw how the classifier can be applied to various text classification problems\n",
    "* The IMDB sentiment classifier ended up at nearly 90% accuracy, the state of the art is about 95%, we got surprisingly far in few lines of code\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-jupyter",
   "language": "python",
   "name": "venv-jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
