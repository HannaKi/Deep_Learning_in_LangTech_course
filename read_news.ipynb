{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Reuters XML news data\n",
    "\n",
    "This code must be run in Python 3. It reads a Reuters news data set, which consists of a set of files containing articles and topic labels. The data can be used to train and test a classifier that categorizes articles by topic.\n",
    "\n",
    "The code extracts the article text and topic (for simplicity, excluding articles with no or multiple topics) and outputs a list of dictionaries in JSON format.\n",
    "\n",
    "The XML-formated data originates from: https://archive.ics.uci.edu/ml/datasets/reuters-21578+text+categorization+collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as et\n",
    "import re\n",
    "import os\n",
    "\n",
    "def get_text(element):\n",
    "    \"\"\" Get text within tag and within nested tags \"\"\"\n",
    "    return ((element.text or '') + ''.join(map(get_text, element)) + (element.tail or ''))\n",
    "\n",
    "def read_news(filename):\n",
    "    \"\"\" Extract news article texts and topic labels from Reuters XML file \"\"\"\n",
    "    f = open(filename, encoding=\"latin-1\")\n",
    "    output = []\n",
    "    while True: # Loop through file\n",
    "        buffer = \"\"\n",
    "        while True: # Loop through article, fill buffer\n",
    "            line = f.readline()\n",
    "            buffer += line\n",
    "            if \"</REUTERS>\" in line:\n",
    "                break\n",
    "            if not line: # End of file\n",
    "                return output\n",
    "        buffer = buffer.replace(\"&\", \"&amp;\") # Fix XML\n",
    "        root = et.fromstring(buffer) # Parse XML\n",
    "        topic_tag = root.find('TOPICS')\n",
    "        if len(topic_tag) != 1: # Extract only articles with exactly one topic label, for simplicity\n",
    "            continue\n",
    "        topic = get_text(topic_tag).strip()\n",
    "        text = re.sub(\"\\n\\s+\", \"\\n\", get_text(root.find('TEXT')).strip())\n",
    "        output.append({'class': topic, 'text': text}) # Save as JSON entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading reut2-005.sgm\n",
      "Reading reut2-016.sgm\n",
      "Reading reut2-007.sgm\n",
      "Reading reut2-003.sgm\n",
      "Reading reut2-020.sgm\n",
      "Reading reut2-019.sgm\n",
      "Reading reut2-001.sgm\n",
      "Reading reut2-021.sgm\n",
      "Reading reut2-013.sgm\n",
      "Reading reut2-004.sgm\n",
      "Reading reut2-011.sgm\n",
      "Reading reut2-008.sgm\n",
      "Reading reut2-018.sgm\n",
      "Reading reut2-012.sgm\n",
      "Reading reut2-000.sgm\n",
      "Reading reut2-014.sgm\n",
      "Reading reut2-002.sgm\n",
      "Reading reut2-009.sgm\n",
      "Reading reut2-015.sgm\n",
      "Reading reut2-017.sgm\n",
      "Reading reut2-006.sgm\n",
      "Reading reut2-010.sgm\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "path = \"data/reuters\"\n",
    "# Read all XML (sgm) files in directory\n",
    "for filename in os.listdir(path):\n",
    "    if '.sgm' in filename:\n",
    "        print(\"Reading\", filename)\n",
    "        data += read_news(os.path.join(path,filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is some code for inspecting and cleaning the data further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9494"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of articles\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of classes\n",
    "len(set([x['class'] for x in data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3945 earn\n",
      "2362 acq\n",
      "408 crude\n",
      "361 trade\n",
      "307 money-fx\n",
      "285 interest\n",
      "161 money-supply\n",
      "158 ship\n",
      "143 sugar\n",
      "116 coffee\n",
      "99 gold\n",
      "83 gnp\n",
      "79 cpi\n",
      "63 cocoa\n",
      "55 jobs\n",
      "54 copper\n",
      "53 reserves\n",
      "51 grain\n",
      "50 alum\n",
      "49 ipi\n",
      "47 iron-steel\n",
      "45 nat-gas\n",
      "41 rubber\n",
      "37 veg-oil\n",
      "32 bop\n",
      "30 tin\n",
      "26 cotton\n",
      "26 wpi\n",
      "22 retail\n",
      "22 orange\n",
      "22 gas\n",
      "21 pet-chem\n",
      "20 livestock\n",
      "19 strategic-metal\n",
      "18 housing\n",
      "16 zinc\n",
      "14 lei\n",
      "14 heat\n",
      "12 income\n",
      "12 lumber\n",
      "11 fuel\n",
      "11 carcass\n",
      "11 silver\n",
      "9 oilseed\n",
      "8 lead\n",
      "7 instal-debt\n",
      "7 meal-feed\n",
      "6 tea\n",
      "6 dlr\n",
      "6 yen\n",
      "5 potato\n",
      "4 nickel\n",
      "4 cpu\n",
      "4 jet\n",
      "3 inventories\n",
      "3 platinum\n",
      "2 groundnut\n",
      "1 l-cattle\n",
      "1 wool\n",
      "1 hog\n",
      "1 rand\n",
      "1 rice\n",
      "1 stg\n",
      "1 propane\n",
      "1 naphtha\n",
      "1 coconut\n"
     ]
    }
   ],
   "source": [
    "# Check number of articles per class\n",
    "import collections\n",
    "counter = collections.defaultdict(lambda: 0)\n",
    "for datum in data:\n",
    "    counter[datum['class']] += 1\n",
    "for topic, count in sorted(counter.items(), key=lambda x:x[1], reverse=True):\n",
    "    print(count, topic)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out classes with less than 5 occurrences\n",
    "data = [d for d in data if counter[d['class']] >= 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9465"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check length\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of classes\n",
    "len(set([x['class'] for x in data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"data/reuters_51cls.json\",\"w\") as f:\n",
    "    json.dump(data,f,indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
