{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project word embeddings\n",
    "\n",
    "The project will have you train and thoroughly test word embeddings.\n",
    "\n",
    "## Milestone 1 -- word2vec\n",
    "\n",
    "Train `word2vec` and vary the training parameters, especially the corpus, the window size, and the word2vec architecture (skip-gram vs. BoW). Inspect the embeddings manually using the nearest neighbor, and write up your observations. How do these models differ? For models trained on two different datasets, or with two different architectures, what is the proportion of nearest neighbors which remain unchanged? Can you see any more general trends here? Write a report on your findings. Choose any language you want for your tests.\n",
    "\n",
    "## Milestone 2 -- formal evaluation\n",
    "\n",
    "There are many formal ways to evaluate the embeddings. Test all your models on several of these, and rank them. Do you see any general trends here? Add these findings to your report. Evaluation datasets:\n",
    "\n",
    "* http://wordvectors.org -- web based evaluation of English similarity\n",
    "* https://github.com/spyysalo/wvlib -- several English datasets and evaluation scripts\n",
    "* analogy_fin and analogy_en in the data directory of the course\n",
    "\n",
    "## Milestone 3\n",
    "\n",
    "TODO :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-jupyter",
   "language": "python",
   "name": "venv-jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
