{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Copy of seq2seq_applications.ipynb","provenance":[{"file_id":"12wSuXMI4kdB85Ei6GrEKnw9gSP3ZwUsV","timestamp":1587464362097},{"file_id":"https://github.com/TurkuNLP/Deep_Learning_in_LangTech_course/blob/master/seq2seq_applications.ipynb","timestamp":1587453704124}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"84yBvO-M1XdJ","colab_type":"text"},"source":["# Sequence-to-Sequence Applications\n","\n","## Seq2seq recap:\n","- Sequence of words or tokens in, sequence of predictions out\n","    - MT: Sequence of English words in, sequence of Finnish words out\n","    - Compare to:\n","        - Sequence classification: Sequence of items in, one prediction out\n","        - Sequence Tagging/Labeling: Sequence of items in, one prediction per item out\n","    \n","- Seq2seq: Input and output do not need to be same length\n","  - e.g. for labeling there is only one output label!\n","- **Neural Attention**\n","    - Instead of a fixed-length vector representing encoded input, decoder has access to any part of the encoder state\n","    - Separate context vector (ci) (attention over all the input when doing a particular prediction)computed for each decoder state\n","    - Decoder steps can “pay attention” to different parts of the input\n","\n","## Today's content (part 1):\n","- How to train complicated seq2seq models with very little coding effort\n","- Lemmatization as a seq2seq task\n","- Other seq2seq applications\n","\n","## MT Frameworks/Libraries\n","- MT is one of the most widely studied seq2seq problems\n","- Many ready-made and well maintained libraries exist for Neural MT, e.g.\n","    - OpenNMT\n","    - MarianNMT\n","- Developed mainly for NMT, however, these do not have any MT specific hard-coded --> can be used to any seq2seq\n","\n","## Why use ready-made libraries?\n","- Everything already implemented (different attention models, different encoder/decoder architectures)\n","- Top notch results/models very difficult to replicate (true even when code is open-source)"]},{"cell_type":"markdown","metadata":{"id":"cbXKuNv9hVHV","colab_type":"text"},"source":["## Date Normalization with OpenNMT\n","\n","### Download and read the dataset"]},{"cell_type":"code","metadata":{"id":"rpGyQtBl6PGI","colab_type":"code","outputId":"d15ea262-8cec-4b87-b532-758378541121","colab":{"base_uri":"https://localhost:8080/","height":744},"executionInfo":{"status":"ok","timestamp":1587454552737,"user_tz":-180,"elapsed":5681,"user":{"displayName":"Hanna Kitti","photoUrl":"","userId":"01511785927733709431"}}},"source":["!pip install OpenNMT-py # restart runtime and run cell again if errors occur"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: OpenNMT-py in /usr/local/lib/python3.6/dist-packages (1.1.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (3.13)\n","Requirement already satisfied: configargparse in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.2.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.12.0)\n","Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.4.0)\n","Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (2.2.0)\n","Requirement already satisfied: waitress in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.4.3)\n","Requirement already satisfied: tqdm~=4.30.0 in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (4.30.0)\n","Requirement already satisfied: flask in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.1.2)\n","Requirement already satisfied: pyonmttok==1.*; platform_system == \"Linux\" in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.18.3)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (0.16.0)\n","Requirement already satisfied: torchtext==0.4.0 in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (0.4.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (1.0.1)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (0.34.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (3.2.1)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (1.18.2)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (1.7.2)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (46.1.3)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (1.6.0.post3)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (1.28.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (0.9.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (0.4.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (2.21.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (3.10.0)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask->OpenNMT-py) (1.1.0)\n","Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask->OpenNMT-py) (2.11.2)\n","Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask->OpenNMT-py) (7.1.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py) (0.2.8)\n","Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py) (3.1.1)\n","Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py) (4.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py) (1.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->OpenNMT-py) (2020.4.5.1)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->OpenNMT-py) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->OpenNMT-py) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->OpenNMT-py) (1.24.3)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask->OpenNMT-py) (1.1.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py) (3.1.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_uLzc7LfhuXX","colab_type":"code","outputId":"ea6e36ea-a272-46f8-902b-50941daa774c","colab":{"base_uri":"https://localhost:8080/","height":222},"executionInfo":{"status":"ok","timestamp":1587454573271,"user_tz":-180,"elapsed":5462,"user":{"displayName":"Hanna Kitti","photoUrl":"","userId":"01511785927733709431"}}},"source":["!wget -nc https://raw.githubusercontent.com/TurkuNLP/Deep_Learning_in_LangTech_course/master/data/generated_dates.txt"],"execution_count":2,"outputs":[{"output_type":"stream","text":["--2020-04-21 07:36:10--  https://raw.githubusercontent.com/TurkuNLP/Deep_Learning_in_LangTech_course/master/data/generated_dates.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2872063 (2.7M) [text/plain]\n","Saving to: ‘generated_dates.txt’\n","\n","\rgenerated_dates.txt   0%[                    ]       0  --.-KB/s               \rgenerated_dates.txt 100%[===================>]   2.74M  15.3MB/s    in 0.2s    \n","\n","2020-04-21 07:36:11 (15.3 MB/s) - ‘generated_dates.txt’ saved [2872063/2872063]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g_ChRkJgiSHv","colab_type":"code","outputId":"69dab2a2-1389-4764-9d51-6ef7b872314a","colab":{"base_uri":"https://localhost:8080/","height":74},"executionInfo":{"status":"ok","timestamp":1587454584549,"user_tz":-180,"elapsed":989,"user":{"displayName":"Hanna Kitti","photoUrl":"","userId":"01511785927733709431"}}},"source":["def load_data(fname):\n","    data = []\n","    with open(fname, \"rt\", encoding=\"utf-8\") as f:\n","        for line in f:\n","            line = line.strip()\n","            input_text, output_text = line.split(\"\\t\")\n","            data.append((input_text, output_text))\n","    return data\n","\n","data = load_data(\"generated_dates.txt\")\n","\n","print(\"Number of examples:\", len(data))\n","print(\"First examples:\", data[:5])\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Number of examples: 100000\n","First examples: [('tammikuun 18. 1987', '18.01.1987'), ('joulukuun 26. 1993', '26.12.1993'), ('KESÄKUUN 16. 2009', '16.06.2009'), ('1997/8/7', '07.08.1997'), ('9. päivänä Heinäkuuta 1981', '09.07.1981')]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3u5zxVJFkACr","colab_type":"text"},"source":["### Create training and development files\n","\n","- OpenNMT\n","    - command line tool (just inpot and output filrs needed), which can be used as a python library as well (but then you need to handle all steps youself)\n","    - requires text files as input\n","- Split data into train and development sets\n","- Data format:\n","    - One file for training input sequences, one file for training output sequences, line numbering must match\n","    - Items (words/characters/subwords) separated by whitespace\n"]},{"cell_type":"code","metadata":{"id":"DQVwFIj7jzDh","colab_type":"code","outputId":"db7e3e83-ddf1-4936-b671-2e499b9e4162","colab":{"base_uri":"https://localhost:8080/","height":56},"executionInfo":{"status":"ok","timestamp":1587454860048,"user_tz":-180,"elapsed":2021,"user":{"displayName":"Hanna Kitti","photoUrl":"","userId":"01511785927733709431"}}},"source":["from sklearn.model_selection import train_test_split\n","\n","def prepare_input(data):\n","  examples = []\n","  for input_, output_ in data:\n","    input_seq = \" \".join(c for c in input_.replace(\" \", \"@\")) # whitespace is item separator, so real whitespace must be represented differently\n","    output_seq = \" \".join(c for c in output_.replace(\" \", \"@\"))\n","    examples.append((input_seq, output_seq))\n","  return examples\n","\n","\n","def save_data(train_data, dev_data):\n","  # write data into files\n","  with open(\"train.input\", \"wt\", encoding=\"utf-8\") as train_input, open(\"train.output\", \"wt\", encoding=\"utf-8\") as train_output:\n","    for input_text, output_text in train_data:\n","      print(input_text, file=train_input)\n","      print(output_text, file=train_output)\n","\n","  with open(\"dev.input\", \"wt\", encoding=\"utf-8\") as dev_input, open(\"dev.output\", \"wt\", encoding=\"utf-8\") as dev_output:\n","    for input_text, output_text in dev_data:\n","      print(input_text, file=dev_input)\n","      print(output_text, file=dev_output)\n","\n","\n","\n","# prepare correct input representation (whitespace separated items) and save\n","data = prepare_input(data)\n","print(\"First examples:\", data[:5])\n","\n","train_data, dev_data = train_test_split(data, test_size=0.2, train_size=0.8, shuffle=True)\n","save_data(train_data, dev_data) # for OpenNMT\n","\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["First examples: [('t a m m i k u u n @ 1 8 . @ 1 9 8 7', '1 8 . 0 1 . 1 9 8 7'), ('j o u l u k u u n @ 2 6 . @ 1 9 9 3', '2 6 . 1 2 . 1 9 9 3'), ('K E S Ä K U U N @ 1 6 . @ 2 0 0 9', '1 6 . 0 6 . 2 0 0 9'), ('1 9 9 7 / 8 / 7', '0 7 . 0 8 . 1 9 9 7'), ('9 . @ p ä i v ä n ä @ H e i n ä k u u t a @ 1 9 8 1', '0 9 . 0 7 . 1 9 8 1')]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SGicgLR2FgCD","colab_type":"text"},"source":["## Train"]},{"cell_type":"code","metadata":{"id":"UJ9KNaFjFnxB","colab_type":"code","outputId":"3abe9be0-2187-4bce-ad8c-4f3fd9be5686","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1587455414438,"user_tz":-180,"elapsed":293497,"user":{"displayName":"Hanna Kitti","photoUrl":"","userId":"01511785927733709431"}}},"source":["# run OpenNMT preprocessing, this handles vectorization etc.\n","# ! --> run in command line using the commands pip installed\n","# pytorch backend used here in OpenNMT\n","!onmt_preprocess -train_src train.input -train_tgt train.output -valid_src dev.input -valid_tgt dev.output -save_data preprocessed-data -src_words_min_frequency 5 -tgt_words_min_frequency 5 -overwrite\n","\n","# train model\n","BATCH_SIZE = 64\n","LEARNING_RATE = 0.001\n","OPTIMIZER = \"adam\"\n","TRAIN_STEPS = 3000 #step is one minibatch, so train for 3000 minibatches\n","\n","print(\"How many epochs:\", (TRAIN_STEPS*BATCH_SIZE)/len(train_data))\n","\n","# save the model\n","!onmt_train -data preprocessed-data -save_model trained-model -gpu_ranks 0 -learning_rate {LEARNING_RATE} -batch_size {BATCH_SIZE} -optim {OPTIMIZER} -train_steps {TRAIN_STEPS} -save_checkpoint_steps {TRAIN_STEPS}"],"execution_count":5,"outputs":[{"output_type":"stream","text":["[2020-04-21 07:45:28,219 INFO] Extracting features...\n","[2020-04-21 07:45:28,220 INFO]  * number of source features: 0.\n","[2020-04-21 07:45:28,220 INFO]  * number of target features: 0.\n","[2020-04-21 07:45:28,220 INFO] Building `Fields` object...\n","[2020-04-21 07:45:28,220 INFO] Building & saving training data...\n","[2020-04-21 07:45:28,302 INFO] Building shard 0.\n","[2020-04-21 07:45:30,940 INFO]  * saving 0th train data shard to preprocessed-data.train.0.pt.\n","[2020-04-21 07:45:32,839 INFO]  * tgt vocab size: 15.\n","[2020-04-21 07:45:32,839 INFO]  * src vocab size: 49.\n","[2020-04-21 07:45:32,870 INFO] Building & saving validation data...\n","[2020-04-21 07:45:32,914 INFO] Building shard 0.\n","[2020-04-21 07:45:33,262 INFO]  * saving 0th valid data shard to preprocessed-data.valid.0.pt.\n","How many epochs: 2.4\n","[2020-04-21 07:45:37,183 INFO]  * src vocab size = 49\n","[2020-04-21 07:45:37,183 INFO]  * tgt vocab size = 15\n","[2020-04-21 07:45:37,183 INFO] Building model...\n","[2020-04-21 07:45:45,299 INFO] NMTModel(\n","  (encoder): RNNEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(49, 500, padding_idx=1)\n","        )\n","      )\n","    )\n","    (rnn): LSTM(500, 500, num_layers=2, dropout=0.3)\n","  )\n","  (decoder): InputFeedRNNDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(15, 500, padding_idx=1)\n","        )\n","      )\n","    )\n","    (dropout): Dropout(p=0.3, inplace=False)\n","    (rnn): StackedLSTM(\n","      (dropout): Dropout(p=0.3, inplace=False)\n","      (layers): ModuleList(\n","        (0): LSTMCell(1000, 500)\n","        (1): LSTMCell(500, 500)\n","      )\n","    )\n","    (attn): GlobalAttention(\n","      (linear_in): Linear(in_features=500, out_features=500, bias=False)\n","      (linear_out): Linear(in_features=1000, out_features=500, bias=False)\n","    )\n","  )\n","  (generator): Sequential(\n","    (0): Linear(in_features=500, out_features=15, bias=True)\n","    (1): Cast()\n","    (2): LogSoftmax()\n","  )\n",")\n","[2020-04-21 07:45:45,299 INFO] encoder: 4032500\n","[2020-04-21 07:45:45,299 INFO] decoder: 5773015\n","[2020-04-21 07:45:45,300 INFO] * number of parameters: 9805515\n","[2020-04-21 07:45:45,301 INFO] Starting training on GPU: [0]\n","[2020-04-21 07:45:45,301 INFO] Start training loop and validate every 10000 steps...\n","[2020-04-21 07:45:45,302 INFO] Loading dataset from preprocessed-data.train.0.pt\n","[2020-04-21 07:45:45,823 INFO] number of examples: 80000\n","[2020-04-21 07:45:50,968 INFO] Step 50/ 3000; acc:  49.06; ppl:  4.37; xent: 1.47; lr: 0.00100; 8475/6213 tok/s;      6 sec\n","[2020-04-21 07:45:55,444 INFO] Step 100/ 3000; acc:  79.36; ppl:  1.77; xent: 0.57; lr: 0.00100; 11782/7864 tok/s;     10 sec\n","[2020-04-21 07:45:59,935 INFO] Step 150/ 3000; acc:  96.78; ppl:  1.11; xent: 0.10; lr: 0.00100; 12112/7837 tok/s;     15 sec\n","[2020-04-21 07:46:04,326 INFO] Step 200/ 3000; acc:  98.71; ppl:  1.05; xent: 0.04; lr: 0.00100; 11621/8017 tok/s;     19 sec\n","[2020-04-21 07:46:08,807 INFO] Step 250/ 3000; acc:  99.32; ppl:  1.03; xent: 0.03; lr: 0.00100; 11927/7856 tok/s;     24 sec\n","[2020-04-21 07:46:13,164 INFO] Step 300/ 3000; acc:  99.62; ppl:  1.01; xent: 0.01; lr: 0.00100; 10886/8080 tok/s;     28 sec\n","[2020-04-21 07:46:17,473 INFO] Step 350/ 3000; acc:  99.79; ppl:  1.01; xent: 0.01; lr: 0.00100; 10835/8168 tok/s;     32 sec\n","[2020-04-21 07:46:21,964 INFO] Step 400/ 3000; acc:  99.56; ppl:  1.02; xent: 0.02; lr: 0.00100; 11986/7839 tok/s;     37 sec\n","[2020-04-21 07:46:26,390 INFO] Step 450/ 3000; acc:  99.74; ppl:  1.01; xent: 0.01; lr: 0.00100; 11776/7954 tok/s;     41 sec\n","[2020-04-21 07:46:30,850 INFO] Step 500/ 3000; acc:  99.86; ppl:  1.00; xent: 0.00; lr: 0.00100; 11896/7892 tok/s;     46 sec\n","[2020-04-21 07:46:35,238 INFO] Step 550/ 3000; acc:  99.96; ppl:  1.00; xent: 0.00; lr: 0.00100; 11371/8022 tok/s;     50 sec\n","[2020-04-21 07:46:39,641 INFO] Step 600/ 3000; acc:  99.99; ppl:  1.00; xent: 0.00; lr: 0.00100; 11526/7994 tok/s;     54 sec\n","[2020-04-21 07:46:44,121 INFO] Step 650/ 3000; acc: 100.00; ppl:  1.00; xent: 0.00; lr: 0.00100; 12167/7858 tok/s;     59 sec\n","[2020-04-21 07:46:48,409 INFO] Step 700/ 3000; acc: 100.00; ppl:  1.00; xent: 0.00; lr: 0.00100; 10417/8209 tok/s;     63 sec\n","[2020-04-21 07:46:52,822 INFO] Step 750/ 3000; acc: 100.00; ppl:  1.00; xent: 0.00; lr: 0.00100; 11491/7978 tok/s;     68 sec\n","[2020-04-21 07:46:57,353 INFO] Step 800/ 3000; acc: 100.00; ppl:  1.00; xent: 0.00; lr: 0.00100; 12515/7768 tok/s;     72 sec\n","[2020-04-21 07:47:01,782 INFO] Step 850/ 3000; acc: 100.00; ppl:  1.00; xent: 0.00; lr: 0.00100; 11928/7948 tok/s;     76 sec\n","[2020-04-21 07:47:06,186 INFO] Step 900/ 3000; acc:  99.59; ppl:  1.02; xent: 0.02; lr: 0.00100; 11220/7992 tok/s;     81 sec\n","[2020-04-21 07:47:10,639 INFO] Step 950/ 3000; acc:  98.71; ppl:  1.06; xent: 0.05; lr: 0.00100; 11849/7906 tok/s;     85 sec\n","[2020-04-21 07:47:14,955 INFO] Step 1000/ 3000; acc:  99.46; ppl:  1.03; xent: 0.03; lr: 0.00100; 10751/8156 tok/s;     90 sec\n","[2020-04-21 07:47:19,250 INFO] Step 1050/ 3000; acc:  99.74; ppl:  1.01; xent: 0.01; lr: 0.00100; 10445/8195 tok/s;     94 sec\n","[2020-04-21 07:47:23,845 INFO] Step 1100/ 3000; acc:  99.77; ppl:  1.01; xent: 0.01; lr: 0.00100; 12857/7662 tok/s;     99 sec\n","[2020-04-21 07:47:28,273 INFO] Step 1150/ 3000; acc:  99.82; ppl:  1.01; xent: 0.01; lr: 0.00100; 11707/7951 tok/s;    103 sec\n","[2020-04-21 07:47:32,677 INFO] Step 1200/ 3000; acc:  99.97; ppl:  1.00; xent: 0.00; lr: 0.00100; 11484/7992 tok/s;    107 sec\n","[2020-04-21 07:47:37,136 INFO] Step 1250/ 3000; acc:  99.97; ppl:  1.00; xent: 0.00; lr: 0.00100; 11956/7895 tok/s;    112 sec\n","[2020-04-21 07:47:37,139 INFO] Loading dataset from preprocessed-data.train.0.pt\n","[2020-04-21 07:47:37,811 INFO] number of examples: 80000\n","[2020-04-21 07:47:42,466 INFO] Step 1300/ 3000; acc:  99.95; ppl:  1.00; xent: 0.00; lr: 0.00100; 9008/6604 tok/s;    117 sec\n","[2020-04-21 07:47:46,952 INFO] Step 1350/ 3000; acc: 100.00; ppl:  1.00; xent: 0.00; lr: 0.00100; 11758/7848 tok/s;    122 sec\n","[2020-04-21 07:47:51,419 INFO] Step 1400/ 3000; acc: 100.00; ppl:  1.00; xent: 0.00; lr: 0.00100; 12179/7880 tok/s;    126 sec\n","[2020-04-21 07:47:55,813 INFO] Step 1450/ 3000; acc: 100.00; ppl:  1.00; xent: 0.00; lr: 0.00100; 11612/8011 tok/s;    131 sec\n","[2020-04-21 07:48:00,257 INFO] Step 1500/ 3000; acc: 100.00; ppl:  1.00; xent: 0.00; lr: 0.00100; 12025/7920 tok/s;    135 sec\n","[2020-04-21 07:48:04,589 INFO] Step 1550/ 3000; acc:  99.99; ppl:  1.00; xent: 0.00; lr: 0.00100; 10948/8126 tok/s;    139 sec\n","[2020-04-21 07:48:08,918 INFO] Step 1600/ 3000; acc: 100.00; ppl:  1.00; xent: 0.00; lr: 0.00100; 10788/8133 tok/s;    144 sec\n","[2020-04-21 07:48:13,371 INFO] Step 1650/ 3000; acc: 100.00; ppl:  1.00; xent: 0.00; lr: 0.00100; 12088/7905 tok/s;    148 sec\n","[2020-04-21 07:48:17,790 INFO] Step 1700/ 3000; acc: 100.00; ppl:  1.00; xent: 0.00; lr: 0.00100; 11794/7966 tok/s;    152 sec\n","[2020-04-21 07:48:22,235 INFO] Step 1750/ 3000; acc: 100.00; ppl:  1.00; xent: 0.00; lr: 0.00100; 11936/7919 tok/s;    157 sec\n","[2020-04-21 07:48:26,629 INFO] Step 1800/ 3000; acc: 100.00; ppl:  1.00; xent: 0.00; lr: 0.00100; 11357/8012 tok/s;    161 sec\n","[2020-04-21 07:48:31,017 INFO] Step 1850/ 3000; acc: 100.00; ppl:  1.00; xent: 0.00; lr: 0.00100; 11566/8022 tok/s;    166 sec\n","[2020-04-21 07:48:35,496 INFO] Step 1900/ 3000; acc: 100.00; ppl:  1.00; xent: 0.00; lr: 0.00100; 12169/7860 tok/s;    170 sec\n","[2020-04-21 07:48:39,783 INFO] Step 1950/ 3000; acc: 100.00; ppl:  1.00; xent: 0.00; lr: 0.00100; 10421/8211 tok/s;    174 sec\n","[2020-04-21 07:48:44,171 INFO] Step 2000/ 3000; acc: 100.00; ppl:  1.00; xent: 0.00; lr: 0.00100; 11554/8023 tok/s;    179 sec\n","[2020-04-21 07:48:48,704 INFO] Step 2050/ 3000; acc: 100.00; ppl:  1.00; xent: 0.00; lr: 0.00100; 12511/7766 tok/s;    183 sec\n","[2020-04-21 07:48:53,152 INFO] Step 2100/ 3000; acc: 100.00; ppl:  1.00; xent: 0.00; lr: 0.00100; 11876/7914 tok/s;    188 sec\n","[2020-04-21 07:48:57,524 INFO] Step 2150/ 3000; acc: 100.00; ppl:  1.00; xent: 0.00; lr: 0.00100; 11302/8051 tok/s;    192 sec\n","[2020-04-21 07:49:01,996 INFO] Step 2200/ 3000; acc: 100.00; ppl:  1.00; xent: 0.00; lr: 0.00100; 11798/7872 tok/s;    197 sec\n","[2020-04-21 07:49:06,320 INFO] Step 2250/ 3000; acc: 100.00; ppl:  1.00; xent: 0.00; lr: 0.00100; 10731/8140 tok/s;    201 sec\n","[2020-04-21 07:49:10,602 INFO] Step 2300/ 3000; acc: 100.00; ppl:  1.00; xent: 0.00; lr: 0.00100; 10480/8222 tok/s;    205 sec\n","[2020-04-21 07:49:15,158 INFO] Step 2350/ 3000; acc:  99.90; ppl:  1.00; xent: 0.00; lr: 0.00100; 12966/7726 tok/s;    210 sec\n","[2020-04-21 07:49:19,592 INFO] Step 2400/ 3000; acc:  99.61; ppl:  1.02; xent: 0.02; lr: 0.00100; 11689/7939 tok/s;    214 sec\n","[2020-04-21 07:49:24,001 INFO] Step 2450/ 3000; acc:  99.73; ppl:  1.01; xent: 0.01; lr: 0.00100; 11473/7985 tok/s;    219 sec\n","[2020-04-21 07:49:28,466 INFO] Step 2500/ 3000; acc:  99.87; ppl:  1.00; xent: 0.00; lr: 0.00100; 11939/7884 tok/s;    223 sec\n","[2020-04-21 07:49:28,469 INFO] Loading dataset from preprocessed-data.train.0.pt\n","[2020-04-21 07:49:29,002 INFO] number of examples: 80000\n","[2020-04-21 07:49:33,667 INFO] Step 2550/ 3000; acc:  99.89; ppl:  1.01; xent: 0.01; lr: 0.00100; 9234/6769 tok/s;    228 sec\n","[2020-04-21 07:49:38,124 INFO] Step 2600/ 3000; acc:  99.99; ppl:  1.00; xent: 0.00; lr: 0.00100; 11832/7897 tok/s;    233 sec\n","[2020-04-21 07:49:42,620 INFO] Step 2650/ 3000; acc:  99.89; ppl:  1.01; xent: 0.01; lr: 0.00100; 12100/7829 tok/s;    237 sec\n","[2020-04-21 07:49:47,017 INFO] Step 2700/ 3000; acc:  99.99; ppl:  1.00; xent: 0.00; lr: 0.00100; 11604/8005 tok/s;    242 sec\n","[2020-04-21 07:49:51,480 INFO] Step 2750/ 3000; acc: 100.00; ppl:  1.00; xent: 0.00; lr: 0.00100; 11976/7888 tok/s;    246 sec\n","[2020-04-21 07:49:55,815 INFO] Step 2800/ 3000; acc: 100.00; ppl:  1.00; xent: 0.00; lr: 0.00100; 10942/8121 tok/s;    251 sec\n","[2020-04-21 07:50:00,126 INFO] Step 2850/ 3000; acc: 100.00; ppl:  1.00; xent: 0.00; lr: 0.00100; 10830/8164 tok/s;    255 sec\n","[2020-04-21 07:50:04,586 INFO] Step 2900/ 3000; acc: 100.00; ppl:  1.00; xent: 0.00; lr: 0.00100; 12071/7894 tok/s;    259 sec\n","[2020-04-21 07:50:09,013 INFO] Step 2950/ 3000; acc: 100.00; ppl:  1.00; xent: 0.00; lr: 0.00100; 11771/7950 tok/s;    264 sec\n","[2020-04-21 07:50:13,469 INFO] Step 3000/ 3000; acc: 100.00; ppl:  1.00; xent: 0.00; lr: 0.00100; 11908/7901 tok/s;    268 sec\n","[2020-04-21 07:50:13,470 INFO] Saving checkpoint trained-model_step_3000.pt\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HKS5ED06JR5w","colab_type":"text"},"source":["## Predict\n","\n","- Prediction also requires input files, let's write files on-the-fly with bash\n"]},{"cell_type":"code","metadata":{"id":"a65snhizKIBw","colab_type":"code","outputId":"f15504b6-3c28-45cb-d3a0-da4306f21acb","colab":{"base_uri":"https://localhost:8080/","height":240},"executionInfo":{"status":"ok","timestamp":1587455650513,"user_tz":-180,"elapsed":11964,"user":{"displayName":"Hanna Kitti","photoUrl":"","userId":"01511785927733709431"}}},"source":["#'1. helmikuuta 2003', 'Toukokuun 7. päivä 1995', '9. päivä huhtikuuta 2020'\n","!echo \"1. helmikuuta 2003\" | perl -pe 's/ /@/g' | perl -CS -pe 's/(.)/\\1 /g' | tee \"tmp.tmp\"; onmt_translate -model trained-model_step_3000.pt -src tmp.tmp -output pred.txt ; cat pred.txt | perl -pe 's/ //g'\n","!echo \"Toukokuun 7. päivä 1995\" | perl -pe 's/ /@/g' | perl -CS -pe 's/(.)/\\1 /g' | tee \"tmp.tmp\"; onmt_translate -model trained-model_step_3000.pt -src tmp.tmp -output pred.txt ; cat pred.txt | perl -pe 's/ //g'\n","!echo \"9. päivä huhtikuuta 2020\" | perl -pe 's/ /@/g' | perl -CS -pe 's/(.)/\\1 /g' | tee \"tmp.tmp\"; onmt_translate -model trained-model_step_3000.pt -src tmp.tmp -output pred.txt ; cat pred.txt | perl -pe 's/ //g'"],"execution_count":6,"outputs":[{"output_type":"stream","text":["1 . @ h e l m i k u u t a @ 2 0 0 3 \n","[2020-04-21 07:54:02,059 INFO] Translating shard 0.\n","PRED AVG SCORE: -0.0000, PRED PPL: 1.0000\n","01.02.2003\n","T o u k o k u u n @ 7 . @ p ä i v ä @ 1 9 9 5 \n","[2020-04-21 07:54:05,574 INFO] Translating shard 0.\n","PRED AVG SCORE: -0.0000, PRED PPL: 1.0000\n","07.05.1995\n","9 . @ p ä i v ä @ h u h t i k u u t a @ 2 0 2 0 \n","[2020-04-21 07:54:09,008 INFO] Translating shard 0.\n","PRED AVG SCORE: -0.0000, PRED PPL: 1.0000\n","09.04.2020\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NTeAKPN461-0","colab_type":"text"},"source":["# Recap: Running OpenNMT-py\n","- You need to create input sequence and output sequence text files\n","    - Line numbers must match\n","    - Items (characters/tokens) separated using whitespace\n","- Model type can be defined using command-line parameters\n","\n","# Lemmatization\n","\n","- For the given word (which may be inflected), determine its base form (dictionary form)\n","    - dogs --> dog\n","    - played --> play\n","    - talossa -> talo\n","    - lukisimme --> lukea\n","    - öiden --> yö\n","\n","- In some languages words can heavily change when inflecting (it's not just adding suffixes)\n","- Exluding irregular words, inflections are not arbitrary, they follow certain language rules\n","    - Rules can be very complicated, but learnable\n","- Good fit for sequence to sequence models\n","- Simple approach: inflected word in --> lemma out\n","    - character level model where one character is one input unit\n","    - d o g s --> d o g \n","    - l u k i s i m m e --> l u k e a\n","\n","- Ambiguity:\n","    - lives --> live (VERB) or life (NOUN)\n","    - koirasta --> koira (Case=Ela) or koiras (Case=Par) or koi#rasta (Case=Nom, if such exists?)\n","    - We need context representation!\n","    - \"En pidä hänen koirasta, koska se haukkuu liikaa.\" --> koira\n","\n","- Context representations\n","  - Context as sliding window of text\n","      - p i d ä @ h ä n e n @ < k o i r a s t a > , @ k o s k a --> k o i r a\n","      - Context representation is very sparse\n","      - At the same time you need to learn how inflections work in Finnish, and to understand the context in order to generate the correct lemma\n","      - Works reasonably well if you have **a lot** of training data\n","  - **Context as morphological tags**\n","      - l i v e s VERB Mood=Ind Number=Sing Person=3 Tense=Pres VerbForm=Fin --> l i v e\n","      - l i v e s NOUN Number=Plur --> l i f e \n","      - k o i r a s t a NOUN Case=Ela Number=Sing --> k o i r a\n","      - k o i r a s t a NOUN Case=Par Number=Sing --> k o i r a s\n","      - Compact context representation (better generalization)\n","      - If you already know these morphological tags (by running a tagger), you only need to learn how inflections work\n","      - Works very well also with less training data\n","\n","- **Brain-teaser:** Why words are not suitable input and output units in lemmatization as such?\n","    - Lukisimme koko päivän kirjaa . --> lukea koko päivä kirja . (sequence labeling task, label set = lemma vocabulary)\n","    - You would need to learn a mapping between words and possible lemmas for it\n","      - if you see 'koirasta' in input, remember that possible lemmas are 'koira' and 'koiras', and predict one of these 'labels' based on context\n","    - Vocabulary is huge, and data is sparse\n","    - You would not be able to predict anything for unknown words (words not seen during training)\n","      - In practise, the model would pick a (random) lemma out of all lemmas, or predict  label unknown if trained to do so\n","    - \"Herra Růžičkalla on uudenaikainen moottorivene .\" --> \"herra UNK olla UNK UNK .\"\n","    - However, you can transform this into reasonable sequence labeling task by predicting e.g. edit-rules but this is another story...\n","\n","\n","## Let's train a Finnish seq2seq lemmatizer with morphological tags as context\n","\n","- When we have the lemmatizer model trained, we can lemmatize new text by first running a tagger model to predict morphological tags, then run the lemmatizer for each word \n","\n","## Download data\n","\n","- **treebank:** an annotated collection of text including annotation for text segmentation, part-of-speech and morphological features, lemmatization and syntactic relations\n","- Finnish: https://github.com/UniversalDependencies/UD_Finnish-TDT\n","- Other languages: https://universaldependencies.org\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"vpq2NKiX8zag","colab_type":"code","outputId":"6be46583-2424-457b-961c-e22135801561","colab":{"base_uri":"https://localhost:8080/","height":427},"executionInfo":{"status":"ok","timestamp":1587457232722,"user_tz":-180,"elapsed":7353,"user":{"displayName":"Hanna Kitti","photoUrl":"","userId":"01511785927733709431"}}},"source":["!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Finnish-TDT/master/fi_tdt-ud-train.conllu\n","!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Finnish-TDT/master/fi_tdt-ud-dev.conllu"],"execution_count":7,"outputs":[{"output_type":"stream","text":["--2020-04-21 08:20:27--  https://raw.githubusercontent.com/UniversalDependencies/UD_Finnish-TDT/master/fi_tdt-ud-train.conllu\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 13443822 (13M) [text/plain]\n","Saving to: ‘fi_tdt-ud-train.conllu’\n","\n","\rfi_tdt-ud-train.con   0%[                    ]       0  --.-KB/s               \rfi_tdt-ud-train.con  14%[=>                  ]   1.83M  9.11MB/s               \rfi_tdt-ud-train.con  47%[========>           ]   6.04M  15.1MB/s               \rfi_tdt-ud-train.con 100%[===================>]  12.82M  22.5MB/s    in 0.6s    \n","\n","2020-04-21 08:20:28 (22.5 MB/s) - ‘fi_tdt-ud-train.conllu’ saved [13443822/13443822]\n","\n","--2020-04-21 08:20:30--  https://raw.githubusercontent.com/UniversalDependencies/UD_Finnish-TDT/master/fi_tdt-ud-dev.conllu\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1511949 (1.4M) [text/plain]\n","Saving to: ‘fi_tdt-ud-dev.conllu’\n","\n","fi_tdt-ud-dev.conll 100%[===================>]   1.44M  --.-KB/s    in 0.08s   \n","\n","2020-04-21 08:20:30 (18.8 MB/s) - ‘fi_tdt-ud-dev.conllu’ saved [1511949/1511949]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9Y2_BN8lxSnh","colab_type":"text"},"source":["## Data preprocessing\n","\n","What we need to do is:\n","- Extract words, lemmas and morphological features\n","- Create an **input sequence file** having the words (one character is one input item) and morphological features (one tag is one input item), one word per line\n","- Create an **output sequence file** having the lemma (one character is one output item), one lemma per line\n","- Line numbering must match\n","\n","**Task setting:** Given an input sequence, predict the corresponding output sequence"]},{"cell_type":"code","metadata":{"id":"_l7Uj0sq7GRW","colab_type":"code","colab":{}},"source":["# helper functions\n","\n","\"\"\"\n","# sent_id = b101.1\n","# text = Kävelyreitti III\n","1 Kävelyreitti  kävely#reitti\tNOUN\tN\tCase=Nom|Number=Sing\t0\troot\t0:root\t_\n","2\tIII\tIII\tADJ\tNum\tNumType=Ord\t1\tamod\t1:amod\t_\n","\n","# sent_id = b101.2\n","# text = Jäällä kävely avaa aina hauskoja ja erikoisia näkökulmia kaupunkiin.\n","1\tJäällä\tjää\tNOUN\tN\tCase=Ade|Number=Sing\t2\tnmod\t2:nmod\t_\n","2\tkävely\tkävely\tNOUN\tN\tCase=Nom|Derivation=U|Number=Sing\t3\tnsubj\t3:nsubj\t_\n","3\tavaa\tavata\tVERB\tV\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\t0\troot\t0:root\t_\n","4\taina\taina\tADV\tAdv\t_\t3\tadvmod\t3:advmod\t_\n","5\thauskoja\thauska\tADJ\tA\tCase=Par|Degree=Pos|Number=Plur\t8\tamod\t8:amod\t_\n","6\tja\tja\tCCONJ\tC\t_\t7\tcc\t7:cc\t_\n","7\terikoisia\terikoinen\tADJ\tA\tCase=Par|Degree=Pos|Derivation=Inen|Number=Plur\t5\tconj\t5:conj|8:amod\t_\n","8\tnäkökulmia\tnäkö#kulma\tNOUN\tN\tCase=Par|Number=Plur\t3\tobj\t3:obj\t_\n","9\tkaupunkiin\tkaupunki\tNOUN\tN\tCase=Ill|Number=Sing\t8\tnmod\t8:nmod\tSpaceAfter=No\n","10\t.\t.\tPUNCT\tPunct\t_\t3\tpunct\t3:punct\t_\n","\n","\"\"\"\n","\n","ID, FORM, LEMMA, UPOS, XPOS, FEATS, HEAD, DEPREL, DEPS, MISC = range(10)\n","\n","def read_conllu(f):\n","    sent=[]\n","    comment=[]\n","    for line in f:\n","        line=line.strip()\n","        if not line: # new sentence\n","            if sent:\n","                yield comment,sent\n","            comment=[]\n","            sent=[]\n","        elif line.startswith(\"#\"):\n","            comment.append(line)\n","        else: #normal line\n","            sent.append(line.split(\"\\t\"))\n","    else:\n","        if sent:\n","            yield comment, sent\n","\n","\n","def prepare_lemmatization_dataset(fname):\n","  # create input and output sequences (in text format)\n","  data = []\n","  with open(fname, \"rt\", encoding=\"utf-8\") as f:\n","    for comments, sent in read_conllu(f):\n","      for token in sent:\n","        if \"-\" in token[ID] or \".\" in token[ID]: # multiword token or null node --> skip\n","          continue\n","        input_chars = \" \".join(c for c in token[FORM]) # our translation model uses whitespace tokenization, so let's create character level model by inserting whitespaces\n","        features = \" \".join([token[UPOS]] + token[FEATS].split(\"|\")) # add morphological features\n","        input_chars = input_chars + \" \" + features\n","        lemma_chars = \" \".join(c for c in token[LEMMA])\n","        data.append((input_chars, lemma_chars))\n","  return data\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UTgNuPGywrsv","colab_type":"code","outputId":"d1d8903c-dfc8-4d6e-dfe7-fcdd3dc067cf","colab":{"base_uri":"https://localhost:8080/","height":149},"executionInfo":{"status":"ok","timestamp":1587457504060,"user_tz":-180,"elapsed":2918,"user":{"displayName":"Hanna Kitti","photoUrl":"","userId":"01511785927733709431"}}},"source":["import random \n","\n","# transform data\n","train_data = prepare_lemmatization_dataset(\"fi_tdt-ud-train.conllu\")\n","random.shuffle(train_data)\n","\n","dev_data = prepare_lemmatization_dataset(\"fi_tdt-ud-dev.conllu\")\n","\n","print(\"First train examples:\", train_data[:5])\n","print(\"Number of training examples:\", len(train_data))\n","print(\"Number of unique training examples:\", len(set(train_data)))\n","print(\"\\nNumber of development examples:\", len(dev_data))\n","print(\"Number of unique development examples:\", len(set(dev_data)))\n","\n","save_data(train_data, dev_data)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["First train examples: [('a l a s t i ADV Derivation=Sti', 'a l a s t i'), ('j u o t t a a VERB Mood=Ind Number=Sing Person=3 Tense=Pres VerbForm=Fin Voice=Act', 'j u o t t a a'), ('M a i t o l a m m i k k o o n NOUN Case=Ill Number=Sing', 'm a i t o # l a m m i k k o'), (', PUNCT _', ','), ('t o r j u a VERB InfForm=1 Number=Sing VerbForm=Inf Voice=Act', 't o r j u a')]\n","Number of training examples: 162816\n","Number of unique training examples: 51100\n","\n","Number of development examples: 18308\n","Number of unique development examples: 8662\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bJ48fQs8NEvD","colab_type":"code","outputId":"90ba23ab-3357-4ce7-e7fb-24fcb23ac0fc","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1587458002339,"user_tz":-180,"elapsed":455168,"user":{"displayName":"Hanna Kitti","photoUrl":"","userId":"01511785927733709431"}}},"source":["# run preprocessing, this handles vectorization etc.\n","!onmt_preprocess -train_src train.input -train_tgt train.output -valid_src dev.input -valid_tgt dev.output -save_data preprocessed-data -src_words_min_frequency 5 -tgt_words_min_frequency 5 -overwrite\n","# preprocess: text to numbers\n","\n","# train model\n","\n","BATCH_SIZE = 64\n","LEARNING_RATE = 0.001\n","OPTIMIZER = \"adam\"\n","ENCODER = \"brnn\" # bidiectional rnn\n","TRAIN_STEPS = 7000 #step is one minibatch, so train for 7000 minibatches\n","\n","print(\"How many epochs:\", (TRAIN_STEPS*BATCH_SIZE)/len(train_data))\n","\n","!onmt_train -data preprocessed-data -save_model trained-model -gpu_ranks 0 -learning_rate {LEARNING_RATE} -batch_size {BATCH_SIZE} -optim {OPTIMIZER} -train_steps {TRAIN_STEPS} -save_checkpoint_steps {TRAIN_STEPS} -encoder_type {ENCODER}"],"execution_count":10,"outputs":[{"output_type":"stream","text":["[2020-04-21 08:25:50,799 INFO] Extracting features...\n","[2020-04-21 08:25:50,800 INFO]  * number of source features: 0.\n","[2020-04-21 08:25:50,800 INFO]  * number of target features: 0.\n","[2020-04-21 08:25:50,800 INFO] Building `Fields` object...\n","[2020-04-21 08:25:50,800 INFO] Building & saving training data...\n","[2020-04-21 08:25:50,801 WARNING] Shards for corpus train already exist, will be overwritten because `-overwrite` option is set.\n","[2020-04-21 08:25:50,807 WARNING] Overwrite shards for corpus None\n","[2020-04-21 08:25:50,976 INFO] Building shard 0.\n","[2020-04-21 08:25:56,754 INFO]  * saving 0th train data shard to preprocessed-data.train.0.pt.\n","[2020-04-21 08:26:00,047 INFO]  * tgt vocab size: 115.\n","[2020-04-21 08:26:00,047 INFO]  * src vocab size: 217.\n","[2020-04-21 08:26:00,051 INFO] Building & saving validation data...\n","[2020-04-21 08:26:00,051 WARNING] Shards for corpus valid already exist, will be overwritten because `-overwrite` option is set.\n","[2020-04-21 08:26:00,056 WARNING] Overwrite shards for corpus None\n","[2020-04-21 08:26:00,085 INFO] Building shard 0.\n","[2020-04-21 08:26:00,435 INFO]  * saving 0th valid data shard to preprocessed-data.valid.0.pt.\n","How many epochs: 2.751572327044025\n","[2020-04-21 08:26:03,823 INFO]  * src vocab size = 217\n","[2020-04-21 08:26:03,823 INFO]  * tgt vocab size = 115\n","[2020-04-21 08:26:03,823 INFO] Building model...\n","[2020-04-21 08:26:06,205 INFO] NMTModel(\n","  (encoder): RNNEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(217, 500, padding_idx=1)\n","        )\n","      )\n","    )\n","    (rnn): LSTM(500, 250, num_layers=2, dropout=0.3, bidirectional=True)\n","  )\n","  (decoder): InputFeedRNNDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(115, 500, padding_idx=1)\n","        )\n","      )\n","    )\n","    (dropout): Dropout(p=0.3, inplace=False)\n","    (rnn): StackedLSTM(\n","      (dropout): Dropout(p=0.3, inplace=False)\n","      (layers): ModuleList(\n","        (0): LSTMCell(1000, 500)\n","        (1): LSTMCell(500, 500)\n","      )\n","    )\n","    (attn): GlobalAttention(\n","      (linear_in): Linear(in_features=500, out_features=500, bias=False)\n","      (linear_out): Linear(in_features=1000, out_features=500, bias=False)\n","    )\n","  )\n","  (generator): Sequential(\n","    (0): Linear(in_features=500, out_features=115, bias=True)\n","    (1): Cast()\n","    (2): LogSoftmax()\n","  )\n",")\n","[2020-04-21 08:26:06,205 INFO] encoder: 3116500\n","[2020-04-21 08:26:06,206 INFO] decoder: 5873115\n","[2020-04-21 08:26:06,206 INFO] * number of parameters: 8989615\n","[2020-04-21 08:26:06,207 INFO] Starting training on GPU: [0]\n","[2020-04-21 08:26:06,207 INFO] Start training loop and validate every 10000 steps...\n","[2020-04-21 08:26:06,208 INFO] Loading dataset from preprocessed-data.train.0.pt\n","[2020-04-21 08:26:07,442 INFO] number of examples: 162816\n","[2020-04-21 08:26:11,242 INFO] Step 50/ 7000; acc:  20.60; ppl: 21.30; xent: 3.06; lr: 0.00100; 6051/4183 tok/s;      5 sec\n","[2020-04-21 08:26:14,140 INFO] Step 100/ 7000; acc:  39.95; ppl:  8.89; xent: 2.18; lr: 0.00100; 10304/6931 tok/s;      8 sec\n","[2020-04-21 08:26:17,184 INFO] Step 150/ 7000; acc:  54.78; ppl:  5.04; xent: 1.62; lr: 0.00100; 11122/6860 tok/s;     11 sec\n","[2020-04-21 08:26:20,195 INFO] Step 200/ 7000; acc:  70.52; ppl:  3.02; xent: 1.11; lr: 0.00100; 10599/6935 tok/s;     14 sec\n","[2020-04-21 08:26:23,385 INFO] Step 250/ 7000; acc:  77.47; ppl:  2.26; xent: 0.82; lr: 0.00100; 10737/7115 tok/s;     17 sec\n","[2020-04-21 08:26:26,495 INFO] Step 300/ 7000; acc:  76.83; ppl:  2.56; xent: 0.94; lr: 0.00100; 10638/6935 tok/s;     20 sec\n","[2020-04-21 08:26:29,442 INFO] Step 350/ 7000; acc:  83.46; ppl:  1.87; xent: 0.63; lr: 0.00100; 9914/7108 tok/s;     23 sec\n","[2020-04-21 08:26:32,565 INFO] Step 400/ 7000; acc:  80.91; ppl:  2.18; xent: 0.78; lr: 0.00100; 10493/7290 tok/s;     26 sec\n","[2020-04-21 08:26:35,685 INFO] Step 450/ 7000; acc:  84.10; ppl:  1.89; xent: 0.64; lr: 0.00100; 10914/7125 tok/s;     29 sec\n","[2020-04-21 08:26:38,915 INFO] Step 500/ 7000; acc:  83.88; ppl:  1.91; xent: 0.65; lr: 0.00100; 10307/7316 tok/s;     33 sec\n","[2020-04-21 08:26:41,692 INFO] Step 550/ 7000; acc:  90.98; ppl:  1.42; xent: 0.35; lr: 0.00100; 10277/6764 tok/s;     35 sec\n","[2020-04-21 08:26:44,644 INFO] Step 600/ 7000; acc:  89.33; ppl:  1.53; xent: 0.43; lr: 0.00100; 10597/6685 tok/s;     38 sec\n","[2020-04-21 08:26:48,042 INFO] Step 650/ 7000; acc:  88.96; ppl:  1.53; xent: 0.42; lr: 0.00100; 11189/7228 tok/s;     42 sec\n","[2020-04-21 08:26:51,098 INFO] Step 700/ 7000; acc:  90.80; ppl:  1.47; xent: 0.39; lr: 0.00100; 10326/7224 tok/s;     45 sec\n","[2020-04-21 08:26:54,055 INFO] Step 750/ 7000; acc:  94.43; ppl:  1.23; xent: 0.21; lr: 0.00100; 10582/7055 tok/s;     48 sec\n","[2020-04-21 08:26:57,330 INFO] Step 800/ 7000; acc:  90.76; ppl:  1.53; xent: 0.42; lr: 0.00100; 10738/6877 tok/s;     51 sec\n","[2020-04-21 08:27:00,413 INFO] Step 850/ 7000; acc:  94.51; ppl:  1.24; xent: 0.21; lr: 0.00100; 10785/7033 tok/s;     54 sec\n","[2020-04-21 08:27:03,540 INFO] Step 900/ 7000; acc:  94.47; ppl:  1.24; xent: 0.22; lr: 0.00100; 10461/7204 tok/s;     57 sec\n","[2020-04-21 08:27:06,426 INFO] Step 950/ 7000; acc:  93.58; ppl:  1.31; xent: 0.27; lr: 0.00100; 10225/7089 tok/s;     60 sec\n","[2020-04-21 08:27:09,651 INFO] Step 1000/ 7000; acc:  94.01; ppl:  1.27; xent: 0.24; lr: 0.00100; 10814/7204 tok/s;     63 sec\n","[2020-04-21 08:27:12,929 INFO] Step 1050/ 7000; acc:  95.09; ppl:  1.20; xent: 0.18; lr: 0.00100; 10898/7360 tok/s;     67 sec\n","[2020-04-21 08:27:16,192 INFO] Step 1100/ 7000; acc:  92.12; ppl:  1.43; xent: 0.36; lr: 0.00100; 10237/7489 tok/s;     70 sec\n","[2020-04-21 08:27:19,659 INFO] Step 1150/ 7000; acc:  93.40; ppl:  1.34; xent: 0.29; lr: 0.00100; 10428/7084 tok/s;     73 sec\n","[2020-04-21 08:27:22,739 INFO] Step 1200/ 7000; acc:  95.35; ppl:  1.18; xent: 0.17; lr: 0.00100; 11034/7050 tok/s;     77 sec\n","[2020-04-21 08:27:25,591 INFO] Step 1250/ 7000; acc:  96.22; ppl:  1.16; xent: 0.15; lr: 0.00100; 10502/6874 tok/s;     79 sec\n","[2020-04-21 08:27:28,528 INFO] Step 1300/ 7000; acc:  96.75; ppl:  1.14; xent: 0.13; lr: 0.00100; 10502/6851 tok/s;     82 sec\n","[2020-04-21 08:27:31,497 INFO] Step 1350/ 7000; acc:  96.31; ppl:  1.16; xent: 0.15; lr: 0.00100; 10722/6712 tok/s;     85 sec\n","[2020-04-21 08:27:34,989 INFO] Step 1400/ 7000; acc:  94.12; ppl:  1.28; xent: 0.25; lr: 0.00100; 10812/7424 tok/s;     89 sec\n","[2020-04-21 08:27:38,080 INFO] Step 1450/ 7000; acc:  96.88; ppl:  1.13; xent: 0.12; lr: 0.00100; 10044/7335 tok/s;     92 sec\n","[2020-04-21 08:27:41,037 INFO] Step 1500/ 7000; acc:  97.52; ppl:  1.12; xent: 0.11; lr: 0.00100; 10563/7063 tok/s;     95 sec\n","[2020-04-21 08:27:44,142 INFO] Step 1550/ 7000; acc:  95.80; ppl:  1.21; xent: 0.19; lr: 0.00100; 10661/7130 tok/s;     98 sec\n","[2020-04-21 08:27:47,127 INFO] Step 1600/ 7000; acc:  97.17; ppl:  1.12; xent: 0.11; lr: 0.00100; 10849/6908 tok/s;    101 sec\n","[2020-04-21 08:27:49,872 INFO] Step 1650/ 7000; acc:  97.09; ppl:  1.13; xent: 0.12; lr: 0.00100; 10538/6795 tok/s;    104 sec\n","[2020-04-21 08:27:52,848 INFO] Step 1700/ 7000; acc:  97.01; ppl:  1.12; xent: 0.11; lr: 0.00100; 10645/7113 tok/s;    107 sec\n","[2020-04-21 08:27:55,764 INFO] Step 1750/ 7000; acc:  96.99; ppl:  1.14; xent: 0.13; lr: 0.00100; 9836/6687 tok/s;    110 sec\n","[2020-04-21 08:27:58,591 INFO] Step 1800/ 7000; acc:  96.69; ppl:  1.13; xent: 0.12; lr: 0.00100; 10278/6951 tok/s;    112 sec\n","[2020-04-21 08:28:01,852 INFO] Step 1850/ 7000; acc:  97.86; ppl:  1.09; xent: 0.08; lr: 0.00100; 10736/7351 tok/s;    116 sec\n","[2020-04-21 08:28:04,784 INFO] Step 1900/ 7000; acc:  97.51; ppl:  1.11; xent: 0.11; lr: 0.00100; 10633/7108 tok/s;    119 sec\n","[2020-04-21 08:28:07,512 INFO] Step 1950/ 7000; acc:  97.53; ppl:  1.12; xent: 0.12; lr: 0.00100; 10274/6749 tok/s;    121 sec\n","[2020-04-21 08:28:10,317 INFO] Step 2000/ 7000; acc:  97.37; ppl:  1.11; xent: 0.11; lr: 0.00100; 10410/6809 tok/s;    124 sec\n","[2020-04-21 08:28:13,515 INFO] Step 2050/ 7000; acc:  97.02; ppl:  1.13; xent: 0.12; lr: 0.00100; 10987/7214 tok/s;    127 sec\n","[2020-04-21 08:28:16,800 INFO] Step 2100/ 7000; acc:  97.03; ppl:  1.12; xent: 0.11; lr: 0.00100; 10805/7230 tok/s;    131 sec\n","[2020-04-21 08:28:19,779 INFO] Step 2150/ 7000; acc:  97.12; ppl:  1.13; xent: 0.12; lr: 0.00100; 10826/7076 tok/s;    134 sec\n","[2020-04-21 08:28:22,802 INFO] Step 2200/ 7000; acc:  97.82; ppl:  1.08; xent: 0.08; lr: 0.00100; 10814/6882 tok/s;    137 sec\n","[2020-04-21 08:28:25,911 INFO] Step 2250/ 7000; acc:  96.36; ppl:  1.20; xent: 0.18; lr: 0.00100; 10213/6948 tok/s;    140 sec\n","[2020-04-21 08:28:28,890 INFO] Step 2300/ 7000; acc:  98.63; ppl:  1.05; xent: 0.05; lr: 0.00100; 10891/7000 tok/s;    143 sec\n","[2020-04-21 08:28:31,804 INFO] Step 2350/ 7000; acc:  98.39; ppl:  1.06; xent: 0.06; lr: 0.00100; 10677/6928 tok/s;    146 sec\n","[2020-04-21 08:28:35,009 INFO] Step 2400/ 7000; acc:  98.12; ppl:  1.08; xent: 0.07; lr: 0.00100; 10784/7222 tok/s;    149 sec\n","[2020-04-21 08:28:37,825 INFO] Step 2450/ 7000; acc:  98.76; ppl:  1.05; xent: 0.05; lr: 0.00100; 10498/6873 tok/s;    152 sec\n","[2020-04-21 08:28:40,683 INFO] Step 2500/ 7000; acc:  98.09; ppl:  1.08; xent: 0.08; lr: 0.00100; 10786/6779 tok/s;    154 sec\n","[2020-04-21 08:28:43,405 INFO] Loading dataset from preprocessed-data.train.0.pt\n","[2020-04-21 08:28:45,064 INFO] number of examples: 162816\n","[2020-04-21 08:28:46,089 INFO] Step 2550/ 7000; acc:  98.11; ppl:  1.08; xent: 0.07; lr: 0.00100; 6038/3964 tok/s;    160 sec\n","[2020-04-21 08:28:49,125 INFO] Step 2600/ 7000; acc:  97.98; ppl:  1.09; xent: 0.08; lr: 0.00100; 10435/7181 tok/s;    163 sec\n","[2020-04-21 08:28:51,888 INFO] Step 2650/ 7000; acc:  97.76; ppl:  1.10; xent: 0.10; lr: 0.00100; 10156/6837 tok/s;    166 sec\n","[2020-04-21 08:28:55,067 INFO] Step 2700/ 7000; acc:  98.21; ppl:  1.07; xent: 0.07; lr: 0.00100; 11377/7006 tok/s;    169 sec\n","[2020-04-21 08:28:57,974 INFO] Step 2750/ 7000; acc:  97.95; ppl:  1.10; xent: 0.09; lr: 0.00100; 10540/6850 tok/s;    172 sec\n","[2020-04-21 08:29:01,176 INFO] Step 2800/ 7000; acc:  98.39; ppl:  1.07; xent: 0.07; lr: 0.00100; 10674/7181 tok/s;    175 sec\n","[2020-04-21 08:29:04,452 INFO] Step 2850/ 7000; acc:  95.81; ppl:  1.23; xent: 0.21; lr: 0.00100; 10695/7033 tok/s;    178 sec\n","[2020-04-21 08:29:07,245 INFO] Step 2900/ 7000; acc:  98.27; ppl:  1.08; xent: 0.08; lr: 0.00100; 9877/7082 tok/s;    181 sec\n","[2020-04-21 08:29:10,363 INFO] Step 2950/ 7000; acc:  98.12; ppl:  1.08; xent: 0.07; lr: 0.00100; 10633/7158 tok/s;    184 sec\n","[2020-04-21 08:29:13,539 INFO] Step 3000/ 7000; acc:  97.34; ppl:  1.13; xent: 0.12; lr: 0.00100; 10762/7302 tok/s;    187 sec\n","[2020-04-21 08:29:16,718 INFO] Step 3050/ 7000; acc:  97.71; ppl:  1.10; xent: 0.10; lr: 0.00100; 10493/7232 tok/s;    191 sec\n","[2020-04-21 08:29:19,514 INFO] Step 3100/ 7000; acc:  98.65; ppl:  1.06; xent: 0.06; lr: 0.00100; 9997/6642 tok/s;    193 sec\n","[2020-04-21 08:29:22,503 INFO] Step 3150/ 7000; acc:  98.48; ppl:  1.07; xent: 0.07; lr: 0.00100; 11199/6880 tok/s;    196 sec\n","[2020-04-21 08:29:25,844 INFO] Step 3200/ 7000; acc:  97.57; ppl:  1.11; xent: 0.10; lr: 0.00100; 10881/7301 tok/s;    200 sec\n","[2020-04-21 08:29:28,887 INFO] Step 3250/ 7000; acc:  98.03; ppl:  1.09; xent: 0.09; lr: 0.00100; 10368/7190 tok/s;    203 sec\n","[2020-04-21 08:29:31,860 INFO] Step 3300/ 7000; acc:  97.89; ppl:  1.11; xent: 0.10; lr: 0.00100; 10213/6797 tok/s;    206 sec\n","[2020-04-21 08:29:35,051 INFO] Step 3350/ 7000; acc:  98.52; ppl:  1.06; xent: 0.06; lr: 0.00100; 11332/7106 tok/s;    209 sec\n","[2020-04-21 08:29:38,114 INFO] Step 3400/ 7000; acc:  98.56; ppl:  1.05; xent: 0.05; lr: 0.00100; 10545/6995 tok/s;    212 sec\n","[2020-04-21 08:29:41,265 INFO] Step 3450/ 7000; acc:  98.34; ppl:  1.07; xent: 0.07; lr: 0.00100; 10543/7217 tok/s;    215 sec\n","[2020-04-21 08:29:44,201 INFO] Step 3500/ 7000; acc:  98.57; ppl:  1.07; xent: 0.06; lr: 0.00100; 10221/7084 tok/s;    218 sec\n","[2020-04-21 08:29:47,566 INFO] Step 3550/ 7000; acc:  98.35; ppl:  1.07; xent: 0.07; lr: 0.00100; 10824/7296 tok/s;    221 sec\n","[2020-04-21 08:29:50,797 INFO] Step 3600/ 7000; acc:  98.24; ppl:  1.07; xent: 0.07; lr: 0.00100; 10755/7385 tok/s;    225 sec\n","[2020-04-21 08:29:54,008 INFO] Step 3650/ 7000; acc:  97.46; ppl:  1.14; xent: 0.13; lr: 0.00100; 10267/7385 tok/s;    228 sec\n","[2020-04-21 08:29:57,402 INFO] Step 3700/ 7000; acc:  97.36; ppl:  1.15; xent: 0.14; lr: 0.00100; 10576/7126 tok/s;    231 sec\n","[2020-04-21 08:30:00,449 INFO] Step 3750/ 7000; acc:  98.58; ppl:  1.06; xent: 0.05; lr: 0.00100; 10943/7000 tok/s;    234 sec\n","[2020-04-21 08:30:03,382 INFO] Step 3800/ 7000; acc:  98.42; ppl:  1.08; xent: 0.07; lr: 0.00100; 10495/6880 tok/s;    237 sec\n","[2020-04-21 08:30:06,198 INFO] Step 3850/ 7000; acc:  98.98; ppl:  1.04; xent: 0.04; lr: 0.00100; 10269/6780 tok/s;    240 sec\n","[2020-04-21 08:30:09,316 INFO] Step 3900/ 7000; acc:  97.89; ppl:  1.11; xent: 0.10; lr: 0.00100; 10765/6811 tok/s;    243 sec\n","[2020-04-21 08:30:12,710 INFO] Step 3950/ 7000; acc:  97.92; ppl:  1.09; xent: 0.09; lr: 0.00100; 10993/7387 tok/s;    247 sec\n","[2020-04-21 08:30:15,753 INFO] Step 4000/ 7000; acc:  98.63; ppl:  1.06; xent: 0.06; lr: 0.00100; 10012/7304 tok/s;    250 sec\n","[2020-04-21 08:30:18,768 INFO] Step 4050/ 7000; acc:  98.80; ppl:  1.05; xent: 0.05; lr: 0.00100; 10574/7162 tok/s;    253 sec\n","[2020-04-21 08:30:21,852 INFO] Step 4100/ 7000; acc:  98.59; ppl:  1.06; xent: 0.06; lr: 0.00100; 10812/7176 tok/s;    256 sec\n","[2020-04-21 08:30:24,825 INFO] Step 4150/ 7000; acc:  98.72; ppl:  1.05; xent: 0.05; lr: 0.00100; 10810/6916 tok/s;    259 sec\n","[2020-04-21 08:30:27,702 INFO] Step 4200/ 7000; acc:  98.30; ppl:  1.09; xent: 0.08; lr: 0.00100; 10433/7010 tok/s;    261 sec\n","[2020-04-21 08:30:30,526 INFO] Step 4250/ 7000; acc:  98.80; ppl:  1.05; xent: 0.05; lr: 0.00100; 10764/6868 tok/s;    264 sec\n","[2020-04-21 08:30:33,522 INFO] Step 4300/ 7000; acc:  98.22; ppl:  1.08; xent: 0.08; lr: 0.00100; 9851/6939 tok/s;    267 sec\n","[2020-04-21 08:30:36,292 INFO] Step 4350/ 7000; acc:  98.66; ppl:  1.06; xent: 0.06; lr: 0.00100; 10306/6861 tok/s;    270 sec\n","[2020-04-21 08:30:39,490 INFO] Step 4400/ 7000; acc:  98.85; ppl:  1.05; xent: 0.05; lr: 0.00100; 10808/7236 tok/s;    273 sec\n","[2020-04-21 08:30:42,401 INFO] Step 4450/ 7000; acc:  98.52; ppl:  1.06; xent: 0.06; lr: 0.00100; 10376/7047 tok/s;    276 sec\n","[2020-04-21 08:30:45,140 INFO] Step 4500/ 7000; acc:  99.01; ppl:  1.04; xent: 0.04; lr: 0.00100; 10237/6795 tok/s;    279 sec\n","[2020-04-21 08:30:48,020 INFO] Step 4550/ 7000; acc:  98.41; ppl:  1.07; xent: 0.07; lr: 0.00100; 10668/6852 tok/s;    282 sec\n","[2020-04-21 08:30:51,172 INFO] Step 4600/ 7000; acc:  98.89; ppl:  1.05; xent: 0.05; lr: 0.00100; 10966/7138 tok/s;    285 sec\n","[2020-04-21 08:30:54,433 INFO] Step 4650/ 7000; acc:  98.32; ppl:  1.07; xent: 0.06; lr: 0.00100; 10686/7183 tok/s;    288 sec\n","[2020-04-21 08:30:57,575 INFO] Step 4700/ 7000; acc:  98.22; ppl:  1.09; xent: 0.08; lr: 0.00100; 10899/7152 tok/s;    291 sec\n","[2020-04-21 08:31:00,525 INFO] Step 4750/ 7000; acc:  98.72; ppl:  1.05; xent: 0.05; lr: 0.00100; 10948/6798 tok/s;    294 sec\n","[2020-04-21 08:31:03,519 INFO] Step 4800/ 7000; acc:  98.11; ppl:  1.09; xent: 0.09; lr: 0.00100; 10073/6981 tok/s;    297 sec\n","[2020-04-21 08:31:06,547 INFO] Step 4850/ 7000; acc:  99.19; ppl:  1.03; xent: 0.03; lr: 0.00100; 10863/6895 tok/s;    300 sec\n","[2020-04-21 08:31:09,557 INFO] Step 4900/ 7000; acc:  99.04; ppl:  1.04; xent: 0.04; lr: 0.00100; 10483/7075 tok/s;    303 sec\n","[2020-04-21 08:31:12,647 INFO] Step 4950/ 7000; acc:  98.97; ppl:  1.04; xent: 0.04; lr: 0.00100; 10895/7164 tok/s;    306 sec\n","[2020-04-21 08:31:15,522 INFO] Step 5000/ 7000; acc:  99.24; ppl:  1.03; xent: 0.03; lr: 0.00100; 10476/6776 tok/s;    309 sec\n","[2020-04-21 08:31:18,418 INFO] Step 5050/ 7000; acc:  98.91; ppl:  1.05; xent: 0.05; lr: 0.00100; 10851/6979 tok/s;    312 sec\n","[2020-04-21 08:31:20,749 INFO] Loading dataset from preprocessed-data.train.0.pt\n","[2020-04-21 08:31:22,456 INFO] number of examples: 162816\n","[2020-04-21 08:31:23,825 INFO] Step 5100/ 7000; acc:  98.66; ppl:  1.06; xent: 0.06; lr: 0.00100; 5907/3834 tok/s;    318 sec\n","[2020-04-21 08:31:26,873 INFO] Step 5150/ 7000; acc:  98.32; ppl:  1.08; xent: 0.08; lr: 0.00100; 10320/7106 tok/s;    321 sec\n","[2020-04-21 08:31:29,614 INFO] Step 5200/ 7000; acc:  98.51; ppl:  1.07; xent: 0.06; lr: 0.00100; 10252/6898 tok/s;    323 sec\n","[2020-04-21 08:31:32,831 INFO] Step 5250/ 7000; acc:  98.66; ppl:  1.06; xent: 0.06; lr: 0.00100; 11418/7081 tok/s;    327 sec\n","[2020-04-21 08:31:35,735 INFO] Step 5300/ 7000; acc:  98.61; ppl:  1.07; xent: 0.07; lr: 0.00100; 10594/6901 tok/s;    330 sec\n","[2020-04-21 08:31:39,112 INFO] Step 5350/ 7000; acc:  98.65; ppl:  1.06; xent: 0.06; lr: 0.00100; 10691/7300 tok/s;    333 sec\n","[2020-04-21 08:31:42,144 INFO] Step 5400/ 7000; acc:  98.87; ppl:  1.05; xent: 0.05; lr: 0.00100; 10668/6864 tok/s;    336 sec\n","[2020-04-21 08:31:45,013 INFO] Step 5450/ 7000; acc:  99.18; ppl:  1.03; xent: 0.03; lr: 0.00100; 9907/7128 tok/s;    339 sec\n","[2020-04-21 08:31:48,147 INFO] Step 5500/ 7000; acc:  98.91; ppl:  1.04; xent: 0.04; lr: 0.00100; 10638/7191 tok/s;    342 sec\n","[2020-04-21 08:31:51,294 INFO] Step 5550/ 7000; acc:  97.84; ppl:  1.12; xent: 0.11; lr: 0.00100; 10679/7167 tok/s;    345 sec\n","[2020-04-21 08:31:54,543 INFO] Step 5600/ 7000; acc:  98.63; ppl:  1.07; xent: 0.07; lr: 0.00100; 10483/7233 tok/s;    348 sec\n","[2020-04-21 08:31:57,217 INFO] Step 5650/ 7000; acc:  99.14; ppl:  1.04; xent: 0.04; lr: 0.00100; 9832/6468 tok/s;    351 sec\n","[2020-04-21 08:32:00,366 INFO] Step 5700/ 7000; acc:  98.96; ppl:  1.05; xent: 0.05; lr: 0.00100; 11199/7059 tok/s;    354 sec\n","[2020-04-21 08:32:03,567 INFO] Step 5750/ 7000; acc:  98.51; ppl:  1.07; xent: 0.07; lr: 0.00100; 10835/7271 tok/s;    357 sec\n","[2020-04-21 08:32:06,794 INFO] Step 5800/ 7000; acc:  98.73; ppl:  1.06; xent: 0.05; lr: 0.00100; 10652/7324 tok/s;    361 sec\n","[2020-04-21 08:32:09,685 INFO] Step 5850/ 7000; acc:  98.22; ppl:  1.09; xent: 0.08; lr: 0.00100; 10149/6613 tok/s;    363 sec\n","[2020-04-21 08:32:12,881 INFO] Step 5900/ 7000; acc:  98.98; ppl:  1.04; xent: 0.04; lr: 0.00100; 11124/6992 tok/s;    367 sec\n","[2020-04-21 08:32:15,942 INFO] Step 5950/ 7000; acc:  98.89; ppl:  1.05; xent: 0.05; lr: 0.00100; 10664/7126 tok/s;    370 sec\n","[2020-04-21 08:32:18,949 INFO] Step 6000/ 7000; acc:  98.68; ppl:  1.06; xent: 0.05; lr: 0.00100; 10515/7154 tok/s;    373 sec\n","[2020-04-21 08:32:21,949 INFO] Step 6050/ 7000; acc:  98.81; ppl:  1.05; xent: 0.05; lr: 0.00100; 10180/7133 tok/s;    376 sec\n","[2020-04-21 08:32:25,378 INFO] Step 6100/ 7000; acc:  98.73; ppl:  1.05; xent: 0.05; lr: 0.00100; 10916/7400 tok/s;    379 sec\n","[2020-04-21 08:32:28,631 INFO] Step 6150/ 7000; acc:  98.78; ppl:  1.06; xent: 0.05; lr: 0.00100; 10704/7376 tok/s;    382 sec\n","[2020-04-21 08:32:31,832 INFO] Step 6200/ 7000; acc:  97.89; ppl:  1.12; xent: 0.11; lr: 0.00100; 10340/7409 tok/s;    386 sec\n","[2020-04-21 08:32:35,113 INFO] Step 6250/ 7000; acc:  97.87; ppl:  1.13; xent: 0.13; lr: 0.00100; 10645/7020 tok/s;    389 sec\n","[2020-04-21 08:32:38,203 INFO] Step 6300/ 7000; acc:  98.81; ppl:  1.05; xent: 0.05; lr: 0.00100; 11041/7151 tok/s;    392 sec\n","[2020-04-21 08:32:41,050 INFO] Step 6350/ 7000; acc:  98.82; ppl:  1.05; xent: 0.05; lr: 0.00100; 10566/6819 tok/s;    395 sec\n","[2020-04-21 08:32:43,925 INFO] Step 6400/ 7000; acc:  99.18; ppl:  1.03; xent: 0.03; lr: 0.00100; 10057/6866 tok/s;    398 sec\n","[2020-04-21 08:32:47,080 INFO] Step 6450/ 7000; acc:  98.19; ppl:  1.08; xent: 0.08; lr: 0.00100; 10943/6850 tok/s;    401 sec\n","[2020-04-21 08:32:50,443 INFO] Step 6500/ 7000; acc:  98.55; ppl:  1.06; xent: 0.06; lr: 0.00100; 10773/7361 tok/s;    404 sec\n","[2020-04-21 08:32:53,443 INFO] Step 6550/ 7000; acc:  98.90; ppl:  1.05; xent: 0.05; lr: 0.00100; 9985/7259 tok/s;    407 sec\n","[2020-04-21 08:32:56,596 INFO] Step 6600/ 7000; acc:  98.84; ppl:  1.05; xent: 0.05; lr: 0.00100; 10738/7232 tok/s;    410 sec\n","[2020-04-21 08:32:59,626 INFO] Step 6650/ 7000; acc:  98.83; ppl:  1.05; xent: 0.05; lr: 0.00100; 10795/7022 tok/s;    413 sec\n","[2020-04-21 08:33:02,670 INFO] Step 6700/ 7000; acc:  98.97; ppl:  1.05; xent: 0.05; lr: 0.00100; 10870/6997 tok/s;    416 sec\n","[2020-04-21 08:33:05,583 INFO] Step 6750/ 7000; acc:  99.09; ppl:  1.04; xent: 0.04; lr: 0.00100; 10306/7059 tok/s;    419 sec\n","[2020-04-21 08:33:08,270 INFO] Step 6800/ 7000; acc:  99.26; ppl:  1.03; xent: 0.03; lr: 0.00100; 10765/6688 tok/s;    422 sec\n","[2020-04-21 08:33:11,266 INFO] Step 6850/ 7000; acc:  98.57; ppl:  1.07; xent: 0.06; lr: 0.00100; 9703/6958 tok/s;    425 sec\n","[2020-04-21 08:33:14,064 INFO] Step 6900/ 7000; acc:  99.10; ppl:  1.04; xent: 0.04; lr: 0.00100; 10382/6905 tok/s;    428 sec\n","[2020-04-21 08:33:17,244 INFO] Step 6950/ 7000; acc:  99.15; ppl:  1.03; xent: 0.03; lr: 0.00100; 10808/7220 tok/s;    431 sec\n","[2020-04-21 08:33:20,080 INFO] Step 7000/ 7000; acc:  99.09; ppl:  1.04; xent: 0.04; lr: 0.00100; 10406/7010 tok/s;    434 sec\n","[2020-04-21 08:33:20,083 INFO] Saving checkpoint trained-model_step_7000.pt\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bqGACHuWt52G","colab_type":"text"},"source":["![Lemmatizer model](https://github.com/TurkuNLP/Deep_Learning_in_LangTech_course/raw/master/figs/lemmatizer-model.png)"]},{"cell_type":"code","metadata":{"id":"osNuwMu-euZv","colab_type":"code","outputId":"9fa56c1d-ae66-493f-e6ab-e3ce10e068c8","colab":{"base_uri":"https://localhost:8080/","height":421}},"source":["# predict \n","!cat dev.input | head -20 > small_test.input ; onmt_translate -model trained-model_step_7000.pt -src small_test.input -output pred.txt -replace_unk ; paste -d\"\\t\" small_test.input pred.txt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[2020-04-20 21:15:38,406 INFO] Translating shard 0.\n","PRED AVG SCORE: -0.0221, PRED PPL: 1.0223\n","T h e PROPN Case=Nom Number=Sing\tT h e\n","G a r d e n PROPN Case=Nom Number=Sing\tG a r d e n\n","C o l l e c t i o n PROPN Case=Nom Number=Sing\tC o l l e c t i o n\n","b y PROPN Case=Nom Number=Sing\tb y\n","H & M PROPN Abbr=Yes Case=Nom Number=Sing\tH & M\n","V i i k o n l o p u n NOUN Case=Gen Derivation=U Number=Sing\tv i i k o n # l o p p u\n","p y ö r i t y s NOUN Case=Nom Number=Sing\tp y ö r i t y s\n","a l k o i VERB Mood=Ind Number=Sing Person=3 Tense=Past VerbForm=Fin Voice=Act\ta l k a a\n","H & M : n PROPN Abbr=Yes Case=Gen Number=Sing\tH & M\n","j ä r j e s t ä m ä l l ä VERB Case=Ade Degree=Pos Number=Sing PartForm=Agt VerbForm=Part Voice=Act\tj ä r j e s t ä ä\n","b l o g g a a j a b r u n s s i l l a NOUN Case=Ade Number=Sing\tb l o g g a a j a # b r u n s s i\n","H e l s i n g i s s ä PROPN Case=Ine Number=Sing\tH e l s i n k i\n",". PUNCT _\t.\n","S h o w r o o m i l l a PROPN Case=Ade Number=Sing\tS h o w r o o m i\n","e s i t e l t i i n VERB Mood=Ind Tense=Past VerbForm=Fin Voice=Pass\te s i t e l l ä\n","u u s i ADJ Case=Nom Degree=Pos Number=Sing\tu u s i\n","T h e PROPN Case=Nom Number=Sing\tT h e\n","G a r d e n PROPN Case=Nom Number=Sing\tG a r d e n\n","C o l l e c t i o n PROPN Case=Nom Number=Sing\tC o l l e c t i o n\n","j a CCONJ _\tj a\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nHrW7jCBr9_u","colab_type":"code","outputId":"f716c94b-eaad-43ad-d440-706e063221b1","colab":{"base_uri":"https://localhost:8080/","height":127}},"source":["# ambiguous words\n","!echo \"k o i r a s t a NOUN Case=Ela Number=Sing\" > tmp.tmp ; onmt_translate -model trained-model_step_7000.pt -src tmp.tmp -output pred.txt -replace_unk ; cat pred.txt | perl -pe 's/ //g'\n","!echo \"k o i r a s t a NOUN Case=Par Number=Sing\" > tmp.tmp ; onmt_translate -model trained-model_step_7000.pt -src tmp.tmp -output pred.txt -replace_unk ; cat pred.txt | perl -pe 's/ //g'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[2020-04-20 21:15:42,854 INFO] Translating shard 0.\n","PRED AVG SCORE: -0.0007, PRED PPL: 1.0007\n","koira\n","[2020-04-20 21:15:47,637 INFO] Translating shard 0.\n","PRED AVG SCORE: -0.0073, PRED PPL: 1.0073\n","koiras\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BlnhSki3P_Aq","colab_type":"text"},"source":["## Fully trained models available at https://turkunlp.org/Turku-neural-parser-pipeline/\n","  - Includes trained models for segmentation, part-of-speech and morphological tagging, lemmatization, and syntactic parsing\n","  - Over 50 languages supported\n","  - Finnish lemmatization accuracy: ~95%\n","  - Demo: http://bionlp-www.utu.fi/parser_demo/"]},{"cell_type":"markdown","metadata":{"id":"KyxpvscB5OMM","colab_type":"text"},"source":["# Word inflection model\n","- The model can also be trained 'the other way around'\n","    - Generate the inflected word from the given lemma and desired inflection (for example Case information)\n","    - (Very handy for a language learner! 😉)\n","\n","- We just need to modify the data preparation code\n","  - Input: lemma + morphological features\n","  - Output: inflected word\n","\n","- Used in search engines, document classification\n","\n"]},{"cell_type":"code","metadata":{"id":"WpgxiKgF74Z8","colab_type":"code","outputId":"03590d67-eefa-45da-ddb2-19f7cf113620","colab":{"base_uri":"https://localhost:8080/","height":111},"executionInfo":{"status":"ok","timestamp":1587458186176,"user_tz":-180,"elapsed":1904,"user":{"displayName":"Hanna Kitti","photoUrl":"","userId":"01511785927733709431"}}},"source":["def prepare_inflection_dataset(fname):\n","  # create input and output sequences (in text format)\n","  data = []\n","  with open(fname, \"rt\", encoding=\"utf-8\") as f:\n","    for comments, sent in read_conllu(f):\n","      for token in sent:\n","        if \"-\" in token[ID] or \".\" in token[ID]: # multiword token or null node --> skip\n","          continue\n","        if token[UPOS] != \"NOUN\": # let's take only nouns to fasten training\n","          continue\n","        input_chars = \" \".join(c for c in token[LEMMA]) # input is lemma + morphological features\n","        features = \" \".join([token[UPOS]] + token[FEATS].split(\"|\")) # add morphological features\n","        input_chars = input_chars + \" \" + features\n","        output_chars = \" \".join(c for c in token[FORM])\n","        data.append((input_chars, output_chars))\n","  return data\n","\n","\n","# transform data\n","train_data = prepare_inflection_dataset(\"fi_tdt-ud-train.conllu\")\n","import random\n","random.shuffle(train_data)\n","\n","dev_data = prepare_inflection_dataset(\"fi_tdt-ud-dev.conllu\")\n","print(\"First train examples:\", train_data[:5])\n","print(\"Number of training examples:\", len(train_data))\n","print(\"\\nNumber of development examples:\", len(dev_data))\n","\n","save_data(train_data, dev_data)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["First train examples: [('h a k i j a # m ä ä r ä NOUN Case=Ela Number=Sing', 'h a k i j a m ä ä r ä s t ä'), ('l o s o # p e r s e NOUN Case=Nom Number=Sing', 'l o s o p e r s e'), ('t o i m e e n # t u l o NOUN Case=Nom Number=Sing', 't o i m e e n t u l o'), ('i n n o s t u s NOUN Case=Nom Number=Sing', 'i n n o s t u s'), ('p i k k u # l i n t u NOUN Case=Nom Number=Sing', 'p i k k u l i n t u')]\n","Number of training examples: 45588\n","\n","Number of development examples: 5103\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CQvbPI3nH89O","colab_type":"code","outputId":"c3088771-e34d-418d-a825-f96cb867c3e9","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1587458727569,"user_tz":-180,"elapsed":430590,"user":{"displayName":"Hanna Kitti","photoUrl":"","userId":"01511785927733709431"}}},"source":["# run preprocessing, this handles vectorization etc.\n","!onmt_preprocess -train_src train.input -train_tgt train.output -valid_src dev.input -valid_tgt dev.output -save_data preprocessed-data -src_words_min_frequency 5 -tgt_words_min_frequency 5 -overwrite\n","\n","# train model\n","\n","BATCH_SIZE = 64\n","LEARNING_RATE = 0.001\n","OPTIMIZER = \"adam\"\n","ENCODER = \"brnn\"\n","TRAIN_STEPS = 5000 #step is one minibatch, so train for 5000 minibatches\n","\n","print(\"How many epochs:\", (TRAIN_STEPS*BATCH_SIZE)/len(train_data))\n","\n","!onmt_train -data preprocessed-data -save_model trained-model -gpu_ranks 0 -learning_rate {LEARNING_RATE} -batch_size {BATCH_SIZE} -optim {OPTIMIZER} -train_steps {TRAIN_STEPS} -save_checkpoint_steps {TRAIN_STEPS} -encoder_type {ENCODER}"],"execution_count":12,"outputs":[{"output_type":"stream","text":["[2020-04-21 08:38:20,586 INFO] Extracting features...\n","[2020-04-21 08:38:20,586 INFO]  * number of source features: 0.\n","[2020-04-21 08:38:20,586 INFO]  * number of target features: 0.\n","[2020-04-21 08:38:20,586 INFO] Building `Fields` object...\n","[2020-04-21 08:38:20,586 INFO] Building & saving training data...\n","[2020-04-21 08:38:20,587 WARNING] Shards for corpus train already exist, will be overwritten because `-overwrite` option is set.\n","[2020-04-21 08:38:20,593 WARNING] Overwrite shards for corpus None\n","[2020-04-21 08:38:20,645 INFO] Building shard 0.\n","[2020-04-21 08:38:22,120 INFO]  * saving 0th train data shard to preprocessed-data.train.0.pt.\n","[2020-04-21 08:38:23,201 INFO]  * tgt vocab size: 76.\n","[2020-04-21 08:38:23,202 INFO]  * src vocab size: 112.\n","[2020-04-21 08:38:23,205 INFO] Building & saving validation data...\n","[2020-04-21 08:38:23,205 WARNING] Shards for corpus valid already exist, will be overwritten because `-overwrite` option is set.\n","[2020-04-21 08:38:23,209 WARNING] Overwrite shards for corpus None\n","[2020-04-21 08:38:23,225 INFO] Building shard 0.\n","[2020-04-21 08:38:23,332 INFO]  * saving 0th valid data shard to preprocessed-data.valid.0.pt.\n","How many epochs: 7.019391067824866\n","[2020-04-21 08:38:26,478 INFO]  * src vocab size = 112\n","[2020-04-21 08:38:26,478 INFO]  * tgt vocab size = 76\n","[2020-04-21 08:38:26,479 INFO] Building model...\n","[2020-04-21 08:38:28,836 INFO] NMTModel(\n","  (encoder): RNNEncoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(112, 500, padding_idx=1)\n","        )\n","      )\n","    )\n","    (rnn): LSTM(500, 250, num_layers=2, dropout=0.3, bidirectional=True)\n","  )\n","  (decoder): InputFeedRNNDecoder(\n","    (embeddings): Embeddings(\n","      (make_embedding): Sequential(\n","        (emb_luts): Elementwise(\n","          (0): Embedding(76, 500, padding_idx=1)\n","        )\n","      )\n","    )\n","    (dropout): Dropout(p=0.3, inplace=False)\n","    (rnn): StackedLSTM(\n","      (dropout): Dropout(p=0.3, inplace=False)\n","      (layers): ModuleList(\n","        (0): LSTMCell(1000, 500)\n","        (1): LSTMCell(500, 500)\n","      )\n","    )\n","    (attn): GlobalAttention(\n","      (linear_in): Linear(in_features=500, out_features=500, bias=False)\n","      (linear_out): Linear(in_features=1000, out_features=500, bias=False)\n","    )\n","  )\n","  (generator): Sequential(\n","    (0): Linear(in_features=500, out_features=76, bias=True)\n","    (1): Cast()\n","    (2): LogSoftmax()\n","  )\n",")\n","[2020-04-21 08:38:28,837 INFO] encoder: 3064000\n","[2020-04-21 08:38:28,837 INFO] decoder: 5834076\n","[2020-04-21 08:38:28,837 INFO] * number of parameters: 8898076\n","[2020-04-21 08:38:28,838 INFO] Starting training on GPU: [0]\n","[2020-04-21 08:38:28,838 INFO] Start training loop and validate every 10000 steps...\n","[2020-04-21 08:38:28,839 INFO] Loading dataset from preprocessed-data.train.0.pt\n","[2020-04-21 08:38:29,128 INFO] number of examples: 45588\n","[2020-04-21 08:38:33,621 INFO] Step 50/ 5000; acc:  18.44; ppl: 17.71; xent: 2.87; lr: 0.00100; 7910/7543 tok/s;      5 sec\n","[2020-04-21 08:38:37,749 INFO] Step 100/ 5000; acc:  42.62; ppl:  7.09; xent: 1.96; lr: 0.00100; 8914/8631 tok/s;      9 sec\n","[2020-04-21 08:38:42,185 INFO] Step 150/ 5000; acc:  60.46; ppl:  3.99; xent: 1.38; lr: 0.00100; 8894/8432 tok/s;     13 sec\n","[2020-04-21 08:38:46,053 INFO] Step 200/ 5000; acc:  75.72; ppl:  2.39; xent: 0.87; lr: 0.00100; 8685/8290 tok/s;     17 sec\n","[2020-04-21 08:38:50,221 INFO] Step 250/ 5000; acc:  78.77; ppl:  2.22; xent: 0.80; lr: 0.00100; 8599/8074 tok/s;     21 sec\n","[2020-04-21 08:38:54,329 INFO] Step 300/ 5000; acc:  87.45; ppl:  1.62; xent: 0.48; lr: 0.00100; 9159/8243 tok/s;     25 sec\n","[2020-04-21 08:38:58,592 INFO] Step 350/ 5000; acc:  85.77; ppl:  1.82; xent: 0.60; lr: 0.00100; 8551/8545 tok/s;     30 sec\n","[2020-04-21 08:39:03,031 INFO] Step 400/ 5000; acc:  90.91; ppl:  1.47; xent: 0.39; lr: 0.00100; 9122/8428 tok/s;     34 sec\n","[2020-04-21 08:39:07,017 INFO] Step 450/ 5000; acc:  88.66; ppl:  1.70; xent: 0.53; lr: 0.00100; 8842/8138 tok/s;     38 sec\n","[2020-04-21 08:39:11,057 INFO] Step 500/ 5000; acc:  93.46; ppl:  1.35; xent: 0.30; lr: 0.00100; 9115/8377 tok/s;     42 sec\n","[2020-04-21 08:39:15,248 INFO] Step 550/ 5000; acc:  94.22; ppl:  1.28; xent: 0.25; lr: 0.00100; 9270/8544 tok/s;     46 sec\n","[2020-04-21 08:39:19,106 INFO] Step 600/ 5000; acc:  94.50; ppl:  1.25; xent: 0.22; lr: 0.00100; 8875/8347 tok/s;     50 sec\n","[2020-04-21 08:39:23,111 INFO] Step 650/ 5000; acc:  93.84; ppl:  1.33; xent: 0.29; lr: 0.00100; 8932/8167 tok/s;     54 sec\n","[2020-04-21 08:39:27,142 INFO] Step 700/ 5000; acc:  95.31; ppl:  1.23; xent: 0.21; lr: 0.00100; 8994/8429 tok/s;     58 sec\n","[2020-04-21 08:39:28,332 INFO] Loading dataset from preprocessed-data.train.0.pt\n","[2020-04-21 08:39:28,793 INFO] number of examples: 45588\n","[2020-04-21 08:39:31,959 INFO] Step 750/ 5000; acc:  96.30; ppl:  1.17; xent: 0.15; lr: 0.00100; 7898/7327 tok/s;     63 sec\n","[2020-04-21 08:39:36,210 INFO] Step 800/ 5000; acc:  96.32; ppl:  1.17; xent: 0.16; lr: 0.00100; 9019/8668 tok/s;     67 sec\n","[2020-04-21 08:39:40,481 INFO] Step 850/ 5000; acc:  94.74; ppl:  1.30; xent: 0.26; lr: 0.00100; 8757/8471 tok/s;     72 sec\n","[2020-04-21 08:39:44,433 INFO] Step 900/ 5000; acc:  96.99; ppl:  1.14; xent: 0.13; lr: 0.00100; 8858/8389 tok/s;     76 sec\n","[2020-04-21 08:39:48,684 INFO] Step 950/ 5000; acc:  96.21; ppl:  1.19; xent: 0.17; lr: 0.00100; 8605/8195 tok/s;     80 sec\n","[2020-04-21 08:39:52,638 INFO] Step 1000/ 5000; acc:  96.60; ppl:  1.16; xent: 0.15; lr: 0.00100; 8986/8165 tok/s;     84 sec\n","[2020-04-21 08:39:57,004 INFO] Step 1050/ 5000; acc:  96.65; ppl:  1.16; xent: 0.15; lr: 0.00100; 8791/8548 tok/s;     88 sec\n","[2020-04-21 08:40:01,218 INFO] Step 1100/ 5000; acc:  97.40; ppl:  1.12; xent: 0.11; lr: 0.00100; 9084/8528 tok/s;     92 sec\n","[2020-04-21 08:40:05,467 INFO] Step 1150/ 5000; acc:  95.46; ppl:  1.24; xent: 0.22; lr: 0.00100; 8862/8164 tok/s;     97 sec\n","[2020-04-21 08:40:09,318 INFO] Step 1200/ 5000; acc:  96.86; ppl:  1.15; xent: 0.14; lr: 0.00100; 9003/8259 tok/s;    100 sec\n","[2020-04-21 08:40:13,552 INFO] Step 1250/ 5000; acc:  97.41; ppl:  1.12; xent: 0.11; lr: 0.00100; 9260/8530 tok/s;    105 sec\n","[2020-04-21 08:40:17,497 INFO] Step 1300/ 5000; acc:  97.58; ppl:  1.10; xent: 0.09; lr: 0.00100; 8989/8379 tok/s;    109 sec\n","[2020-04-21 08:40:21,507 INFO] Step 1350/ 5000; acc:  97.30; ppl:  1.13; xent: 0.12; lr: 0.00100; 8984/8192 tok/s;    113 sec\n","[2020-04-21 08:40:25,438 INFO] Step 1400/ 5000; acc:  97.50; ppl:  1.11; xent: 0.10; lr: 0.00100; 8858/8447 tok/s;    117 sec\n","[2020-04-21 08:40:27,786 INFO] Loading dataset from preprocessed-data.train.0.pt\n","[2020-04-21 08:40:28,180 INFO] number of examples: 45588\n","[2020-04-21 08:40:30,280 INFO] Step 1450/ 5000; acc:  96.47; ppl:  1.21; xent: 0.19; lr: 0.00100; 8034/7317 tok/s;    121 sec\n","[2020-04-21 08:40:34,543 INFO] Step 1500/ 5000; acc:  97.98; ppl:  1.09; xent: 0.08; lr: 0.00100; 9008/8676 tok/s;    126 sec\n","[2020-04-21 08:40:38,850 INFO] Step 1550/ 5000; acc:  97.42; ppl:  1.13; xent: 0.12; lr: 0.00100; 8759/8536 tok/s;    130 sec\n","[2020-04-21 08:40:42,915 INFO] Step 1600/ 5000; acc:  97.95; ppl:  1.09; xent: 0.09; lr: 0.00100; 8943/8460 tok/s;    134 sec\n","[2020-04-21 08:40:47,007 INFO] Step 1650/ 5000; acc:  97.62; ppl:  1.11; xent: 0.11; lr: 0.00100; 8562/8076 tok/s;    138 sec\n","[2020-04-21 08:40:51,042 INFO] Step 1700/ 5000; acc:  97.69; ppl:  1.11; xent: 0.11; lr: 0.00100; 8968/8381 tok/s;    142 sec\n","[2020-04-21 08:40:55,320 INFO] Step 1750/ 5000; acc:  97.41; ppl:  1.13; xent: 0.12; lr: 0.00100; 8878/8401 tok/s;    146 sec\n","[2020-04-21 08:40:59,446 INFO] Step 1800/ 5000; acc:  98.08; ppl:  1.09; xent: 0.09; lr: 0.00100; 8905/8511 tok/s;    151 sec\n","[2020-04-21 08:41:03,977 INFO] Step 1850/ 5000; acc:  96.03; ppl:  1.26; xent: 0.23; lr: 0.00100; 9046/8309 tok/s;    155 sec\n","[2020-04-21 08:41:07,679 INFO] Step 1900/ 5000; acc:  97.98; ppl:  1.08; xent: 0.08; lr: 0.00100; 8921/8271 tok/s;    159 sec\n","[2020-04-21 08:41:11,924 INFO] Step 1950/ 5000; acc:  97.81; ppl:  1.10; xent: 0.09; lr: 0.00100; 9173/8449 tok/s;    163 sec\n","[2020-04-21 08:41:15,944 INFO] Step 2000/ 5000; acc:  97.93; ppl:  1.08; xent: 0.08; lr: 0.00100; 9185/8409 tok/s;    167 sec\n","[2020-04-21 08:41:19,820 INFO] Step 2050/ 5000; acc:  97.89; ppl:  1.10; xent: 0.09; lr: 0.00100; 8772/8191 tok/s;    171 sec\n","[2020-04-21 08:41:23,824 INFO] Step 2100/ 5000; acc:  97.54; ppl:  1.13; xent: 0.12; lr: 0.00100; 9044/8362 tok/s;    175 sec\n","[2020-04-21 08:41:27,180 INFO] Loading dataset from preprocessed-data.train.0.pt\n","[2020-04-21 08:41:27,598 INFO] number of examples: 45588\n","[2020-04-21 08:41:28,761 INFO] Step 2150/ 5000; acc:  97.68; ppl:  1.11; xent: 0.11; lr: 0.00100; 7931/7357 tok/s;    180 sec\n","[2020-04-21 08:41:32,822 INFO] Step 2200/ 5000; acc:  98.26; ppl:  1.07; xent: 0.07; lr: 0.00100; 8936/8571 tok/s;    184 sec\n","[2020-04-21 08:41:37,116 INFO] Step 2250/ 5000; acc:  97.83; ppl:  1.11; xent: 0.10; lr: 0.00100; 8892/8685 tok/s;    188 sec\n","[2020-04-21 08:41:41,253 INFO] Step 2300/ 5000; acc:  97.73; ppl:  1.12; xent: 0.11; lr: 0.00100; 9002/8441 tok/s;    192 sec\n","[2020-04-21 08:41:45,228 INFO] Step 2350/ 5000; acc:  97.87; ppl:  1.09; xent: 0.09; lr: 0.00100; 8804/8365 tok/s;    196 sec\n","[2020-04-21 08:41:49,430 INFO] Step 2400/ 5000; acc:  97.95; ppl:  1.10; xent: 0.10; lr: 0.00100; 8637/8100 tok/s;    201 sec\n","[2020-04-21 08:41:53,504 INFO] Step 2450/ 5000; acc:  97.95; ppl:  1.09; xent: 0.09; lr: 0.00100; 9018/8228 tok/s;    205 sec\n","[2020-04-21 08:41:57,805 INFO] Step 2500/ 5000; acc:  98.06; ppl:  1.09; xent: 0.09; lr: 0.00100; 8727/8621 tok/s;    209 sec\n","[2020-04-21 08:42:02,152 INFO] Step 2550/ 5000; acc:  97.92; ppl:  1.10; xent: 0.09; lr: 0.00100; 9072/8305 tok/s;    213 sec\n","[2020-04-21 08:42:06,049 INFO] Step 2600/ 5000; acc:  97.48; ppl:  1.14; xent: 0.13; lr: 0.00100; 8854/8297 tok/s;    217 sec\n","[2020-04-21 08:42:10,332 INFO] Step 2650/ 5000; acc:  98.15; ppl:  1.07; xent: 0.07; lr: 0.00100; 9315/8486 tok/s;    221 sec\n","[2020-04-21 08:42:14,390 INFO] Step 2700/ 5000; acc:  98.14; ppl:  1.07; xent: 0.07; lr: 0.00100; 9133/8404 tok/s;    226 sec\n","[2020-04-21 08:42:18,084 INFO] Step 2750/ 5000; acc:  97.99; ppl:  1.09; xent: 0.09; lr: 0.00100; 8657/8086 tok/s;    229 sec\n","[2020-04-21 08:42:22,282 INFO] Step 2800/ 5000; acc:  98.10; ppl:  1.08; xent: 0.08; lr: 0.00100; 9030/8333 tok/s;    233 sec\n","[2020-04-21 08:42:26,446 INFO] Step 2850/ 5000; acc:  97.75; ppl:  1.11; xent: 0.10; lr: 0.00100; 8898/8351 tok/s;    238 sec\n","[2020-04-21 08:42:26,627 INFO] Loading dataset from preprocessed-data.train.0.pt\n","[2020-04-21 08:42:27,012 INFO] number of examples: 45588\n","[2020-04-21 08:42:31,139 INFO] Step 2900/ 5000; acc:  98.22; ppl:  1.08; xent: 0.08; lr: 0.00100; 8059/7562 tok/s;    242 sec\n","[2020-04-21 08:42:35,290 INFO] Step 2950/ 5000; acc:  98.41; ppl:  1.07; xent: 0.06; lr: 0.00100; 8821/8611 tok/s;    246 sec\n","[2020-04-21 08:42:39,726 INFO] Step 3000/ 5000; acc:  97.81; ppl:  1.12; xent: 0.11; lr: 0.00100; 8951/8496 tok/s;    251 sec\n","[2020-04-21 08:42:43,564 INFO] Step 3050/ 5000; acc:  98.27; ppl:  1.07; xent: 0.07; lr: 0.00100; 8752/8337 tok/s;    255 sec\n","[2020-04-21 08:42:47,779 INFO] Step 3100/ 5000; acc:  98.13; ppl:  1.10; xent: 0.09; lr: 0.00100; 8640/8060 tok/s;    259 sec\n","[2020-04-21 08:42:51,830 INFO] Step 3150/ 5000; acc:  98.02; ppl:  1.08; xent: 0.08; lr: 0.00100; 9176/8283 tok/s;    263 sec\n","[2020-04-21 08:42:56,120 INFO] Step 3200/ 5000; acc:  98.15; ppl:  1.09; xent: 0.09; lr: 0.00100; 8559/8562 tok/s;    267 sec\n","[2020-04-21 08:43:00,395 INFO] Step 3250/ 5000; acc:  98.42; ppl:  1.07; xent: 0.06; lr: 0.00100; 9192/8476 tok/s;    272 sec\n","[2020-04-21 08:43:04,509 INFO] Step 3300/ 5000; acc:  97.62; ppl:  1.13; xent: 0.12; lr: 0.00100; 8813/8157 tok/s;    276 sec\n","[2020-04-21 08:43:08,560 INFO] Step 3350/ 5000; acc:  98.18; ppl:  1.07; xent: 0.07; lr: 0.00100; 9105/8368 tok/s;    280 sec\n","[2020-04-21 08:43:12,699 INFO] Step 3400/ 5000; acc:  98.35; ppl:  1.06; xent: 0.06; lr: 0.00100; 9248/8513 tok/s;    284 sec\n","[2020-04-21 08:43:16,617 INFO] Step 3450/ 5000; acc:  98.43; ppl:  1.06; xent: 0.06; lr: 0.00100; 8919/8399 tok/s;    288 sec\n","[2020-04-21 08:43:20,615 INFO] Step 3500/ 5000; acc:  98.26; ppl:  1.07; xent: 0.07; lr: 0.00100; 8915/8149 tok/s;    292 sec\n","[2020-04-21 08:43:24,640 INFO] Step 3550/ 5000; acc:  98.18; ppl:  1.08; xent: 0.08; lr: 0.00100; 8913/8362 tok/s;    296 sec\n","[2020-04-21 08:43:26,018 INFO] Loading dataset from preprocessed-data.train.0.pt\n","[2020-04-21 08:43:26,392 INFO] number of examples: 45588\n","[2020-04-21 08:43:29,443 INFO] Step 3600/ 5000; acc:  98.38; ppl:  1.07; xent: 0.07; lr: 0.00100; 8041/7443 tok/s;    301 sec\n","[2020-04-21 08:43:33,651 INFO] Step 3650/ 5000; acc:  98.51; ppl:  1.06; xent: 0.06; lr: 0.00100; 9048/8693 tok/s;    305 sec\n","[2020-04-21 08:43:37,828 INFO] Step 3700/ 5000; acc:  98.39; ppl:  1.06; xent: 0.06; lr: 0.00100; 8786/8484 tok/s;    309 sec\n","[2020-04-21 08:43:41,868 INFO] Step 3750/ 5000; acc:  98.55; ppl:  1.06; xent: 0.06; lr: 0.00100; 8904/8487 tok/s;    313 sec\n","[2020-04-21 08:43:46,111 INFO] Step 3800/ 5000; acc:  98.24; ppl:  1.08; xent: 0.08; lr: 0.00100; 8621/8149 tok/s;    317 sec\n","[2020-04-21 08:43:50,080 INFO] Step 3850/ 5000; acc:  98.05; ppl:  1.08; xent: 0.08; lr: 0.00100; 8952/8199 tok/s;    321 sec\n","[2020-04-21 08:43:54,427 INFO] Step 3900/ 5000; acc:  98.16; ppl:  1.09; xent: 0.08; lr: 0.00100; 8799/8556 tok/s;    326 sec\n","[2020-04-21 08:43:58,596 INFO] Step 3950/ 5000; acc:  98.42; ppl:  1.07; xent: 0.07; lr: 0.00100; 9090/8496 tok/s;    330 sec\n","[2020-04-21 08:44:02,879 INFO] Step 4000/ 5000; acc:  97.68; ppl:  1.13; xent: 0.12; lr: 0.00100; 8956/8203 tok/s;    334 sec\n","[2020-04-21 08:44:06,704 INFO] Step 4050/ 5000; acc:  98.27; ppl:  1.07; xent: 0.07; lr: 0.00100; 8931/8300 tok/s;    338 sec\n","[2020-04-21 08:44:10,944 INFO] Step 4100/ 5000; acc:  98.21; ppl:  1.07; xent: 0.07; lr: 0.00100; 9323/8533 tok/s;    342 sec\n","[2020-04-21 08:44:14,886 INFO] Step 4150/ 5000; acc:  98.20; ppl:  1.08; xent: 0.07; lr: 0.00100; 8963/8401 tok/s;    346 sec\n","[2020-04-21 08:44:18,872 INFO] Step 4200/ 5000; acc:  98.28; ppl:  1.07; xent: 0.07; lr: 0.00100; 8958/8161 tok/s;    350 sec\n","[2020-04-21 08:44:22,750 INFO] Step 4250/ 5000; acc:  98.55; ppl:  1.06; xent: 0.06; lr: 0.00100; 8895/8414 tok/s;    354 sec\n","[2020-04-21 08:44:25,309 INFO] Loading dataset from preprocessed-data.train.0.pt\n","[2020-04-21 08:44:25,820 INFO] number of examples: 45588\n","[2020-04-21 08:44:27,750 INFO] Step 4300/ 5000; acc:  98.12; ppl:  1.08; xent: 0.08; lr: 0.00100; 7884/7240 tok/s;    359 sec\n","[2020-04-21 08:44:31,993 INFO] Step 4350/ 5000; acc:  98.55; ppl:  1.06; xent: 0.06; lr: 0.00100; 8988/8625 tok/s;    363 sec\n","[2020-04-21 08:44:36,207 INFO] Step 4400/ 5000; acc:  98.51; ppl:  1.06; xent: 0.06; lr: 0.00100; 8832/8592 tok/s;    367 sec\n","[2020-04-21 08:44:40,258 INFO] Step 4450/ 5000; acc:  98.47; ppl:  1.07; xent: 0.07; lr: 0.00100; 8943/8498 tok/s;    371 sec\n","[2020-04-21 08:44:44,386 INFO] Step 4500/ 5000; acc:  98.21; ppl:  1.08; xent: 0.08; lr: 0.00100; 8611/8117 tok/s;    376 sec\n","[2020-04-21 08:44:48,452 INFO] Step 4550/ 5000; acc:  98.35; ppl:  1.07; xent: 0.07; lr: 0.00100; 9027/8398 tok/s;    380 sec\n","[2020-04-21 08:44:52,723 INFO] Step 4600/ 5000; acc:  98.03; ppl:  1.09; xent: 0.09; lr: 0.00100; 8921/8443 tok/s;    384 sec\n","[2020-04-21 08:44:56,834 INFO] Step 4650/ 5000; acc:  98.22; ppl:  1.08; xent: 0.08; lr: 0.00100; 8892/8512 tok/s;    388 sec\n","[2020-04-21 08:45:01,235 INFO] Step 4700/ 5000; acc:  97.81; ppl:  1.12; xent: 0.11; lr: 0.00100; 9080/8370 tok/s;    392 sec\n","[2020-04-21 08:45:05,053 INFO] Step 4750/ 5000; acc:  98.48; ppl:  1.06; xent: 0.06; lr: 0.00100; 8936/8317 tok/s;    396 sec\n","[2020-04-21 08:45:09,231 INFO] Step 4800/ 5000; acc:  98.30; ppl:  1.06; xent: 0.06; lr: 0.00100; 9287/8491 tok/s;    400 sec\n","[2020-04-21 08:45:13,220 INFO] Step 4850/ 5000; acc:  98.42; ppl:  1.06; xent: 0.06; lr: 0.00100; 9162/8422 tok/s;    404 sec\n","[2020-04-21 08:45:17,129 INFO] Step 4900/ 5000; acc:  98.32; ppl:  1.07; xent: 0.06; lr: 0.00100; 8863/8260 tok/s;    408 sec\n","[2020-04-21 08:45:21,109 INFO] Step 4950/ 5000; acc:  98.31; ppl:  1.08; xent: 0.08; lr: 0.00100; 9031/8387 tok/s;    412 sec\n","[2020-04-21 08:45:24,600 INFO] Loading dataset from preprocessed-data.train.0.pt\n","[2020-04-21 08:45:25,001 INFO] number of examples: 45588\n","[2020-04-21 08:45:26,036 INFO] Step 5000/ 5000; acc:  98.09; ppl:  1.09; xent: 0.09; lr: 0.00100; 8014/7404 tok/s;    417 sec\n","[2020-04-21 08:45:26,038 INFO] Saving checkpoint trained-model_step_5000.pt\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VjCIAXNzSTl2","colab_type":"text"},"source":["## Predict Inflections"]},{"cell_type":"code","metadata":{"id":"-589URYqSPee","colab_type":"code","outputId":"451853c2-c1c8-4903-87b6-a8cdabe85b40","colab":{"base_uri":"https://localhost:8080/","height":237}},"source":["!echo \"k i s s a NOUN Case=Ade Number=Sing\" > tmp.tmp ; onmt_translate -model trained-model_step_5000.pt -src tmp.tmp -output pred.txt ; cat pred.txt | perl -pe 's/ //g'\n","!echo \"t a l o NOUN Case=Ine Number=Sing\" > tmp.tmp ; onmt_translate -model trained-model_step_5000.pt -src tmp.tmp -output pred.txt ; cat pred.txt | perl -pe 's/ //g'\n","!echo \"t u l p p a a n i NOUN Case=Par Number=Plur\" > tmp.tmp ; onmt_translate -model trained-model_step_5000.pt -src tmp.tmp -output pred.txt ; cat pred.txt | perl -pe 's/ //g'\n","!echo \"t u l p p a a n i NOUN Case=Par Clitic=Kin Number=Plur\" > tmp.tmp ; onmt_translate -model trained-model_step_5000.pt -src tmp.tmp -output pred.txt ; cat pred.txt | perl -pe 's/ //g'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[2020-04-20 21:20:25,975 INFO] Translating shard 0.\n","PRED AVG SCORE: -0.0068, PRED PPL: 1.0069\n","kissalla\n","[2020-04-20 21:20:29,071 INFO] Translating shard 0.\n","PRED AVG SCORE: -0.0034, PRED PPL: 1.0034\n","talossa\n","[2020-04-20 21:20:33,170 INFO] Translating shard 0.\n","PRED AVG SCORE: -0.0124, PRED PPL: 1.0124\n","tulppaaneja\n","[2020-04-20 21:20:37,771 INFO] Translating shard 0.\n","PRED AVG SCORE: -0.0315, PRED PPL: 1.0320\n","tulppaanejakin\n"],"name":"stdout"}]}]}