{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "bowcls_demo_3.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HannaKi/Deep_Learning_in_LangTech_course/blob/master/language_classifier_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwOk0plcmZez",
        "colab_type": "text"
      },
      "source": [
        "In the data package , the directory language_identification contains data for 5 languages. Based on this data\n",
        "* Train an SVM classifier for language recognition between these 5 languages.\n",
        "  * Kun regressioalgoritmi tekee luokittelun, jokaista luokkaa kohden tehdään oma luokittelija (\"Onko englantia? Kyllä/ei\") --> viisi decision boundaryä\n",
        "* Implement this same classifier using a simple NN\n",
        "* Compare the results you get with NN and SVM? Focus on experimenting with the various parameters of learning (learning rate, optimizer, etc)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwuacC9wl6L5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reading the data in makes sense to structure a little bit\n",
        "# ratkaise, miten kansio tuodaan omasta GitHubista!\n",
        "# toimii myös luomalla Colabiin kansion (tässä nimeltä \"texts\"), \n",
        "# jonne tiedostot raahaa (kansio katoaa, kun ajo päättyy)\n",
        "\n",
        "import random\n",
        "\n",
        "def read_data_one_lang(lang,part):\n",
        "    \"\"\"Reads one file for one language. Returns data in the form of pairs of (lang,line)\"\"\"\n",
        "    filename=\"texts/{}_{}.txt\".format(lang,part)\n",
        "    result=[] #this will be the list of pairs (lang,line)\n",
        "    with open(filename) as f:\n",
        "        for line in f:\n",
        "            line=line.strip()\n",
        "            result.append((lang,line)) \n",
        "    return result\n",
        "\n",
        "\n",
        "def read_data_all_langs(part):\n",
        "    \"\"\"Reads train, test or dev data for all languages. part can be train, test, or devel\"\"\"\n",
        "    data=[]\n",
        "    for lang in (\"en\",\"es\",\"et\",\"fi\",\"pt\"):\n",
        "        pairs=read_data_one_lang(lang,part)\n",
        "        data.extend(pairs) #just add these lines to the end\n",
        "    #...done\n",
        "    #but now they come in the order of languages\n",
        "    #we really must scramble these!\n",
        "    random.shuffle(data)\n",
        "    \n",
        "    #let's yet separate the labels and lines, we will need that anyway\n",
        "    labels=[label for label,line in data]\n",
        "    lines=[line for label,line in data]\n",
        "    return labels,lines\n",
        "\n",
        "labels_train, lines_train=read_data_all_langs(\"train\") # train and test data splitting already done!\n",
        "labels_dev,lines_dev=read_data_all_langs(\"devel\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP6vO5awPFGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "d7625be3-1ffb-4ed4-fa9a-7db40bd37e3a"
      },
      "source": [
        "for label,line in zip(labels_train[:5],lines_train[:5]):\n",
        "    print(label,\"   \",line[:30],\"...\")\n",
        "\n",
        "print(labels_train[0], lines_train[0])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "es     La acumulación de dicha sustan ...\n",
            "pt     Se outros já por lá andavam, f ...\n",
            "en     <<Alberta Transmission Access  ...\n",
            "es     Esta se inició con un antinatu ...\n",
            "fi     Sumuisena syysaamuna äiti polt ...\n",
            "es La acumulación de dicha sustancia en los tejidos del de el cuerpo puede causar un daño severo al a el sistema nervioso central de los niños pequeños.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DN1szyCVLlXc",
        "colab_type": "text"
      },
      "source": [
        "# Reminder\n",
        "\n",
        "Feature matrix has row for each document"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfVT4fZOl6MN",
        "colab_type": "code",
        "outputId": "438ea365-7986-40d1-b04d-96bb70f3bb9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import sklearn.svm\n",
        "\n",
        "vectorizer = CountVectorizer(max_features=100000, binary=True, ngram_range=(1,1))\n",
        "\n",
        "feature_matrix_train = vectorizer.fit_transform(lines_train) \n",
        "# .fit_transform: Learn the vocabulary dictionary and return term-document matrix.\n",
        "feature_matrix_dev = vectorizer.transform(lines_dev)\n",
        "# .transform: Transform documents to document-term matrix.\n",
        "\n",
        "# print(vectorizer.get_feature_names()) # Words (or ngrams) in learned vocabulary, a HUGE list!\n",
        "print(\"Number of rows (documens) and unique ngrams in feature matrix\")\n",
        "print(feature_matrix_train.shape) \n",
        "print()\n",
        "print(\"Since most of the texts only use a limited amonut of words (ngrams) in the vocabulary, feature matrix is sparse!\")\n",
        "print(feature_matrix_train.toarray())"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of rows (documens) and unique ngrams in feature matrix\n",
            "(5000, 28620)\n",
            "\n",
            "Since most of the texts only use a limited amonut of words (ngrams) in the vocabulary, feature matrix is sparse!\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjEZcvrqLd6T",
        "colab_type": "text"
      },
      "source": [
        "# Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I09AyZhsLcfu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "55b872ca-d711-4862-abe1-cde545d3e160"
      },
      "source": [
        "for C in (0.001,0.01,0.1,1,10,100):\n",
        "    classifier =  sklearn.svm.LinearSVC(C=C)\n",
        "    classifier.fit(feature_matrix_train, labels_train)\n",
        "    print(\"C=\",C,\"     \",classifier.score(feature_matrix_dev, labels_dev))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C= 0.001       0.8758\n",
            "C= 0.01       0.9144\n",
            "C= 0.1       0.933\n",
            "C= 1       0.9302\n",
            "C= 10       0.9102\n",
            "C= 100       0.8728\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssCwTZxCl6Mc",
        "colab_type": "text"
      },
      "source": [
        "* 93% accuracy!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF3JQwVsWBlT",
        "colab_type": "text"
      },
      "source": [
        "# NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djgk8GjZceOl",
        "colab_type": "text"
      },
      "source": [
        "For NN we need to encode each class to numeric value.\n",
        " * Remember[ difference between encoding vs. one hot encoding](https://https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZojDVNIUWBGM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "f76871b2-556b-4b2d-b076-1734ab37dd24"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder() #Turns class labels into integers\n",
        "\n",
        "class_numbers = label_encoder.fit_transform(labels_train)\n",
        "\n",
        "print(class_numbers)\n",
        "\n",
        "print(\"class_numbers shape=\",class_numbers.shape)\n",
        "print(\"class labels\",label_encoder.classes_) #this will let us translate back from indices to labels"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 4 0 ... 0 3 4]\n",
            "class_numbers shape= (5000,)\n",
            "class labels ['en' 'es' 'et' 'fi' 'pt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plicePXSXTGe",
        "colab_type": "text"
      },
      "source": [
        "* Are words actually a good source of features?\n",
        "* Let us try with character n-grams instead of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA79fOkIl6Mg",
        "colab_type": "code",
        "outputId": "90129870-cc61-476d-b810-2305dfa114ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "vectorizer = CountVectorizer(max_features=100000, binary=True,\n",
        "                           ngram_range=(1,3), analyzer=\"char_wb\")\n",
        "feature_matrix_train=vectorizer.fit_transform(lines_train)\n",
        "feature_matrix_dev=vectorizer.transform(lines_dev)\n",
        "\n",
        "# print(vectorizer.get_feature_names()) # Words (or ngrams) in learned vocabulary, a HUGE list!\n",
        "print(\"Number of rows (documens) and unique ngrams in feature matrix\")\n",
        "print(feature_matrix_train.shape) \n",
        "print()\n",
        "print(\"Since most of the texts only use a limited amonut of words (ngrams) in the vocabulary, feature matrix is sparse!\")\n",
        "print(feature_matrix_train.toarray())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of rows (documens) and unique ngrams in feature matrix\n",
            "(5000, 17671)\n",
            "\n",
            "Since most of the texts only use a limited amonut of words (ngrams) in the vocabulary, feature matrix is sparse!\n",
            "[[1 1 1 ... 0 0 0]\n",
            " [1 0 0 ... 0 0 0]\n",
            " [1 0 0 ... 0 0 0]\n",
            " ...\n",
            " [1 0 0 ... 0 0 0]\n",
            " [1 1 1 ... 0 0 0]\n",
            " [1 0 0 ... 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c_iHzyeXKVI",
        "colab_type": "text"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uay1wpUJVPPE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "af7f8157-1fed-482f-e378-756aafe6fe56"
      },
      "source": [
        "for C in (0.001,0.01,0.1,1,10,100):\n",
        "    classifier=sklearn.svm.LinearSVC(C=C)\n",
        "    classifier.fit(feature_matrix_train, labels_train)\n",
        "    print(\"C=\",C,\"     \",classifier.score(feature_matrix_dev, labels_dev))\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C= 0.001       0.9762\n",
            "C= 0.01       0.9778\n",
            "C= 0.1       0.9732\n",
            "C= 1       0.9726\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "C= 10       0.9726\n",
            "C= 100       0.9724\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz-iDGAql6Mr",
        "colab_type": "text"
      },
      "source": [
        "Now, that's quite a bit better!"
      ]
    }
  ]
}