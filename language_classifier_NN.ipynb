{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "bowcls_demo_3.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwOk0plcmZez",
        "colab_type": "text"
      },
      "source": [
        "In the data package , the directory language_identification contains data for 5 languages. Based on this data, train an SVM classifier for language recognition between these 5 languages.\n",
        "* kun regressioalgoritmi tekee luokittelun, jokaista luokkaa kohden tehdään oma luokittelija (\"Onko englantia? Kyllä/ei\") --> viisi decision boundaryä"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwuacC9wl6L5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "532ab0f2-10c3-4119-82f6-c882ccb35a1c"
      },
      "source": [
        "# Reading the data in makes sense to structure a little bit\n",
        "# ratkaise, miten kansi tuodaan omasta GitHubista!\n",
        "# toimii myös luomalla Colabiin kansion (tässä nimeltä \"texts\"), \n",
        "# jonne tiedostot raahaa (kansio katoaa, kun ajo päättyy)\n",
        "\n",
        "import random\n",
        "\n",
        "def read_data_one_lang(lang,part):\n",
        "    \"\"\"Reads one file for one language. Returns data in the form of pairs of (lang,line)\"\"\"\n",
        "    filename=\"texts/{}_{}.txt\".format(lang,part)\n",
        "    result=[] #this will be the list of pairs (lang,line)\n",
        "    with open(filename) as f:\n",
        "        for line in f:\n",
        "            line=line.strip()\n",
        "            result.append((lang,line)) \n",
        "    return result\n",
        "\n",
        "\n",
        "def read_data_all_langs(part):\n",
        "    \"\"\"Reads train, test or dev data for all languages. part can be train, test, or devel\"\"\"\n",
        "    data=[]\n",
        "    for lang in (\"en\",\"es\",\"et\",\"fi\",\"pt\"):\n",
        "        pairs=read_data_one_lang(lang,part)\n",
        "        data.extend(pairs) #just add these lines to the end\n",
        "    #...done\n",
        "    #but now they come in the order of languages\n",
        "    #we really must scramble these!\n",
        "    random.shuffle(data)\n",
        "    \n",
        "    #let's yet separate the labels and lines, we will need that anyway\n",
        "    labels=[label for label,line in data]\n",
        "    lines=[line for label,line in data]\n",
        "    return labels,lines\n",
        "\n",
        "labels_train,lines_train=read_data_all_langs(\"train\")\n",
        "labels_dev,lines_dev=read_data_all_langs(\"devel\")\n",
        "for label,line in zip(labels_train[:5],lines_train[:5]):\n",
        "    print(label,\"   \",line[:30],\"...\")\n",
        "#and beyond this point, exactly same code is applicable as before"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fi     Pakko laittaa tämä toinenkin a ...\n",
            "et     Milovan Djilas kinnitab oma ra ...\n",
            "es     Con Pablo Mackenna como invita ...\n",
            "fi     Hän kuitenkin toivoi, että rau ...\n",
            "es     Este grupo priorizaba el reagr ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfVT4fZOl6MN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "fc67141d-11a1-461f-b76d-a73b636337f7"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import sklearn.svm\n",
        "\n",
        "vectorizer=CountVectorizer(max_features=100000,binary=True,ngram_range=(1,1))\n",
        "feature_matrix_train=vectorizer.fit_transform(lines_train)\n",
        "feature_matrix_dev=vectorizer.transform(lines_dev)\n",
        "\n",
        "for C in (0.001,0.01,0.1,1,10,100):\n",
        "    classifier=sklearn.svm.LinearSVC(C=C)\n",
        "    classifier.fit(feature_matrix_train, labels_train)\n",
        "    print(\"C=\",C,\"     \",classifier.score(feature_matrix_dev, labels_dev))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C= 0.001       0.8758\n",
            "C= 0.01       0.9144\n",
            "C= 0.1       0.933\n",
            "C= 1       0.9302\n",
            "C= 10       0.9102\n",
            "C= 100       0.8726\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssCwTZxCl6Mc",
        "colab_type": "text"
      },
      "source": [
        "* 93% is now that great!\n",
        "* Are words actually a good source of features?\n",
        "* Let us try with character n-grams instead of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA79fOkIl6Mg",
        "colab_type": "code",
        "colab": {},
        "outputId": "d92eca13-7959-4af7-d577-65fc364bac28"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import sklearn.svm\n",
        "\n",
        "vectorizer=CountVectorizer(max_features=100000,binary=True,\n",
        "                           ngram_range=(1,3),analyzer=\"char_wb\")\n",
        "feature_matrix_train=vectorizer.fit_transform(lines_train)\n",
        "feature_matrix_dev=vectorizer.transform(lines_dev)\n",
        "\n",
        "for C in (0.001,0.01,0.1,1,10,100):\n",
        "    classifier=sklearn.svm.LinearSVC(C=C)\n",
        "    classifier.fit(feature_matrix_train, labels_train)\n",
        "    print(\"C=\",C,\"     \",classifier.score(feature_matrix_dev, labels_dev))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C= 0.001       0.9762\n",
            "C= 0.01       0.9778\n",
            "C= 0.1       0.9732\n",
            "C= 1       0.9726\n",
            "C= 10       0.9726\n",
            "C= 100       0.9724\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz-iDGAql6Mr",
        "colab_type": "text"
      },
      "source": [
        "Now, that's quite a bit better!"
      ]
    }
  ]
}