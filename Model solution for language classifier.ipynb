{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Model solution for language classifier.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1xFpP10Lhtx",
        "colab_type": "code",
        "outputId": "7480f964-a998-4924-aa6c-0afa5c82c624",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "%tensorflow_version 1.x\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYz6Lwd_pmFC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "e23deaed-936c-4852-fb82-a3fbc06fa2d3"
      },
      "source": [
        "# Reading the data in makes sense to structure a little bit\n",
        "import random\n",
        "\n",
        "def read_data_one_lang(lang,part):\n",
        "    \"\"\"Reads one file for one language. Returns data in the form of pairs of (lang,line)\"\"\"\n",
        "    filename=\"language-identification/{}_{}.txt\".format(lang,part)\n",
        "    result=[] #this will be the list of pairs (lang,line)\n",
        "    with open(filename) as f:\n",
        "        for line in f:\n",
        "            line=line.strip()\n",
        "            result.append((lang,line)) \n",
        "    return result\n",
        "\n",
        "\n",
        "def read_data_all_langs(part):\n",
        "    \"\"\"Reads train, test or dev data for all languages. part can be train, test, or devel\"\"\"\n",
        "    #glob\n",
        "    data=[]\n",
        "    for lang in (\"en\",\"es\",\"et\",\"fi\",\"pt\"):\n",
        "        pairs=read_data_one_lang(lang,part)\n",
        "        data.extend(pairs) #just add these lines to the end\n",
        "    #...done\n",
        "    #but now they come in the order of languages\n",
        "    #we really must scramble these!\n",
        "    random.shuffle(data)\n",
        "    \n",
        "    #let's yet separate the labels and lines, we will need that anyway\n",
        "    labels=[label for label,line in data]\n",
        "    lines=[line for label,line in data]\n",
        "    return labels,lines\n",
        "\n",
        "labels_train,lines_train=read_data_all_langs(\"train\")\n",
        "labels_dev,lines_dev=read_data_all_langs(\"devel\")\n",
        "for label,line in zip(labels_train[:5],lines_train[:5]):\n",
        "    print(label,\"   \",line[:30],\"...\")\n",
        "#and beyond this point, exactly same code is applicable as before"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pt     A altura de o solo foi ampliad ...\n",
            "en     And what is there to show for  ...\n",
            "et     Kuulsusega k√§ib juba paraku ka ...\n",
            "et     Alles siis, kui mees ametist p ...\n",
            "et     Padari mitmete konkurentide se ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4HHGNieLhuB",
        "colab_type": "code",
        "outputId": "a21e6149-84c5-483e-abdd-be8dc8f2fbae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#1-3 character grams\n",
        "vectorizer=CountVectorizer(max_features=100000,binary=True,ngram_range=(3,3),analyzer=\"char_wb\")\n",
        "feature_matrix_train=vectorizer.fit_transform(lines_train)\n",
        "feature_matrix_dev=vectorizer.transform(lines_dev)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder=LabelEncoder() #Turns class labels into integers\n",
        "class_numbers_train=label_encoder.fit_transform(labels_train)\n",
        "class_numbers_dev=label_encoder.fit_transform(labels_dev)\n",
        "\n",
        "print(\"class_numbers shape=\",class_numbers_train.shape)\n",
        "print(\"class labels\",label_encoder.classes_) #this will let us translate back from indices to labels\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class_numbers shape= (5000,)\n",
            "class labels ['en' 'es' 'et' 'fi' 'pt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4GLRdjsOEHK",
        "colab_type": "text"
      },
      "source": [
        "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.\n",
        "We recommend you upgrade now or ensure your notebook will continue to use TensorFlow 1.x via the %tensorflow_version 1.x magic: more info.\n",
        "\n",
        "https://www.tensorflow.org/guide/migrate\n",
        "https://colab.research.google.com/notebooks/tensorflow_version.ipynb\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuC77IMsLhuN",
        "colab_type": "code",
        "outputId": "d02bbb49-dbd7-415d-bd7d-3c9696541cdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        " \n",
        "import keras \n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "example_count,feature_count=feature_matrix_train.shape\n",
        "class_count=len(label_encoder.classes_)\n",
        "\n",
        "inp=Input(shape=(feature_count,))\n",
        "hidden=Dense(20,activation=\"tanh\")(inp)\n",
        "outp=Dense(class_count,activation=\"softmax\")(hidden)\n",
        "model=Model(inputs=[inp], outputs=[outp])\n",
        "\n",
        "stop_cb=EarlyStopping(monitor='val_accuracy', patience=5, verbose=1, mode='auto', baseline=None, restore_best_weights=True)\n",
        "\n",
        "model.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=['accuracy'])\n",
        "hist=model.fit(feature_matrix_train,class_numbers_train,batch_size=100,verbose=1,epochs=25,validation_data=(feature_matrix_dev,class_numbers_dev),callbacks=[stop_cb])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/25\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "5000/5000 [==============================] - 9s 2ms/step - loss: 0.6254 - acc: 0.9254 - val_loss: 0.2960 - val_acc: 0.9784\n",
            "Epoch 2/25\n",
            "2300/5000 [============>.................] - ETA: 0s - loss: 0.2188 - acc: 0.9900"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:842: RuntimeWarning: Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: val_loss,val_acc,loss,acc\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5000/5000 [==============================] - 1s 134us/step - loss: 0.1912 - acc: 0.9886 - val_loss: 0.1889 - val_acc: 0.9824\n",
            "Epoch 3/25\n",
            "5000/5000 [==============================] - 1s 129us/step - loss: 0.1168 - acc: 0.9948 - val_loss: 0.1453 - val_acc: 0.9834\n",
            "Epoch 4/25\n",
            "5000/5000 [==============================] - 1s 127us/step - loss: 0.0798 - acc: 0.9968 - val_loss: 0.1215 - val_acc: 0.9840\n",
            "Epoch 5/25\n",
            "5000/5000 [==============================] - 1s 129us/step - loss: 0.0579 - acc: 0.9982 - val_loss: 0.1062 - val_acc: 0.9830\n",
            "Epoch 6/25\n",
            "5000/5000 [==============================] - 1s 136us/step - loss: 0.0436 - acc: 0.9990 - val_loss: 0.0959 - val_acc: 0.9838\n",
            "Epoch 7/25\n",
            "5000/5000 [==============================] - 1s 130us/step - loss: 0.0336 - acc: 0.9996 - val_loss: 0.0887 - val_acc: 0.9826\n",
            "Epoch 8/25\n",
            "5000/5000 [==============================] - 1s 134us/step - loss: 0.0265 - acc: 0.9998 - val_loss: 0.0833 - val_acc: 0.9832\n",
            "Epoch 9/25\n",
            "5000/5000 [==============================] - 1s 127us/step - loss: 0.0213 - acc: 0.9998 - val_loss: 0.0792 - val_acc: 0.9826\n",
            "Epoch 10/25\n",
            "5000/5000 [==============================] - 1s 137us/step - loss: 0.0174 - acc: 1.0000 - val_loss: 0.0760 - val_acc: 0.9830\n",
            "Epoch 11/25\n",
            "5000/5000 [==============================] - 1s 135us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.0735 - val_acc: 0.9828\n",
            "Epoch 12/25\n",
            "5000/5000 [==============================] - 1s 134us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.0714 - val_acc: 0.9824\n",
            "Epoch 13/25\n",
            "5000/5000 [==============================] - 1s 134us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.0698 - val_acc: 0.9818\n",
            "Epoch 14/25\n",
            "5000/5000 [==============================] - 1s 132us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.0684 - val_acc: 0.9818\n",
            "Epoch 15/25\n",
            "5000/5000 [==============================] - 1s 134us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0673 - val_acc: 0.9820\n",
            "Epoch 16/25\n",
            "5000/5000 [==============================] - 1s 128us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0664 - val_acc: 0.9818\n",
            "Epoch 17/25\n",
            "5000/5000 [==============================] - 1s 130us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0656 - val_acc: 0.9820\n",
            "Epoch 18/25\n",
            "5000/5000 [==============================] - 1s 135us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0649 - val_acc: 0.9816\n",
            "Epoch 19/25\n",
            "5000/5000 [==============================] - 1s 134us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0644 - val_acc: 0.9814\n",
            "Epoch 20/25\n",
            "5000/5000 [==============================] - 1s 132us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0639 - val_acc: 0.9812\n",
            "Epoch 21/25\n",
            "5000/5000 [==============================] - 1s 129us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0635 - val_acc: 0.9812\n",
            "Epoch 22/25\n",
            "5000/5000 [==============================] - 1s 132us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0631 - val_acc: 0.9812\n",
            "Epoch 23/25\n",
            "5000/5000 [==============================] - 1s 130us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0629 - val_acc: 0.9810\n",
            "Epoch 24/25\n",
            "5000/5000 [==============================] - 1s 127us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0626 - val_acc: 0.9808\n",
            "Epoch 25/25\n",
            "5000/5000 [==============================] - 1s 135us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0623 - val_acc: 0.9808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCehK5fcLhuX",
        "colab_type": "text"
      },
      "source": [
        "* Let's try to identify misclassified documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHFmrzjALhuZ",
        "colab_type": "code",
        "outputId": "84793732-69ea-417d-cf10-5509e7faf926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy\n",
        "\n",
        "predictions=model.predict(feature_matrix_dev)\n",
        "pred_classes=numpy.argmax(predictions,axis=-1)\n",
        "for pred,correct,txt_line in zip(pred_classes,labels_dev,lines_dev):\n",
        "    pred_label=label_encoder.classes_[pred]\n",
        "    if pred_label!=correct:\n",
        "        print(\"Prediction:\",pred_label,\"Correct:\",correct,\"Text:\",txt_line)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: en Correct: fi Text: ANNEX 16\n",
            "Prediction: fi Correct: et Text: Parima uustulnuka kategoorias on Bomfunki rivaalideks Blink 182, Melanie C, Sonique ja Anastasia.\n",
            "Prediction: en Correct: et Text: 1.1.2..\n",
            "Prediction: en Correct: pt Text: Medidas para as PME\n",
            "Prediction: pt Correct: en Text: For decades.\n",
            "Prediction: en Correct: pt Text: Voando Baixo\n",
            "Prediction: et Correct: fi Text: Talovahtina\n",
            "Prediction: en Correct: et Text: AT.\n",
            "Prediction: en Correct: es Text: Apareci√≥ en un art√≠culo de The Alternate View:\" Boomerang and the Sound of the Big Bang\"( January 2001).\n",
            "Prediction: pt Correct: es Text: Se opone a un sistema econ√≥mico, social o pol√≠tico estratificado.\n",
            "Prediction: en Correct: et Text: Just.\n",
            "Prediction: et Correct: en Text: 2 Peels:\n",
            "Prediction: en Correct: fi Text: Yritysesittely: Accenture oy\n",
            "Prediction: pt Correct: en Text: christmas cake for christmas day.\n",
            "Prediction: en Correct: pt Text: Com f√©\n",
            "Prediction: en Correct: et Text: BRISTOL MYERS 36,9\n",
            "Prediction: es Correct: pt Text: Visconde da Luz muda de sentido\n",
            "Prediction: en Correct: pt Text: Rarar√°!\n",
            "Prediction: en Correct: et Text: Vt\n",
            "Prediction: en Correct: pt Text: Sommeliers paulistas se superam em evento\n",
            "Prediction: es Correct: et Text: Tuntuimad DO piirkonnad: Ribera del Duero, Rueda, Toro.\n",
            "Prediction: pt Correct: en Text: Barbara Quimba 1/30/10\n",
            "Prediction: pt Correct: es Text: Se denomina as√≠ por emplear teja.\n",
            "Prediction: en Correct: pt Text: FM Radical\n",
            "Prediction: en Correct: et Text: Filter-disco, anyone?\n",
            "Prediction: et Correct: fi Text: LIITE 1\n",
            "Prediction: fi Correct: en Text: junkie lube?!\n",
            "Prediction: et Correct: pt Text: Raz√µes?\n",
            "Prediction: et Correct: fi Text: J√§rven valuma-alue on 524 km¬≤.\n",
            "Prediction: en Correct: et Text: Sott gramm.\n",
            "Prediction: pt Correct: en Text: Remember Luis Posada Carriles?\n",
            "Prediction: en Correct: es Text: M√© decepcion√≥.\n",
            "Prediction: es Correct: pt Text: Lambari d' Oeste( 5.000 habitantes) virou munic√≠pio h√° dois anos.\n",
            "Prediction: en Correct: pt Text: ?:? Acreditam?\n",
            "Prediction: es Correct: pt Text: China condiciona\n",
            "Prediction: et Correct: fi Text: Ei puoliso ole h√§√§pp√∂inen uimari.\n",
            "Prediction: et Correct: fi Text: - Tii√§tk√∂, m√§√§ oon kelannu.\n",
            "Prediction: en Correct: et Text: Samad v√§rvid!\n",
            "Prediction: et Correct: fi Text: ‚ÄúOkei.\n",
            "Prediction: et Correct: fi Text: Valinta miljoonien lauseiden joukosta on minun tekoni.\n",
            "Prediction: en Correct: et Text: Hiireke Stuart Little 79 398\n",
            "Prediction: en Correct: pt Text: Barcelos\n",
            "Prediction: en Correct: et Text: R√§√§gin.\n",
            "Prediction: fi Correct: et Text: Kuulan.\n",
            "Prediction: en Correct: fi Text: I know someone you don‚Äôt know... zzzztsts...\n",
            "Prediction: es Correct: pt Text: Rostos eloquentes\n",
            "Prediction: en Correct: fi Text: * KTM Fahrrad GmbH(polkupy√∂r√§t)\n",
            "Prediction: pt Correct: en Text: Ramtanu Maitra\n",
            "Prediction: et Correct: en Text: Obudu cattle ranch.\n",
            "Prediction: en Correct: fi Text: I\n",
            "Prediction: et Correct: en Text: Free parking.\n",
            "Prediction: es Correct: pt Text: S√≥ depois surge Tonya Harding, campe√£ de os Estados Unidos.\n",
            "Prediction: et Correct: en Text: [Tholt, Jane M.]\n",
            "Prediction: en Correct: fi Text: Oranje\n",
            "Prediction: en Correct: pt Text: Brizola\n",
            "Prediction: et Correct: fi Text: Tulet s√§ ja?\n",
            "Prediction: en Correct: pt Text: Em um √∫nico ano, 1937, eles compuseram¬´ They Can't Take That Away From Me¬ª,¬´ Let's Call the Whole Thing Off¬ª,¬´ A Foggy Day¬ª,¬´ Nice Work if You Can Get it¬ª,¬´ They All Laughed¬ª,¬´ Love Walked In¬ª' e¬´ Love Is Here to Stay¬ª', e essas s√£o apenas as que ficaram universalmente conhecidas.\n",
            "Prediction: pt Correct: es Text: Plantas acaulescentes.\n",
            "Prediction: en Correct: pt Text: G. Love canta blues\n",
            "Prediction: es Correct: pt Text: Director das OGMA exonerado\n",
            "Prediction: pt Correct: es Text: Seguro que no va a ser el √∫ltimo.\n",
            "Prediction: en Correct: et Text: Loe ka:, ML, 14. november\n",
            "Prediction: en Correct: pt Text: Inf√¢ncia:\n",
            "Prediction: en Correct: fi Text: PHP-skripti\n",
            "Prediction: en Correct: pt Text: Uma parte de Herv√© Guibert.\n",
            "Prediction: en Correct: es Text: Miguel Jim√©nez Garc√≠a, Lic.\n",
            "Prediction: en Correct: et Text: -?!\n",
            "Prediction: et Correct: en Text: calendar\n",
            "Prediction: en Correct: et Text: Link.\n",
            "Prediction: en Correct: pt Text: Faber and Faber\n",
            "Prediction: en Correct: et Text: √úle tuhande meedialogo\n",
            "Prediction: en Correct: pt Text: 46 anos\n",
            "Prediction: en Correct: pt Text: Reuni√£o regional\n",
            "Prediction: fi Correct: et Text: Vala viina!\n",
            "Prediction: et Correct: fi Text: No niin k√§y joskus.\n",
            "Prediction: es Correct: pt Text: Pol√≠cia localiza raptores\n",
            "Prediction: et Correct: fi Text: Kristus 2011\n",
            "Prediction: es Correct: pt Text: Montoya recupera\n",
            "Prediction: en Correct: pt Text: Med√≠ocre menos\n",
            "Prediction: pt Correct: et Text: Ljova Bi & ≈†ura Bi\n",
            "Prediction: fi Correct: et Text: Siin!\n",
            "Prediction: en Correct: es Text: Carlson dej√≥ la serie en 2003.\n",
            "Prediction: en Correct: pt Text: Iori Hamer\n",
            "Prediction: pt Correct: es Text: Concejal de Soria( 1991-1996);\n",
            "Prediction: en Correct: pt Text: Nervosas!\n",
            "Prediction: en Correct: es Text: ¬ø Mam√°?\n",
            "Prediction: en Correct: pt Text: WILSON BALDINI JR.\n",
            "Prediction: pt Correct: es Text: Florece de marzo a mayo.\n",
            "Prediction: en Correct: pt Text: Kim[ rindo]-- Ele √© Susan Hayward:\n",
            "Prediction: et Correct: fi Text: Joki on roomalaiselta nimelt√§√§n Singilis.\n",
            "Prediction: en Correct: es Text: En teatro incluye Othello, A.M.L., Hamlet, The Hunchback of Notre Dame y Looking for the Pony en Manhattan Theater Source con su hermana Adrienne Hurd.\n",
            "Prediction: es Correct: pt Text: BC espera queda para comprar d√≥lar\n",
            "Prediction: et Correct: fi Text: Se haluaa sinun rahasi.\n",
            "Prediction: en Correct: pt Text: ¬´ Peppermint Tea House-- The Best of Shoukichi Kina¬ª.\n",
            "Prediction: en Correct: pt Text: Renato Fairbanks Barbosa, 81, m√©dico:\n",
            "Prediction: en Correct: pt Text: ¬´ On tourne!¬ª\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAG7yJjWLhug",
        "colab_type": "code",
        "outputId": "9e4f31c7-749e-4903-e9ca-f8cd554e8d77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "data_in=vectorizer.transform([\"sdfjfj fsdjfoj fsjofs fjskf fjsklf\",\"I really think this should be classified as English\"])\n",
        "print(label_encoder.classes_)\n",
        "model.predict(data_in)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['en' 'es' 'et' 'fi' 'pt']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.2468520e-01, 4.5902524e-02, 1.6088000e-01, 1.5496165e-01,\n",
              "        1.1357068e-01],\n",
              "       [9.9990404e-01, 1.8294686e-05, 3.0967985e-05, 2.9542984e-05,\n",
              "        1.7214745e-05]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    }
  ]
}