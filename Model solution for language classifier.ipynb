{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Model solution for language classifier.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1xFpP10Lhtx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "97eb26e1-cf69-4e60-aedc-552f8e95230b"
      },
      "source": [
        "# Reading the data in makes sense to structure a little bit\n",
        "import random\n",
        "\n",
        "def read_data_one_lang(lang,part):\n",
        "    \"\"\"Reads one file for one language. Returns data in the form of pairs of (lang,line)\"\"\"\n",
        "    filename=\"language-identification/{}_{}.txt\".format(lang,part)\n",
        "    result=[] #this will be the list of pairs (lang,line)\n",
        "    with open(filename) as f:\n",
        "        for line in f:\n",
        "            line=line.strip()\n",
        "            result.append((lang,line)) \n",
        "    return result\n",
        "\n",
        "\n",
        "def read_data_all_langs(part):\n",
        "    \"\"\"Reads train, test or dev data for all languages. part can be train, test, or devel\"\"\"\n",
        "    #glob\n",
        "    data=[]\n",
        "    for lang in (\"en\",\"es\",\"et\",\"fi\",\"pt\"):\n",
        "        pairs=read_data_one_lang(lang,part)\n",
        "        data.extend(pairs) #just add these lines to the end\n",
        "    #...done\n",
        "    #but now they come in the order of languages\n",
        "    #we really must scramble these!\n",
        "    random.shuffle(data)\n",
        "    \n",
        "    #let's yet separate the labels and lines, we will need that anyway\n",
        "    labels=[label for label,line in data]\n",
        "    lines=[line for label,line in data]\n",
        "    return labels,lines\n",
        "\n",
        "labels_train,lines_train=read_data_all_langs(\"train\")\n",
        "labels_dev,lines_dev=read_data_all_langs(\"devel\")\n",
        "for label,line in zip(labels_train[:5],lines_train[:5]):\n",
        "    print(label,\"   \",line[:30],\"...\")\n",
        "#and beyond this point, exactly same code is applicable as before"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "et     Sest viimased on palju ilusama ...\n",
            "fi     Tähänkin on varmasti jäsenvalt ...\n",
            "en     Thanks. ...\n",
            "es     Muchos deltanos han optado por ...\n",
            "es     García Rojas escapó el 21 de f ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4HHGNieLhuB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5b3c8e9b-b1c0-4508-dec9-d33bc7eae947"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#1-3 character grams\n",
        "vectorizer=CountVectorizer(max_features=100000,binary=True,ngram_range=(3,3),analyzer=\"char_wb\")\n",
        "feature_matrix_train=vectorizer.fit_transform(lines_train)\n",
        "feature_matrix_dev=vectorizer.transform(lines_dev)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder=LabelEncoder() #Turns class labels into integers\n",
        "class_numbers_train=label_encoder.fit_transform(labels_train)\n",
        "class_numbers_dev=label_encoder.fit_transform(labels_dev)\n",
        "\n",
        "print(\"class_numbers shape=\",class_numbers_train.shape)\n",
        "print(\"class labels\",label_encoder.classes_) #this will let us translate back from indices to labels\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class_numbers shape= (5000,)\n",
            "class labels ['en' 'es' 'et' 'fi' 'pt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4GLRdjsOEHK",
        "colab_type": "text"
      },
      "source": [
        "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.\n",
        "We recommend you upgrade now or ensure your notebook will continue to use TensorFlow 1.x via the %tensorflow_version 1.x magic: more info.\n",
        "\n",
        "https://www.tensorflow.org/guide/migrate\n",
        "https://colab.research.google.com/notebooks/tensorflow_version.ipynb\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuC77IMsLhuN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "efb2dccc-aecf-4f74-9b9c-37d1fad53c78"
      },
      "source": [
        "# !pip install tensorflow==1.14.0 # to run with old tf with which the code is made\n",
        "# The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.\n",
        "# \n",
        "import keras \n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "example_count,feature_count=feature_matrix_train.shape\n",
        "class_count=len(label_encoder.classes_)\n",
        "\n",
        "inp=Input(shape=(feature_count,))\n",
        "hidden=Dense(20,activation=\"tanh\")(inp)\n",
        "outp=Dense(class_count,activation=\"softmax\")(hidden)\n",
        "model=Model(inputs=[inp], outputs=[outp])\n",
        "\n",
        "stop_cb=EarlyStopping(monitor='val_accuracy', patience=5, verbose=1, mode='auto', baseline=None, restore_best_weights=True)\n",
        "\n",
        "model.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=['accuracy'])\n",
        "hist=model.fit(feature_matrix_train,class_numbers_train,batch_size=100,verbose=1,epochs=25,validation_data=(feature_matrix_dev,class_numbers_dev),callbacks=[stop_cb])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/25\n",
            "5000/5000 [==============================] - 1s 266us/step - loss: 0.6821 - acc: 0.9160 - val_loss: 0.3269 - val_acc: 0.9784\n",
            "Epoch 2/25\n",
            "1300/5000 [======>.......................] - ETA: 0s - loss: 0.2621 - acc: 0.9869"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:842: RuntimeWarning: Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: val_loss,val_acc,loss,acc\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5000/5000 [==============================] - 1s 218us/step - loss: 0.2118 - acc: 0.9878 - val_loss: 0.2004 - val_acc: 0.9816\n",
            "Epoch 3/25\n",
            "5000/5000 [==============================] - 1s 214us/step - loss: 0.1257 - acc: 0.9928 - val_loss: 0.1505 - val_acc: 0.9822\n",
            "Epoch 4/25\n",
            "5000/5000 [==============================] - 1s 222us/step - loss: 0.0849 - acc: 0.9972 - val_loss: 0.1238 - val_acc: 0.9828\n",
            "Epoch 5/25\n",
            "5000/5000 [==============================] - 1s 217us/step - loss: 0.0610 - acc: 0.9982 - val_loss: 0.1076 - val_acc: 0.9830\n",
            "Epoch 6/25\n",
            "5000/5000 [==============================] - 1s 217us/step - loss: 0.0457 - acc: 0.9990 - val_loss: 0.0969 - val_acc: 0.9838\n",
            "Epoch 7/25\n",
            "5000/5000 [==============================] - 1s 219us/step - loss: 0.0352 - acc: 0.9992 - val_loss: 0.0894 - val_acc: 0.9832\n",
            "Epoch 8/25\n",
            "5000/5000 [==============================] - 1s 214us/step - loss: 0.0278 - acc: 0.9998 - val_loss: 0.0839 - val_acc: 0.9826\n",
            "Epoch 9/25\n",
            "5000/5000 [==============================] - 1s 216us/step - loss: 0.0223 - acc: 1.0000 - val_loss: 0.0795 - val_acc: 0.9826\n",
            "Epoch 10/25\n",
            "5000/5000 [==============================] - 1s 216us/step - loss: 0.0182 - acc: 1.0000 - val_loss: 0.0763 - val_acc: 0.9822\n",
            "Epoch 11/25\n",
            "5000/5000 [==============================] - 1s 221us/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.0737 - val_acc: 0.9818\n",
            "Epoch 12/25\n",
            "5000/5000 [==============================] - 1s 219us/step - loss: 0.0127 - acc: 1.0000 - val_loss: 0.0717 - val_acc: 0.9816\n",
            "Epoch 13/25\n",
            "5000/5000 [==============================] - 1s 216us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.0701 - val_acc: 0.9812\n",
            "Epoch 14/25\n",
            "5000/5000 [==============================] - 1s 222us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.0687 - val_acc: 0.9812\n",
            "Epoch 15/25\n",
            "5000/5000 [==============================] - 1s 217us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0675 - val_acc: 0.9808\n",
            "Epoch 16/25\n",
            "5000/5000 [==============================] - 1s 217us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0666 - val_acc: 0.9812\n",
            "Epoch 17/25\n",
            "5000/5000 [==============================] - 1s 216us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0658 - val_acc: 0.9812\n",
            "Epoch 18/25\n",
            "5000/5000 [==============================] - 1s 217us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 0.9816\n",
            "Epoch 19/25\n",
            "5000/5000 [==============================] - 1s 218us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0645 - val_acc: 0.9816\n",
            "Epoch 20/25\n",
            "5000/5000 [==============================] - 1s 217us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0641 - val_acc: 0.9818\n",
            "Epoch 21/25\n",
            "5000/5000 [==============================] - 1s 220us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0637 - val_acc: 0.9818\n",
            "Epoch 22/25\n",
            "5000/5000 [==============================] - 1s 215us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0633 - val_acc: 0.9818\n",
            "Epoch 23/25\n",
            "5000/5000 [==============================] - 1s 215us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0630 - val_acc: 0.9816\n",
            "Epoch 24/25\n",
            "5000/5000 [==============================] - 1s 215us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0628 - val_acc: 0.9816\n",
            "Epoch 25/25\n",
            "5000/5000 [==============================] - 1s 214us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0625 - val_acc: 0.9814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCehK5fcLhuX",
        "colab_type": "text"
      },
      "source": [
        "* Let's try to identify misclassified documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHFmrzjALhuZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "07c2a565-401b-4792-9977-1626013bf61e"
      },
      "source": [
        "import numpy\n",
        "\n",
        "predictions=model.predict(feature_matrix_dev)\n",
        "pred_classes=numpy.argmax(predictions,axis=-1)\n",
        "for pred,correct,txt_line in zip(pred_classes,labels_dev,lines_dev):\n",
        "    pred_label=label_encoder.classes_[pred]\n",
        "    if pred_label!=correct:\n",
        "        print(\"Prediction:\",pred_label,\"Correct:\",correct,\"Text:\",txt_line)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: en Correct: pt Text: « Peppermint Tea House-- The Best of Shoukichi Kina».\n",
            "Prediction: es Correct: pt Text: Suficientemente refrescante e estival.\n",
            "Prediction: en Correct: et Text: Üle tuhande meedialogo\n",
            "Prediction: en Correct: fi Text: I\n",
            "Prediction: en Correct: pt Text: Em um único ano, 1937, eles compuseram« They Can't Take That Away From Me»,« Let's Call the Whole Thing Off»,« A Foggy Day»,« Nice Work if You Can Get it»,« They All Laughed»,« Love Walked In»' e« Love Is Here to Stay»', e essas são apenas as que ficaram universalmente conhecidas.\n",
            "Prediction: pt Correct: es Text: Florece de marzo a mayo.\n",
            "Prediction: en Correct: es Text: Apareció en un artículo de The Alternate View:\" Boomerang and the Sound of the Big Bang\"( January 2001).\n",
            "Prediction: en Correct: et Text: Virginia- odavam järglane.\n",
            "Prediction: et Correct: fi Text: Talovahtina\n",
            "Prediction: en Correct: fi Text: * KTM Fahrrad GmbH(polkupyörät)\n",
            "Prediction: en Correct: pt Text: Faber and Faber\n",
            "Prediction: en Correct: fi Text: I know someone you don’t know... zzzztsts...\n",
            "Prediction: en Correct: pt Text: Sommeliers paulistas se superam em evento\n",
            "Prediction: en Correct: et Text: Filter-disco, anyone?\n",
            "Prediction: es Correct: et Text: Tuntuimad DO piirkonnad: Ribera del Duero, Rueda, Toro.\n",
            "Prediction: pt Correct: en Text: Email Us\n",
            "Prediction: et Correct: pt Text: Razões?\n",
            "Prediction: en Correct: et Text: Sott gramm.\n",
            "Prediction: es Correct: pt Text: BC espera queda para comprar dólar\n",
            "Prediction: en Correct: et Text: Hiireke Stuart Little 79 398\n",
            "Prediction: en Correct: fi Text: Yritysesittely: Accenture oy\n",
            "Prediction: pt Correct: et Text: Ljova Bi & Šura Bi\n",
            "Prediction: en Correct: es Text: Miguel Jiménez García, Lic.\n",
            "Prediction: pt Correct: es Text: Se opone a un sistema económico, social o político estratificado.\n",
            "Prediction: fi Correct: et Text: Siin!\n",
            "Prediction: et Correct: en Text: 2 Peels:\n",
            "Prediction: et Correct: fi Text: No niin käy joskus.\n",
            "Prediction: pt Correct: es Text: Como docente, enseña historia contemporánea de Europa.\n",
            "Prediction: en Correct: et Text: Vt\n",
            "Prediction: en Correct: et Text: Foto: Reuters\n",
            "Prediction: et Correct: fi Text: Valinta miljoonien lauseiden joukosta on minun tekoni.\n",
            "Prediction: en Correct: et Text: 1.1.2..\n",
            "Prediction: pt Correct: es Text: Concejal de Soria( 1991-1996);\n",
            "Prediction: en Correct: fi Text: PHP-skripti\n",
            "Prediction: pt Correct: es Text: Plantas acaulescentes.\n",
            "Prediction: en Correct: pt Text: Medíocre menos\n",
            "Prediction: en Correct: es Text: ¿ Mamá?\n",
            "Prediction: es Correct: pt Text: Director das OGMA exonerado\n",
            "Prediction: et Correct: fi Text: Se haluaa sinun rahasi.\n",
            "Prediction: en Correct: pt Text: Renato Fairbanks Barbosa, 81, médico:\n",
            "Prediction: fi Correct: et Text: Vala viina!\n",
            "Prediction: et Correct: en Text: calendar\n",
            "Prediction: en Correct: pt Text: Voando Baixo\n",
            "Prediction: en Correct: pt Text: Medidas para as PME\n",
            "Prediction: es Correct: pt Text: Rostos eloquentes\n",
            "Prediction: en Correct: pt Text: FM Radical\n",
            "Prediction: es Correct: pt Text: Visconde da Luz muda de sentido\n",
            "Prediction: en Correct: pt Text: Rarará!\n",
            "Prediction: en Correct: et Text: Link.\n",
            "Prediction: et Correct: fi Text: Ei puoliso ole hääppöinen uimari.\n",
            "Prediction: pt Correct: en Text: Ramtanu Maitra\n",
            "Prediction: et Correct: fi Text: - Tiiätkö, mää oon kelannu.\n",
            "Prediction: en Correct: et Text: Samad värvid!\n",
            "Prediction: en Correct: es Text: Mé decepcionó.\n",
            "Prediction: en Correct: et Text: AT.\n",
            "Prediction: en Correct: pt Text: WILSON BALDINI JR.\n",
            "Prediction: fi Correct: et Text: Kuulan.\n",
            "Prediction: et Correct: fi Text: Järven valuma-alue on 524 km².\n",
            "Prediction: pt Correct: es Text: Se denomina así por emplear teja.\n",
            "Prediction: en Correct: fi Text: “Okei.\n",
            "Prediction: en Correct: et Text: BRISTOL MYERS 36,9\n",
            "Prediction: es Correct: pt Text: Só depois surge Tonya Harding, campeã de os Estados Unidos.\n",
            "Prediction: et Correct: fi Text: Pitsakastike;\n",
            "Prediction: en Correct: pt Text: « On tourne!»\n",
            "Prediction: pt Correct: es Text: Seguro que no va a ser el último.\n",
            "Prediction: es Correct: pt Text: Montoya recupera\n",
            "Prediction: en Correct: et Text: Just.\n",
            "Prediction: en Correct: pt Text: ?:? Acreditam?\n",
            "Prediction: en Correct: et Text: KIRIK.\n",
            "Prediction: en Correct: pt Text: Kim[ rindo]-- Ele é Susan Hayward:\n",
            "Prediction: fi Correct: en Text: junkie lube?!\n",
            "Prediction: et Correct: fi Text: Joki on roomalaiselta nimeltään Singilis.\n",
            "Prediction: en Correct: et Text: -?!\n",
            "Prediction: es Correct: pt Text: Polícia localiza raptores\n",
            "Prediction: et Correct: fi Text: LIITE 1\n",
            "Prediction: en Correct: pt Text: Uma parte de Hervé Guibert.\n",
            "Prediction: et Correct: en Text: Free parking.\n",
            "Prediction: en Correct: es Text: En teatro incluye Othello, A.M.L., Hamlet, The Hunchback of Notre Dame y Looking for the Pony en Manhattan Theater Source con su hermana Adrienne Hurd.\n",
            "Prediction: en Correct: pt Text: G. Love canta blues\n",
            "Prediction: en Correct: pt Text: Nervosas!\n",
            "Prediction: en Correct: pt Text: Com fé\n",
            "Prediction: en Correct: fi Text: Oranje\n",
            "Prediction: en Correct: pt Text: Brizola\n",
            "Prediction: en Correct: pt Text: China condiciona\n",
            "Prediction: en Correct: pt Text: Iori Hamer\n",
            "Prediction: et Correct: en Text: Obudu cattle ranch.\n",
            "Prediction: pt Correct: en Text: Barbara Quimba 1/30/10\n",
            "Prediction: en Correct: pt Text: Infância:\n",
            "Prediction: es Correct: pt Text: Lambari d' Oeste( 5.000 habitantes) virou município há dois anos.\n",
            "Prediction: et Correct: fi Text: Kristus 2011\n",
            "Prediction: en Correct: fi Text: ANNEX 16\n",
            "Prediction: en Correct: pt Text: Barcelos\n",
            "Prediction: en Correct: et Text: Loe ka:, ML, 14. november\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAG7yJjWLhug",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "a14d3d75-efac-4a63-95d6-e8099ae3b5d0"
      },
      "source": [
        "data_in=vectorizer.transform([\"sdfjfj fsdjfoj fsjofs fjskf fjsklf\",\"I really think this should be classified as English\"])\n",
        "print(label_encoder.classes_)\n",
        "model.predict(data_in)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['en' 'es' 'et' 'fi' 'pt']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.9812174e-01, 5.3042203e-02, 1.5040587e-01, 1.4734639e-01,\n",
              "        1.5108387e-01],\n",
              "       [9.9988163e-01, 5.4350170e-05, 1.6178319e-05, 5.2756500e-06,\n",
              "        4.2504202e-05]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    }
  ]
}