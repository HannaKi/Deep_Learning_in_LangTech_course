{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Bag-of-words classifier with pretrained word embeddings\n",
    "\n",
    "- If we have a trained word embeddings model, we can transfer that knowledge into a new task and model\n",
    "- Initialize the weights in the classifier with pretrained word embeddings\n",
    "- Word embeddings downloaded at https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki-news-300d-1M.vec.zip\n",
    "\n",
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class': 'pos', 'text': 'The stories in this video are very entertaining, and it definately is worth a look! The first one concerns a young couple harrassed in the woods by two rednecks, with a great, but unexplained twist at the end.  The seond is the best of the lot, and it alone, makes this worth watching - A man is attacked by a dog, which he fears to be rabid - He finds shelter in what appears to be a hospital, but he finds out the employees there are not exactly what they appear to be...... Great twist at the end, and this episode alone scores 10/10! If the others were up to par with this one, this would get 10/10!  The third is the weakest of the bunch - A girl meets with some guys and has wild sex! There appears to be no point to the story until the end, with a good little twist, but it is spoiled by the awful first part!  Never the less, this is a great movie that will not do you wrong at all! Well worth a rental!'}\n",
      "['The stories in this video are very entertaining, and it definately is worth a look! The first one concerns a young couple harrassed in the woods by two rednecks, with a great, but unexplained twist at the end.  The seond is the best of the lot, and it alone, makes this worth watching - A man is attacked by a dog, which he fears to be rabid - He finds shelter in what appears to be a hospital, but he finds out the employees there are not exactly what they appear to be...... Great twist at the end, and this episode alone scores 10/10! If the others were up to par with this one, this would get 10/10!  The third is the weakest of the bunch - A girl meets with some guys and has wild sex! There appears to be no point to the story until the end, with a good little twist, but it is spoiled by the awful first part!  Never the less, this is a great movie that will not do you wrong at all! Well worth a rental!', 'Lindsay Anderson was very much a European film maker , whereas the likes of David Lean , Ridley Scott and Alan Parker make spectacular movies involving visuel scope Anderson`s movie are more about social commentary and subtext , so much so that the message often ends up taking over the entire film whose primary function should be to entertain the audience   What you think of IF comes down to what you think of British film makers . I`m very much of the view that cinema should be a universial medium ( The best Brit movie makes are those who try to emulate Hollywood in my opinion ) , if you want to send a message try pony express , and I find the movie dated , pretentious and too set in the 1960s . 1968 was the summer of love and the year of student rebellion in France . You can just imagine every single French leftist worshipping this movie especially the climax . French new wave film makers will also admire the abstract surrealism of some scenes but a mainstream international will dislike it , and many will dislike it intensely']\n",
      "['pos', 'neg']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "with open(\"data/imdb_train.json\") as f:\n",
    "    data=json.load(f)\n",
    "random.shuffle(data) \n",
    "print(data[0])\n",
    "\n",
    "# We need to gather the texts, into a list\n",
    "texts=[one_example[\"text\"] for one_example in data]\n",
    "labels=[one_example[\"class\"] for one_example in data]\n",
    "print(texts[:2])\n",
    "print(labels[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use gensim to read the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words from embedding model: 50000\n",
      "First 50 words: [',', 'the', '.', 'and', 'of', 'to', 'in', 'a', '\"', ':', ')', 'that', '(', 'is', 'for', 'on', '*', 'with', 'as', 'it', 'The', 'or', 'was', \"'\", \"'s\", 'by', 'from', 'at', 'I', 'this', 'you', '/', 'are', '=', 'not', '-', 'have', '?', 'be', 'which', ';', 'all', 'his', 'has', 'one', 'their', 'about', 'but', 'an', '|']\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "vector_model=KeyedVectors.load_word2vec_format(\"data/wiki-news-300d-1M.vec\", binary=False, limit=50000)\n",
    "\n",
    "# sort based on the index to make sure they are in the correct order\n",
    "words=[k for k,v in sorted(vector_model.vocab.items(), key=lambda x:x[1].index)]\n",
    "print(\"Words from embedding model:\",len(words))\n",
    "print(\"First 50 words:\",words[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the vectors\n",
    "\n",
    "- Easier to learn on top of these vectors when the magnitude does not vary much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before normalization: [-0.0234 -0.0268 -0.0838  0.0386 -0.0321  0.0628  0.0281 -0.0252  0.0269\n",
      " -0.0063]\n",
      "After normalization: [-0.0163762  -0.01875564 -0.05864638  0.02701372 -0.02246478  0.04394979\n",
      "  0.01966543 -0.0176359   0.01882563 -0.00440898]\n"
     ]
    }
   ],
   "source": [
    "print(\"Before normalization:\",vector_model.get_vector(\"in\")[:10])\n",
    "vector_model.init_sims(replace=True)\n",
    "print(\"After normalization:\",vector_model.get_vector(\"in\")[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text analyzer and vectorizer\n",
    "\n",
    "- When we use an embedding layer (keras.layers.Embedding) the input data must be a sequence, not a bag-of-words vector\n",
    "- You can use CountVectorizer only as an analyzer without building the feature matrix\n",
    "- We will then build the vectorizer part later ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'stories', 'in', 'this', 'video', 'are', 'very', 'entertaining', 'and', 'it', 'definately', 'is', 'worth', 'look', 'The', 'first', 'one', 'concerns', 'young', 'couple', 'harrassed', 'in', 'the', 'woods', 'by', 'two', 'rednecks', 'with', 'great', 'but', 'unexplained', 'twist', 'at', 'the', 'end', 'The', 'seond', 'is', 'the', 'best', 'of', 'the', 'lot', 'and', 'it', 'alone', 'makes', 'this', 'worth', 'watching', 'man', 'is', 'attacked', 'by', 'dog', 'which', 'he', 'fears', 'to', 'be', 'rabid', 'He', 'finds', 'shelter', 'in', 'what', 'appears', 'to', 'be', 'hospital', 'but', 'he', 'finds', 'out', 'the', 'employees', 'there', 'are', 'not', 'exactly', 'what', 'they', 'appear', 'to', 'be', 'Great', 'twist', 'at', 'the', 'end', 'and', 'this', 'episode', 'alone', 'scores', '10', '10', 'If', 'the', 'others', 'were', 'up', 'to', 'par', 'with', 'this', 'one', 'this', 'would', 'get', '10', '10', 'The', 'third', 'is', 'the', 'weakest', 'of', 'the', 'bunch', 'girl', 'meets', 'with', 'some', 'guys', 'and', 'has', 'wild', 'sex', 'There', 'appears', 'to', 'be', 'no', 'point', 'to', 'the', 'story', 'until', 'the', 'end', 'with', 'good', 'little', 'twist', 'but', 'it', 'is', 'spoiled', 'by', 'the', 'awful', 'first', 'part', 'Never', 'the', 'less', 'this', 'is', 'great', 'movie', 'that', 'will', 'not', 'do', 'you', 'wrong', 'at', 'all', 'Well', 'worth', 'rental']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy\n",
    "analyzer=CountVectorizer(lowercase=False).build_analyzer() # includes tokenizer and preprocessing\n",
    "print(analyzer(texts[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand the vocabulary using words from the embedding model\n",
    "\n",
    "- The embedding model usually knows more words than the task specific model, because it has seen a lot more data\n",
    "- If you wish, you can use the embedding model vocabulary to expand the task specific one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words from embedding model: 47852\n"
     ]
    }
   ],
   "source": [
    "# init the vectorizer vocabulary using words from the embedding model\n",
    "def init_vocabulary(vocab, text, text_analyzer):\n",
    "    for word in analyzer(text):\n",
    "        # Only use pretrained vocabulary\n",
    "        if word in vector_model.vocab:\n",
    "            vocab.setdefault(word, len(vocab))\n",
    "    return vocab\n",
    "\n",
    "words_from_model=\" \".join(words[:50000]) # use 50K words from the embedding model to initialize the vocabulary --> expands the learned vocabulary\n",
    "vocabulary={\"<SPECIAL>\": 0} # zero has a special meaning in sequence models, prevent using it for a normal word\n",
    "vocabulary=init_vocabulary(vocabulary, words_from_model, analyzer)\n",
    "print(\"Words from embedding model:\",len(vocabulary))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizer\n",
    "\n",
    "- Build a dictionary to turn words into numbers, here we use the one which we initialized with the embedding model\n",
    "- Vectorizing a sequence: In our data each example is a list of words, we need to turn each example into list of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in vocabulary: 47852\n",
      "Vectorized data shape: (25000,)\n",
      "First example vectorized: [13, 1421, 5, 19, 685, 21, 183, 8288, 2, 12, 26983, 7, 1534, 308, 13, 90, 29, 1060, 745, 1965, 5, 1, 11588, 16, 85, 10, 353, 32, 17120, 8474, 18, 1, 406, 13, 7, 1, 256, 3, 1, 1461, 2, 12, 868, 571, 19, 1534, 2175, 305, 7, 2912, 16, 2286, 25, 37, 4629, 4, 24, 23772, 140, 3078, 5355, 5, 58, 937, 4, 24, 999, 32, 37, 3078, 75, 1, 1018, 62, 21, 22, 1250, 58, 54, 712, 4, 24, 1540, 8474, 18, 1, 406, 2, 19, 1374, 868, 3283, 118, 118, 93, 1, 208, 42, 71, 4, 6666, 10, 19, 29, 19, 63, 129, 118, 118, 13, 660, 7, 1, 29056, 3, 1, 9396, 1759, 2545, 10, 48, 2713, 2, 28, 3229, 1746, 374, 937, 4, 24, 82, 158, 4, 1, 372, 222, 1, 406, 10, 142, 411, 8474, 32, 12, 7, 16966, 16, 1, 6506, 90, 237, 5969, 1, 395, 19, 7, 353, 1056, 6, 39, 22, 79, 20, 521, 18, 26, 1707, 1534, 10187]\n",
      "First example text: ['The', 'stories', 'in', 'this', 'video', 'are', 'very', 'entertaining', 'and', 'it', 'definately', 'is', 'worth', 'look', 'The', 'first', 'one', 'concerns', 'young', 'couple', 'in', 'the', 'woods', 'by', 'two', 'with', 'great', 'but', 'unexplained', 'twist', 'at', 'the', 'end', 'The', 'is', 'the', 'best', 'of', 'the', 'lot', 'and', 'it', 'alone', 'makes', 'this', 'worth', 'watching', 'man', 'is', 'attacked', 'by', 'dog', 'which', 'he', 'fears', 'to', 'be', 'rabid', 'He', 'finds', 'shelter', 'in', 'what', 'appears', 'to', 'be', 'hospital', 'but', 'he', 'finds', 'out', 'the', 'employees', 'there', 'are', 'not', 'exactly', 'what', 'they', 'appear', 'to', 'be', 'Great', 'twist', 'at', 'the', 'end', 'and', 'this', 'episode', 'alone', 'scores', '10', '10', 'If', 'the', 'others', 'were', 'up', 'to', 'par', 'with', 'this', 'one', 'this', 'would', 'get', '10', '10', 'The', 'third', 'is', 'the', 'weakest', 'of', 'the', 'bunch', 'girl', 'meets', 'with', 'some', 'guys', 'and', 'has', 'wild', 'sex', 'There', 'appears', 'to', 'be', 'no', 'point', 'to', 'the', 'story', 'until', 'the', 'end', 'with', 'good', 'little', 'twist', 'but', 'it', 'is', 'spoiled', 'by', 'the', 'awful', 'first', 'part', 'Never', 'the', 'less', 'this', 'is', 'great', 'movie', 'that', 'will', 'not', 'do', 'you', 'wrong', 'at', 'all', 'Well', 'worth', 'rental']\n"
     ]
    }
   ],
   "source": [
    "def vectorizer(vocab, texts):\n",
    "    vectorized_data=[] # turn text into numbers based on our vocabulary mapping\n",
    "    for one_example in texts:\n",
    "        vectorized_example=[]\n",
    "        for word in analyzer(one_example):\n",
    "            # Only use pretrained vocabulary\n",
    "            if word in vector_model.vocab:\n",
    "                vectorized_example.append(vocab[word])\n",
    "            #vocab.setdefault(word, len(vocab)) # add word to our vocabulary if it does not exist\n",
    "            #vectorized_example.append(vocab[word])\n",
    "        vectorized_data.append(vectorized_example)\n",
    "    \n",
    "    vectorized_data=numpy.array(vectorized_data) # turn python list into numpy matrix\n",
    "    return vectorized_data, vocab\n",
    "\n",
    "vectorized_data, vocabulary=vectorizer(vocabulary, texts)\n",
    "\n",
    "# now vectorized data is the same as feature_matrix, but in different format\n",
    "print(\"Words in vocabulary:\",len(vocabulary))\n",
    "print(\"Vectorized data shape:\",vectorized_data.shape)\n",
    "print(\"First example vectorized:\",vectorized_data[0])\n",
    "inversed_vocabulary={value:key for key, value in vocabulary.items()} # inverse the dictionary\n",
    "print(\"First example text:\",[inversed_vocabulary[idx] for idx in vectorized_data[0]])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels into onehot vectors\n",
    "\n",
    "- Same as in the original BOW classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_numbers shape= (25000,)\n",
      "class_numbers [1 0 0 ... 1 1 0]\n",
      "class labels ['neg' 'pos']\n",
      "classes_1hot [[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "label_encoder=LabelEncoder() #Turns class labels into integers\n",
    "one_hot_encoder=OneHotEncoder(sparse=False) #Turns class integers into one-hot encoding\n",
    "class_numbers=label_encoder.fit_transform(labels)\n",
    "print(\"class_numbers shape=\",class_numbers.shape)\n",
    "print(\"class_numbers\",class_numbers)\n",
    "print(\"class labels\",label_encoder.classes_)\n",
    "#And now yet the one-hot encoding\n",
    "classes_1hot=one_hot_encoder.fit_transform(class_numbers.reshape(-1,1))\n",
    "print(\"classes_1hot\",classes_1hot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network\n",
    "\n",
    "- First we need to create an embedding matrix which we can then plug into the neural network\n",
    "- The embedding matrix must follow the order from the vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pretrained vectors for 47851 words.\n",
      "Shape of pretrained embeddings: (47852, 300)\n",
      "Vector for the word 'in': [-0.0163762  -0.01875564 -0.05864638  0.02701372 -0.02246478  0.04394979\n",
      "  0.01966543 -0.0176359   0.01882563 -0.00440898]\n"
     ]
    }
   ],
   "source": [
    "def load_pretrained_embeddings(vocab, embedding_model):\n",
    "    \"\"\" vocab: vocabulary from our data vectorizer, embedding_model: model loaded with gensim \"\"\"\n",
    "    pretrained_embeddings=numpy.random.uniform(low=-0.05, high=0.05, size=(len(vocab),embedding_model.vectors.shape[1])) # initialize new matrix (words x embedding dim)\n",
    "    found=0\n",
    "    for word,idx in vocab.items():\n",
    "        if word in embedding_model.vocab:\n",
    "            pretrained_embeddings[idx]=embedding_model.get_vector(word)\n",
    "            found+=1\n",
    "            \n",
    "    print(\"Found pretrained vectors for {found} words.\".format(found=found))\n",
    "    return pretrained_embeddings\n",
    "\n",
    "pretrained=load_pretrained_embeddings(vocabulary, vector_model)\n",
    "print(\"Shape of pretrained embeddings:\",pretrained.shape)\n",
    "print(\"Vector for the word 'in':\",pretrained[vocabulary[\"in\"]][:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Sequential input\n",
    "\n",
    "- Remember how the shape of the input data matrix had undefined number of columns\n",
    "- Now we must make it into fixed size (same for each example)\n",
    "- Padding: include zeros until you reach the correct size\n",
    "- You will hear more about this next week!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old shape: (25000,)\n",
      "New shape: (25000, 2226)\n",
      "First example: [  13 1421    5 ...    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "### Only needed for me, not to block the whole GPU, you don't need this stuff\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "set_session(tf.Session(config=config))\n",
    "### ---end of weird stuff\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "print(\"Old shape:\", vectorized_data.shape)\n",
    "vectorized_data_padded=pad_sequences(vectorized_data, padding='post')\n",
    "print(\"New shape:\", vectorized_data_padded.shape)\n",
    "print(\"First example:\", vectorized_data_padded[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple network with a single convolutional layer with window size of 2 words (bigrams), 50 kernels and global max pooling (only the maximum value from each kernel is preserved). We create a separate model with the CNN layer as the output. This model shares weights with the actual model and can be used in analysing the kernel activations in each time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 2226)              0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 2226, 300)         14355600  \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 2225, 50)          30050     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 14,385,752\n",
      "Trainable params: 30,152\n",
      "Non-trainable params: 14,355,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 22500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n",
      "22500/22500 [==============================] - 7s 299us/step - loss: 0.5229 - acc: 0.7718 - val_loss: 0.4018 - val_acc: 0.8324\n",
      "Epoch 2/10\n",
      "22500/22500 [==============================] - 8s 343us/step - loss: 0.3592 - acc: 0.8460 - val_loss: 0.3405 - val_acc: 0.8580\n",
      "Epoch 3/10\n",
      "22500/22500 [==============================] - 7s 298us/step - loss: 0.3138 - acc: 0.8691 - val_loss: 0.3145 - val_acc: 0.8680\n",
      "Epoch 4/10\n",
      "22500/22500 [==============================] - 8s 334us/step - loss: 0.2847 - acc: 0.8842 - val_loss: 0.3071 - val_acc: 0.8724\n",
      "Epoch 5/10\n",
      "22500/22500 [==============================] - 7s 323us/step - loss: 0.2635 - acc: 0.8938 - val_loss: 0.2913 - val_acc: 0.8812\n",
      "Epoch 6/10\n",
      "22500/22500 [==============================] - 7s 308us/step - loss: 0.2462 - acc: 0.9026 - val_loss: 0.2833 - val_acc: 0.8872\n",
      "Epoch 7/10\n",
      "22500/22500 [==============================] - 8s 341us/step - loss: 0.2285 - acc: 0.9087 - val_loss: 0.2774 - val_acc: 0.8872\n",
      "Epoch 8/10\n",
      "22500/22500 [==============================] - 7s 299us/step - loss: 0.2149 - acc: 0.9161 - val_loss: 0.2743 - val_acc: 0.8912\n",
      "Epoch 9/10\n",
      "22500/22500 [==============================] - 7s 328us/step - loss: 0.2009 - acc: 0.9232 - val_loss: 0.2691 - val_acc: 0.8936\n",
      "Epoch 10/10\n",
      "22500/22500 [==============================] - 8s 339us/step - loss: 0.1902 - acc: 0.9271 - val_loss: 0.2674 - val_acc: 0.8928\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, Activation, Conv1D, GlobalMaxPooling1D\n",
    "from keras import backend as K\n",
    "from keras.layers.core import Lambda\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "\n",
    "example_count,sequence_len=vectorized_data_padded.shape\n",
    "example_count,class_count=classes_1hot.shape\n",
    "\n",
    "vector_size=pretrained.shape[1] # embedding dim (\"hidden layer\") must be the same as in the pretrained model\n",
    "kernels = 50\n",
    "window_size = 2 # How many words a kernel sees at a time\n",
    "\n",
    "inp=Input(shape=(sequence_len,))\n",
    "embeddings=Embedding(len(vocabulary), vector_size, mask_zero=False, weights=[pretrained], trainable=False)(inp)\n",
    "cnn = Conv1D(kernels,window_size,padding='valid',activation='relu',strides=1)(embeddings)\n",
    "pooling = GlobalMaxPooling1D()(cnn)\n",
    "outp=Dense(class_count, activation=\"softmax\")(pooling)\n",
    "model=Model(inputs=[inp], outputs=[outp])\n",
    "\n",
    "optimizer=Adam(lr=0.001) # define the learning rate\n",
    "model.compile(optimizer=optimizer,loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "\n",
    "# This is our model for outputting the time step wise kernel activations.\n",
    "cnn_out_model=Model(inputs=[inp], outputs=[cnn])\n",
    "# We have to compile the model, but we nerver train it directly\n",
    "cnn_out_model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# train\n",
    "hist=model.fit(vectorized_data_padded,classes_1hot,batch_size=100,verbose=1,epochs=10,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to note:\n",
    "1. We are using ReLU activation as it simplifies our life\n",
    "2. The word embeddings are now fixed, i.e. the training algorithm is not allowed to change the pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History: [0.8323999953269958, 0.857999997138977, 0.867999997138977, 0.8723999953269959, 0.8811999988555909, 0.8872000026702881, 0.8872000002861022, 0.8912000012397766, 0.8935999989509582, 0.8928000020980835]\n",
      "Max accuracy: 0.8935999989509582\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"History:\",hist.history[\"val_acc\"])\n",
    "print(\"Max accuracy:\",numpy.max(hist.history[\"val_acc\"]))\n",
    "plt.ylim(0.85,1.0)\n",
    "plt.plot(hist.history[\"val_acc\"],label=\"Validation set accuracy\")\n",
    "plt.plot(hist.history[\"acc\"],label=\"Training set accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make predictions for the whole training and validation data to see what type of bigrams each kernel has learnt to recognize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 4s 2ms/step\n",
      "Predictions shape: (2500, 2225, 50)\n"
     ]
    }
   ],
   "source": [
    "input_data = hist.validation_data[0] # Use vectorized_data_padded if you want activations for the training data as well\n",
    "predictions = cnn_out_model.predict(input_data, verbose=1, batch_size=64)\n",
    "print(\"Predictions shape:\", predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embeddings from the model: (47852, 300)\n",
      "Kernels: (2, 300, 50)\n",
      "Kernel 0:\n",
      "still manages | still manages | still brings | still unveils | today Jake | still makes | still makes | still makes | today adventure | still finds\n",
      "Hypothetical maximum activation 0: today uncovers [0.9590905 0.8074217] \n",
      "\n",
      "Kernel 1:\n",
      "zero emotion | no redeeming | no redeeming | no redeeming | no redeeming | no redeeming | no redeeming | no redeeming | no redeeming | no redeeming\n",
      "Hypothetical maximum activation 1: whatsoever redeeming [1.1030507  0.87583375] \n",
      "\n",
      "Kernel 2:\n",
      "absolutely perfect | absolutely perfect | also perfect | is perfect | is perfect | is perfect | is perfect | is perfect | is perfect | is perfect\n",
      "Hypothetical maximum activation 2: hereby perfect [0.60775065 1.5542    ] \n",
      "\n",
      "Kernel 3:\n",
      "boring scenes | boring scenes | dull with | boring with | boring with | boring with | boring with | dull characters | dull and | dull and\n",
      "Hypothetical maximum activation 3: dull Editing [1.0966085 0.4052556] \n",
      "\n",
      "Kernel 4:\n",
      "She superb | does superb | simply superb | It wonderful | It brilliant | It terrific | is superb | is superb | is superb | is superb\n",
      "Hypothetical maximum activation 4: It superb [0.6299753 1.0392431] \n",
      "\n",
      "Kernel 5:\n",
      "worse <SPECIAL> | worse screenplay | poor script | poor script | lousy script | lousy script | bad script | bad script | bad script | bad script\n",
      "Hypothetical maximum activation 5: worse Composition [0.8640836  0.36686298] \n",
      "\n",
      "Kernel 6:\n",
      "very favorites | very favorites | my favorite | my favorite | my favorite | my favorite | my favorite | my favorite | my favorite | my favorite\n",
      "Hypothetical maximum activation 6: also favorite [0.95534784 1.7217857 ] \n",
      "\n",
      "Kernel 7:\n",
      "downright embarrassing | downright ridiculous | utterly lame | utterly laughable | utterly pointless | utterly pointless | utterly unconvincing | patently absurd | Totally lame | Totally lame\n",
      "Hypothetical maximum activation 7: patently lame [0.7064622  0.88622886] \n",
      "\n",
      "Kernel 8:\n",
      "world With | world With | world we | world we | dreams Without | world That | world All | world All | reality His | reality we\n",
      "Hypothetical maximum activation 8: worlds Without [0.8928259 0.4354313] \n",
      "\n",
      "Kernel 9:\n",
      "save what | save thing | save two | saved After | save yourself | save yourself | save yourself | saving grace | saving grace | saving grace\n",
      "Hypothetical maximum activation 9: save Assuming [0.90862274 0.4307066 ] \n",
      "\n",
      "Kernel 10:\n",
      "Worst script | incoherent script | worst acting | worst acting | worst acting | abysmal screenplay | worst written | poorly scripted | poorly filmed | poorly directed\n",
      "Hypothetical maximum activation 10: worst script [1.0209291 0.7113825] \n",
      "\n",
      "Kernel 11:\n",
      "awful attempt | awful directing | horrible parody | horrible parody | horrid film | horrid film | dreadful directing | awful film | awful film | awful film\n",
      "Hypothetical maximum activation 11: horrid Directed [0.88364494 0.46863887] \n",
      "\n",
      "Kernel 12:\n",
      "liked it | liked it | liked it | liked it | liked it | liked it | liked it | liked it | liked it | liked it\n",
      "Hypothetical maximum activation 12: liked film [0.8821121 0.8275025] \n",
      "\n",
      "Kernel 13:\n",
      "movie sorry | movie Sorry | movie Oh | movie Oh | movie Oh | movie oh | movie oh | movie fails | movie fails | movie fails\n",
      "Hypothetical maximum activation 13: porn oops [0.6134886 1.025104 ] \n",
      "\n",
      "Kernel 14:\n",
      "classic performance | sophisticated performances | powerful performance | Criterion DVD | finest performance | finest performance | finest performance | nuanced performances | feature DVD | Collection DVD\n",
      "Hypothetical maximum activation 14: versatile DVD [0.65342605 0.95893013] \n",
      "\n",
      "Kernel 15:\n",
      "Experiment delivers | twists delivers | consistently delivers | brilliantly illustrates | Visitor delivers | Shaw delivers | expertly captures | Jake delivers | best showcases | Christine provides\n",
      "Hypothetical maximum activation 15: Highly delivers [0.5125471 0.9856653] \n",
      "\n",
      "Kernel 16:\n",
      "couldn make | couldn make | couldn make | couldn make | could make | could make | could make | could make | could make | could make\n",
      "Hypothetical maximum activation 16: couldn make [0.74135506 0.8067725 ] \n",
      "\n",
      "Kernel 17:\n",
      "stays true | still true | Quite gem | is gem | is gem | is gem | quite true | quite true | is true | is true\n",
      "Hypothetical maximum activation 17: thrives gem [0.67635965 0.8929663 ] \n",
      "\n",
      "Kernel 18:\n",
      "Irene Dunne | Jose Ferrer | José Ferrer | José Ferrer | Raoul Walsh | Raoul Walsh | Errol Flynn | Errol Flynn | Errol Flynn | Errol Flynn\n",
      "Hypothetical maximum activation 18: Edouard Flynn [0.77107143 0.4183715 ] \n",
      "\n",
      "Kernel 19:\n",
      "Great soundtrack | Great film | Great film | great soundtrack | great soundtrack | Great movie | Great Movies | great film | great film | great film\n",
      "Hypothetical maximum activation 19: Great worksheets [1.0821922 0.6044347] \n",
      "\n",
      "Kernel 20:\n",
      "lackluster cliche | worst stereotypes | worst cheap | tacky cheap | idiotic cheap | ending cheap | vicious stereotyping | stupid stereotyped | predictable cliché | up stereotype\n",
      "Hypothetical maximum activation 20: lackluster stereotype [0.5978513 0.7272793] \n",
      "\n",
      "Kernel 21:\n",
      "actors seem | actors somehow | actors <SPECIAL> | actors <SPECIAL> | actors <SPECIAL> | actors <SPECIAL> | actors <SPECIAL> | actors seemed | actors attempt | actor wants\n",
      "Hypothetical maximum activation 21: actors fails [0.94465697 0.62374675] \n",
      "\n",
      "Kernel 22:\n",
      "be stupid | be stupid | be stupid | extremely stupid | were stupid | mildly insulting | with stupid | with stupid | this stupid | this stupid\n",
      "Hypothetical maximum activation 22: eb vulgar [0.38588038 0.71248615] \n",
      "\n",
      "Kernel 23:\n",
      "works tremendously | episodes miniseries | works extremely | episodes results | works very | works very | episodes It | works thematically | works well | works well\n",
      "Hypothetical maximum activation 23: episodes award [1.04241   0.7543996] \n",
      "\n",
      "Kernel 24:\n",
      "this poorly | this poorly | this poorly | extremely poorly | How badly | how poorly | so poorly | so poorly | so poorly | so poorly\n",
      "Hypothetical maximum activation 24: Wow poorly [0.52185965 1.1049047 ] \n",
      "\n",
      "Kernel 25:\n",
      "great job | great job | great job | great job | great job | great job | great job | great job | great job | great job\n",
      "Hypothetical maximum activation 25: great job [1.0496422  0.93632346] \n",
      "\n",
      "Kernel 26:\n",
      "not Why | not Why | not Why | Avoid Avoid | stupid Avoid | qualities Avoid | decent Avoid | authenticity Why | words Avoid | idiot Why\n",
      "Hypothetical maximum activation 26: levy Avoid [0.5421316 1.4187831] \n",
      "\n",
      "Kernel 27:\n",
      "fails If | fails The | fails to | fails to | fails to | fails to | fails to | fails to | fails to | fails to\n",
      "Hypothetical maximum activation 27: fails Directed [0.93705064 0.31097046] \n",
      "\n",
      "Kernel 28:\n",
      "breathtaking cinematography | stunning visuals | stunning cinematography | eerie soundtrack | stunning movie | captivating mood | superb soundtrack | breathtaking monologue | amazing movie | amazing film\n",
      "Hypothetical maximum activation 28: breathtaking thriller [1.1265565  0.58457994] \n",
      "\n",
      "Kernel 29:\n",
      "worst The | worst The | Worst script | worst writing | worst written | worst This | worst acting | worst acting | worst acting | worst film\n",
      "Hypothetical maximum activation 29: worst Filming [0.92975307 0.5338904 ] \n",
      "\n",
      "Kernel 30:\n",
      "and wry | with wry | and humorous | and hilarious | and hilarious | and hilarious | and hilarious | and hilarious | and hilarious | and hilarious\n",
      "Hypothetical maximum activation 30: and wry [0.5338451 0.9419282] \n",
      "\n",
      "Kernel 31:\n",
      "fun and | fun and | fun and | fun and | fun and | fun and | fun and | fun and | fun and | fun and\n",
      "Hypothetical maximum activation 31: friendships and [0.7617852 0.5373909] \n",
      "\n",
      "Kernel 32:\n",
      "incredibly underwhelming | very tiresome | incredibly irritating | really tiresome | completely unconvincing | just tiresome | absolutely pathetic | absolutely pathetic | is tiresome | totally unconvincing\n",
      "Hypothetical maximum activation 32: unbelievably tiresome [0.55981505 0.91565   ] \n",
      "\n",
      "Kernel 33:\n",
      "loving this | loving it | loving it | loving it | emotional movie | love this | love this | love this | love this | love this\n",
      "Hypothetical maximum activation 33: loving this [1.1561577  0.49369502] \n",
      "\n",
      "Kernel 34:\n",
      "most fun | most fun | most fun | and fun | and fun | and fun | and fun | and fun | and fun | and fun\n",
      "Hypothetical maximum activation 34: comprises fun [0.5523245 1.1163677] \n",
      "\n",
      "Kernel 35:\n",
      "waste your | waste your | waste your | waste your | waste your | waste your | waste your | waste your | waste your | waste your\n",
      "Hypothetical maximum activation 35: waste Worst [1.1507039  0.40647697] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel 36:\n",
      "flimsy plot | flimsy plot | weak plot | weak plot | existent plot | lacking storyline | discernible plot | discernible plot | Worst plot | bad plot\n",
      "Hypothetical maximum activation 36: Useless plot [0.5839009 0.6621209] \n",
      "\n",
      "Kernel 37:\n",
      "flawless acting | superb soundtrack | beautifully crafted | superbly performed | perfectly crafted | flawless performance | superb film | superb film | perfect film | perfect film\n",
      "Hypothetical maximum activation 37: flawless Produced [1.212911   0.54238904] \n",
      "\n",
      "Kernel 38:\n",
      "Frank Sinatra | Frank Sinatra | Frank Sinatra | Frank Sinatra | unexpected gritty | Clint Eastwood | Clint Eastwood | Clint Eastwood | Clint Eastwood | Clint Eastwood\n",
      "Hypothetical maximum activation 38: Vicente Sinatra [0.5512372  0.58232844] \n",
      "\n",
      "Kernel 39:\n",
      "just awful | just awful | just awful | just awful | just awful | just horrible | just horrible | just horrible | just horrible | just horrible\n",
      "Hypothetical maximum activation 39: just awful [0.8347242  0.92426133] \n",
      "\n",
      "Kernel 40:\n",
      "WRONG OK | re supposed | re supposed | re supposed | re supposed | re supposed | re supposed | re supposed | re supposed | re supposed\n",
      "Hypothetical maximum activation 40: OLD Oh [0.62383586 0.9800966 ] \n",
      "\n",
      "Kernel 41:\n",
      "boring Maybe | embarrassing Maybe | incoherent Why | ridiculous script | asinine script | mess Why | pointless Characters | laughable Are | annoying characters | annoying characters\n",
      "Hypothetical maximum activation 41: laughable Did [0.6626561 0.6365841] \n",
      "\n",
      "Kernel 42:\n",
      "everyday life | everyday life | everyday life | lives life | turbulent life | true adventure | life journey | political life | exciting life | family life\n",
      "Hypothetical maximum activation 42: realism life [0.6244784 0.6406526] \n",
      "\n",
      "Kernel 43:\n",
      "one of | one of | one of | one of | one of | one of | one of | one of | one of | one of\n",
      "Hypothetical maximum activation 43: one of [0.62431276 0.35881215] \n",
      "\n",
      "Kernel 44:\n",
      "so lackluster | was bad | was bad | was bad | was bad | was bad | was bad | was bad | was bad | was bad\n",
      "Hypothetical maximum activation 44: was lackluster [0.6663768  0.87849927] \n",
      "\n",
      "Kernel 45:\n",
      "huge disappointment | huge disappointment | money waste | propaganda mediocre | cheap shoddy | utter disappointment | big disappointment | big disappointment | big disappointment | big disappointment\n",
      "Hypothetical maximum activation 45: money disappointment [0.95041335 0.92074543] \n",
      "\n",
      "Kernel 46:\n",
      "perfect family | enjoyed this | enjoyed this | enjoyed this | enjoyed this | enjoyed this | enjoyed this | enjoyed this | enjoyed this | enjoyed this\n",
      "Hypothetical maximum activation 46: appreciated family [0.9934538  0.65144175] \n",
      "\n",
      "Kernel 47:\n",
      "script didn | script doesn | screenwriter Don | script attempt | script was | script was | script was | script was | script was | script was\n",
      "Hypothetical maximum activation 47: script couldn [0.8824553  0.46638948] \n",
      "\n",
      "Kernel 48:\n",
      "Don waste | Don waste | Don waste | Don waste | Don waste | Don waste | Don waste | Don waste | Don waste | Don waste\n",
      "Hypothetical maximum activation 48: Don waste [0.82825124 0.9876604 ] \n",
      "\n",
      "Kernel 49:\n",
      "Highly Recommended | Highly Recommended | Highly recommended | Highly recommended | Highly recommended | Highly recommended | Highly recommended | Highly recommended | Highly recommended | Highly recommended\n",
      "Hypothetical maximum activation 49: Highly Recommended [0.748165   0.95554316] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_embeddings = model.layers[1].get_weights()[0]\n",
    "print(\"Word embeddings from the model:\", word_embeddings.shape)\n",
    "print(\"Kernels:\", model.layers[2].get_weights()[0].shape)\n",
    "for kernel_index in range(model.layers[2].get_weights()[0].shape[-1]):\n",
    "    kernel = model.layers[2].get_weights()[0][:,:,kernel_index] + model.layers[2].get_weights()[1][kernel_index]\n",
    "\n",
    "    # Hypothetical highest activations\n",
    "    activations = numpy.dot(kernel, word_embeddings.T)\n",
    "    best_word_indices = numpy.argmax(activations, axis=-1)\n",
    "    \n",
    "    # Highest activations seen in the validation data\n",
    "    max_time_steps = numpy.argmax(predictions[:,:,kernel_index], axis=-1)\n",
    "    max_activations = numpy.max(predictions[:,:,kernel_index], axis=-1)\n",
    "    best_sentences = numpy.argsort(-max_activations)\n",
    "    \n",
    "    best_ngrams = [input_data[best_sentences[nth]][max_time_steps[best_sentences[nth]]:max_time_steps[best_sentences[nth]]+window_size] for nth in range(10)]\n",
    "    best_ngrams = [' '.join([inversed_vocabulary[i] for i in best]) for best in best_ngrams]\n",
    "    best_ngrams = ' | '.join(best_ngrams)\n",
    " \n",
    "    print('Kernel %s:' % kernel_index)\n",
    "    print(best_ngrams)\n",
    "    print('Hypothetical maximum activation %s:' % kernel_index, ' '.join([inversed_vocabulary[wi] for wi in best_word_indices]), numpy.max(activations, axis=-1), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at some of the kernels, e.g. kernel 10:\n",
    "\n",
    "Worst script | incoherent script | worst acting | worst acting | worst acting | abysmal screenplay | worst written | poorly scripted | poorly filmed | poorly directed\n",
    "Hypothetical maximum activation 10: worst script [1.0209291 0.7113825]\n",
    "\n",
    "* The activating bigram seems to be a negative adjective and a movie related concept\n",
    "* The hypothetical maximum activation we can generate with the given vocabulary is \"worst script\", which is very close to the first actual hit, however, this is not always the case:\n",
    "\n",
    "Kernel 13:\n",
    "movie sorry | movie Sorry | movie Oh | movie Oh | movie Oh | movie oh | movie oh | movie fails | movie fails | movie fails\n",
    "\n",
    "Hypothetical maximum activation 13: porn oops [0.6134886 1.025104 ]\n",
    "\n",
    "Sometimes the kernels are uninterpretable or they make unrealistic assumptions about the the shape of the word embedding space.\n",
    "\n",
    "* Window size does not force the kernel to learn certain length n-grams (only sets an upper boundary):\n",
    "\n",
    "Kernel 19:\n",
    "Great soundtrack | Great film | Great film | great soundtrack | great soundtrack | Great movie | Great Movies | great film | great film | great film\n",
    "\n",
    "Hypothetical maximum activation 19: Great worksheets [1.0821922 0.6044347]\n",
    "\n",
    "If we look at the maximum activations for each slot in the above kernel, we notice that the first word has almost twice as high activation as the second one. This means that basically the first word has to be \"great\" and the second word can be almost anything, i.e. the kernel is only detecting unigrams.\n",
    "\n",
    "* Looking at the kernel activations does not tell us anything about the kernel importance or relatedness to a certain output (e.g. positive review). To analyze these aspects of the network we have to look into the dense layers following the convolutional layer. This, however, is not straightforward as both CNN kernel activation strengths and dense layer weights should be analyzed together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
