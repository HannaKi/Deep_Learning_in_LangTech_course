{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Interpreting Convolutional Kernels\n",
    "\n",
    "This example shows how to analyze kernel activations for given input texts or with hypothetical word sequences.\n",
    "The example is based on our previous IMDB movie review sentiment classification notes. The relevant information starts from the NN model definition, reading the data and pretrained word embeddings is identical/similar to what we have seen previously.\n",
    "\n",
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class': 'pos', 'text': 'Whoopi was the only reason I watched the Oscars that year. She is hilarious. Of course there was a major serious side to the show. She was great not only because she\\'s funny, but because she said some things that needed to be said in a public forum. White folks need to be reminded that Hollywood awards\\' ceremonies, employment, and representation are WAY out of balance racially. There should be no need for \\\\black\\\\\" awards shows. The white-bread, milquetoast nominators and judges need to bring their heads into the sunshine and see that great material is not limited to \\\\\"white\\\\\" directors, producers, actors, etc. Allowing Woody Allen on the air was the depth of poor taste. He had no business being there. The fact of the matter is, this is the first Oscar presentation I\\'ve watched since \\\\\"The Color Purple\\\\\" was up for awards. That miscarriage of voting soured me on watching the shows until 2002. Which is not to denigrate other presenters. Billy Crystal is a riot.\"'}\n",
      "['Whoopi was the only reason I watched the Oscars that year. She is hilarious. Of course there was a major serious side to the show. She was great not only because she\\'s funny, but because she said some things that needed to be said in a public forum. White folks need to be reminded that Hollywood awards\\' ceremonies, employment, and representation are WAY out of balance racially. There should be no need for \\\\black\\\\\" awards shows. The white-bread, milquetoast nominators and judges need to bring their heads into the sunshine and see that great material is not limited to \\\\\"white\\\\\" directors, producers, actors, etc. Allowing Woody Allen on the air was the depth of poor taste. He had no business being there. The fact of the matter is, this is the first Oscar presentation I\\'ve watched since \\\\\"The Color Purple\\\\\" was up for awards. That miscarriage of voting soured me on watching the shows until 2002. Which is not to denigrate other presenters. Billy Crystal is a riot.\"', 'Sadly, the print of the film we were going to watch burned in the fire at Universal Studios last week, so we were stuck with video. That could even be a metaphor for this second-rate King Kong movie from Toho studios\\' stalwart director Ishiro Honda. Essentially it\\'s a warm up for \\\\King Kong versus Godzilla\\\\\". It even uses the idea of a Mecha-Kong, like Mecha-Godzilla. Of course the movie climaxes with King Kong fighting Mecha-Kong on top of the expo tower in Tokyo, but if you didn\\'t know that already then maybe you\\'re in the age group that this movie was intended for.  The cast is headed by a guy named Rhodes Reason who we had never heard of... glancing over his list I see mostly a lot of scattered American TV credits, so it\\'s interesting that they dragged him all the way to Japan so that they could have a nominal American hero. The real hero of the movie is the more sensitive Japanese commander played by Akira Takarada, who I recognized from Hiroshi Inagaki\\'s iconic version of \\\\\"Chushingura\\\\\" (47 Ronin) and also from the original Godzilla films by Honda. I\\'m sorry Rhodes Reason whoever you are, but this guy has way more screen presence and you can bet that everyone wants him to end up with the cute little blonde, played by Linda Miller. We laughed at the way Reason would always find a way to interject himself between Miller and Takarada, who it seemed like she kind of preferred. Of course like all Kong leading ladies her primary relationship is with the King himself. She discovers a nice trick: if you talk to a giant ape really..... really.... slowly..... he\\'ll understand what you\\'re saying. And if you\\'re a blonde gal, that means that he\\'ll do whatever you tell him to do. That fact is not lost on Dr. Who (Eisei Amamoto) and Madame Piranha (Mie Hama) -- representing a \\\\\"nation which shall not be named\\\\\" -- who plan on using her as bait to get Kong to dig up mineral deposits that are trapped at the North Pole.  Yes, this is truly the plot of the whole movie -- apparently only a giant ape is going to be capable of digging out these minerals which can be used to make super powerful weapons. Dr. Who builds Mecha-Kong to get it but the circuitry gets in the way, so they decide to go for the real Kong. Kong himself seems momentarily infatuated with Mecha-Kong, a story element that might have made the film more interesting but wasn\\'t followed up on.  By the end of the movie, the cute blonde has shouted \\\\\"Kong\\\\\" or \\\\\"King Kong\\\\\" in her chirpy voice so many times that when the two heroes tell her to let him go at the end they\\'re speaking for all of us. Basically this movie squanders whatever majesty was possible in the Kong character by making him a heroic and friendly figure much too early, just like the newest version of the story. Kong is just a guy in a suit in this movie, and they show quite a lot of him to the point where the goofy face becomes impossible to take seriously. It\\'s a nice looking movie, I\\'m sure it satisfies the demands or desires of fans of this type of thing, which is really more of a wrestling film than a monster film in a lot of ways. The monsters don\\'t ever really scare in these films, they just jump around and push each other around a lot. It\\'s not a worthless movie, but it\\'s extremely predictable and formulaic so for anyone under the age of 10 or so it probably will only be entertaining as comedy.\"']\n",
      "['pos', 'neg']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "with open(\"data/imdb_train.json\") as f:\n",
    "    data=json.load(f)\n",
    "random.shuffle(data) \n",
    "print(data[0])\n",
    "\n",
    "# We need to gather the texts, into a list\n",
    "texts=[one_example[\"text\"] for one_example in data]\n",
    "labels=[one_example[\"class\"] for one_example in data]\n",
    "print(texts[:2])\n",
    "print(labels[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use gensim to read the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words from embedding model: 50000\n",
      "First 50 words: [',', 'the', '.', 'and', 'of', 'to', 'in', 'a', '\"', ':', ')', 'that', '(', 'is', 'for', 'on', '*', 'with', 'as', 'it', 'The', 'or', 'was', \"'\", \"'s\", 'by', 'from', 'at', 'I', 'this', 'you', '/', 'are', '=', 'not', '-', 'have', '?', 'be', 'which', ';', 'all', 'his', 'has', 'one', 'their', 'about', 'but', 'an', '|']\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "vector_model=KeyedVectors.load_word2vec_format(\"data/wiki-news-300d-1M.vec\", binary=False, limit=50000)\n",
    "\n",
    "# sort based on the index to make sure they are in the correct order\n",
    "words=[k for k,v in sorted(vector_model.vocab.items(), key=lambda x:x[1].index)]\n",
    "print(\"Words from embedding model:\",len(words))\n",
    "print(\"First 50 words:\",words[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the vectors\n",
    "\n",
    "- Easier to learn on top of these vectors when the magnitude does not vary much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before normalization: [-0.0234 -0.0268 -0.0838  0.0386 -0.0321  0.0628  0.0281 -0.0252  0.0269\n",
      " -0.0063]\n",
      "After normalization: [-0.0163762  -0.01875564 -0.05864638  0.02701372 -0.02246478  0.04394979\n",
      "  0.01966543 -0.0176359   0.01882563 -0.00440898]\n"
     ]
    }
   ],
   "source": [
    "print(\"Before normalization:\",vector_model.get_vector(\"in\")[:10])\n",
    "vector_model.init_sims(replace=True)\n",
    "print(\"After normalization:\",vector_model.get_vector(\"in\")[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text analyzer and vectorizer\n",
    "\n",
    "- When we use an embedding layer (keras.layers.Embedding) the input data must be a sequence, not a bag-of-words vector\n",
    "- You can use CountVectorizer only as an analyzer without building the feature matrix\n",
    "- We will then build the vectorizer part later ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Whoopi', 'was', 'the', 'only', 'reason', 'watched', 'the', 'Oscars', 'that', 'year', 'She', 'is', 'hilarious', 'Of', 'course', 'there', 'was', 'major', 'serious', 'side', 'to', 'the', 'show', 'She', 'was', 'great', 'not', 'only', 'because', 'she', 'funny', 'but', 'because', 'she', 'said', 'some', 'things', 'that', 'needed', 'to', 'be', 'said', 'in', 'public', 'forum', 'White', 'folks', 'need', 'to', 'be', 'reminded', 'that', 'Hollywood', 'awards', 'ceremonies', 'employment', 'and', 'representation', 'are', 'WAY', 'out', 'of', 'balance', 'racially', 'There', 'should', 'be', 'no', 'need', 'for', 'black', 'awards', 'shows', 'The', 'white', 'bread', 'milquetoast', 'nominators', 'and', 'judges', 'need', 'to', 'bring', 'their', 'heads', 'into', 'the', 'sunshine', 'and', 'see', 'that', 'great', 'material', 'is', 'not', 'limited', 'to', 'white', 'directors', 'producers', 'actors', 'etc', 'Allowing', 'Woody', 'Allen', 'on', 'the', 'air', 'was', 'the', 'depth', 'of', 'poor', 'taste', 'He', 'had', 'no', 'business', 'being', 'there', 'The', 'fact', 'of', 'the', 'matter', 'is', 'this', 'is', 'the', 'first', 'Oscar', 'presentation', 've', 'watched', 'since', 'The', 'Color', 'Purple', 'was', 'up', 'for', 'awards', 'That', 'miscarriage', 'of', 'voting', 'soured', 'me', 'on', 'watching', 'the', 'shows', 'until', '2002', 'Which', 'is', 'not', 'to', 'denigrate', 'other', 'presenters', 'Billy', 'Crystal', 'is', 'riot']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy\n",
    "analyzer=CountVectorizer(lowercase=False).build_analyzer() # includes tokenizer and preprocessing\n",
    "print(analyzer(texts[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand the vocabulary using words from the embedding model\n",
    "\n",
    "- The embedding model usually knows more words than the task specific model, because it has seen a lot more data\n",
    "- If you wish, you can use the embedding model vocabulary to expand the task specific one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words from embedding model: 47852\n"
     ]
    }
   ],
   "source": [
    "# init the vectorizer vocabulary using words from the embedding model\n",
    "def init_vocabulary(vocab, text, text_analyzer):\n",
    "    for word in analyzer(text):\n",
    "        # Only use pretrained vocabulary\n",
    "        if word in vector_model.vocab:\n",
    "            vocab.setdefault(word, len(vocab))\n",
    "    return vocab\n",
    "\n",
    "words_from_model=\" \".join(words[:50000]) # use 50K words from the embedding model to initialize the vocabulary --> expands the learned vocabulary\n",
    "vocabulary={\"<SPECIAL>\": 0} # zero has a special meaning in sequence models, prevent using it for a normal word\n",
    "vocabulary=init_vocabulary(vocabulary, words_from_model, analyzer)\n",
    "print(\"Words from embedding model:\",len(vocabulary))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizer\n",
    "\n",
    "- Build a dictionary to turn words into numbers, here we use the one which we initialized with the embedding model\n",
    "- Vectorizing a sequence: In our data each example is a list of words, we need to turn each example into list of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in vocabulary: 47852\n",
      "Vectorized data shape: (25000,)\n",
      "First example vectorized: [15, 1, 45, 430, 3700, 1, 16836, 6, 117, 593, 7, 11060, 1578, 288, 62, 15, 499, 1376, 541, 4, 1, 198, 593, 15, 353, 22, 45, 78, 131, 3228, 32, 78, 131, 34, 48, 252, 6, 692, 4, 24, 34, 5, 199, 3090, 1363, 3647, 206, 4, 24, 10194, 6, 2762, 2025, 9781, 1728, 2, 3714, 21, 35365, 75, 3, 1503, 21931, 374, 108, 24, 82, 206, 8, 827, 2025, 596, 13, 851, 5214, 29572, 2, 2735, 206, 4, 1216, 30, 2882, 70, 1, 12023, 2, 112, 6, 353, 338, 7, 22, 1166, 4, 851, 3559, 3091, 3081, 1265, 28631, 16003, 3803, 9, 1, 829, 15, 1, 3341, 3, 777, 3672, 140, 43, 82, 242, 100, 62, 13, 365, 3, 1, 572, 7, 19, 7, 1, 90, 5748, 2430, 1095, 3700, 120, 13, 11219, 15125, 15, 71, 8, 2025, 291, 27444, 3, 2200, 38115, 84, 9, 2175, 1, 596, 222, 906, 3262, 7, 22, 4, 39274, 53, 14008, 5230, 10035, 7, 10300]\n",
      "First example text: ['was', 'the', 'only', 'reason', 'watched', 'the', 'Oscars', 'that', 'year', 'She', 'is', 'hilarious', 'Of', 'course', 'there', 'was', 'major', 'serious', 'side', 'to', 'the', 'show', 'She', 'was', 'great', 'not', 'only', 'because', 'she', 'funny', 'but', 'because', 'she', 'said', 'some', 'things', 'that', 'needed', 'to', 'be', 'said', 'in', 'public', 'forum', 'White', 'folks', 'need', 'to', 'be', 'reminded', 'that', 'Hollywood', 'awards', 'ceremonies', 'employment', 'and', 'representation', 'are', 'WAY', 'out', 'of', 'balance', 'racially', 'There', 'should', 'be', 'no', 'need', 'for', 'black', 'awards', 'shows', 'The', 'white', 'bread', 'nominators', 'and', 'judges', 'need', 'to', 'bring', 'their', 'heads', 'into', 'the', 'sunshine', 'and', 'see', 'that', 'great', 'material', 'is', 'not', 'limited', 'to', 'white', 'directors', 'producers', 'actors', 'etc', 'Allowing', 'Woody', 'Allen', 'on', 'the', 'air', 'was', 'the', 'depth', 'of', 'poor', 'taste', 'He', 'had', 'no', 'business', 'being', 'there', 'The', 'fact', 'of', 'the', 'matter', 'is', 'this', 'is', 'the', 'first', 'Oscar', 'presentation', 've', 'watched', 'since', 'The', 'Color', 'Purple', 'was', 'up', 'for', 'awards', 'That', 'miscarriage', 'of', 'voting', 'soured', 'me', 'on', 'watching', 'the', 'shows', 'until', '2002', 'Which', 'is', 'not', 'to', 'denigrate', 'other', 'presenters', 'Billy', 'Crystal', 'is', 'riot']\n"
     ]
    }
   ],
   "source": [
    "def vectorizer(vocab, texts):\n",
    "    vectorized_data=[] # turn text into numbers based on our vocabulary mapping\n",
    "    for one_example in texts:\n",
    "        vectorized_example=[]\n",
    "        for word in analyzer(one_example):\n",
    "            # Only use pretrained vocabulary\n",
    "            if word in vector_model.vocab:\n",
    "                vectorized_example.append(vocab[word])\n",
    "            #vocab.setdefault(word, len(vocab)) # add word to our vocabulary if it does not exist\n",
    "            #vectorized_example.append(vocab[word])\n",
    "        vectorized_data.append(vectorized_example)\n",
    "    \n",
    "    vectorized_data=numpy.array(vectorized_data) # turn python list into numpy matrix\n",
    "    return vectorized_data, vocab\n",
    "\n",
    "vectorized_data, vocabulary=vectorizer(vocabulary, texts)\n",
    "\n",
    "# now vectorized data is the same as feature_matrix, but in different format\n",
    "print(\"Words in vocabulary:\",len(vocabulary))\n",
    "print(\"Vectorized data shape:\",vectorized_data.shape)\n",
    "print(\"First example vectorized:\",vectorized_data[0])\n",
    "inversed_vocabulary={value:key for key, value in vocabulary.items()} # inverse the dictionary\n",
    "print(\"First example text:\",[inversed_vocabulary[idx] for idx in vectorized_data[0]])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels into onehot vectors\n",
    "\n",
    "- Same as in the original BOW classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_numbers shape= (25000,)\n",
      "class_numbers [1 0 1 ... 0 0 0]\n",
      "class labels ['neg' 'pos']\n",
      "classes_1hot [[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "label_encoder=LabelEncoder() #Turns class labels into integers\n",
    "one_hot_encoder=OneHotEncoder(sparse=False) #Turns class integers into one-hot encoding\n",
    "class_numbers=label_encoder.fit_transform(labels)\n",
    "print(\"class_numbers shape=\",class_numbers.shape)\n",
    "print(\"class_numbers\",class_numbers)\n",
    "print(\"class labels\",label_encoder.classes_)\n",
    "#And now yet the one-hot encoding\n",
    "classes_1hot=one_hot_encoder.fit_transform(class_numbers.reshape(-1,1))\n",
    "print(\"classes_1hot\",classes_1hot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network\n",
    "\n",
    "- First we need to create an embedding matrix which we can then plug into the neural network\n",
    "- The embedding matrix must follow the order from the vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pretrained vectors for 47851 words.\n",
      "Shape of pretrained embeddings: (47852, 300)\n",
      "Vector for the word 'in': [-0.0163762  -0.01875564 -0.05864638  0.02701372 -0.02246478  0.04394979\n",
      "  0.01966543 -0.0176359   0.01882563 -0.00440898]\n"
     ]
    }
   ],
   "source": [
    "def load_pretrained_embeddings(vocab, embedding_model):\n",
    "    \"\"\" vocab: vocabulary from our data vectorizer, embedding_model: model loaded with gensim \"\"\"\n",
    "    pretrained_embeddings=numpy.random.uniform(low=-0.05, high=0.05, size=(len(vocab),embedding_model.vectors.shape[1])) # initialize new matrix (words x embedding dim)\n",
    "    found=0\n",
    "    for word,idx in vocab.items():\n",
    "        if word in embedding_model.vocab:\n",
    "            pretrained_embeddings[idx]=embedding_model.get_vector(word)\n",
    "            found+=1\n",
    "            \n",
    "    print(\"Found pretrained vectors for {found} words.\".format(found=found))\n",
    "    return pretrained_embeddings\n",
    "\n",
    "pretrained=load_pretrained_embeddings(vocabulary, vector_model)\n",
    "print(\"Shape of pretrained embeddings:\",pretrained.shape)\n",
    "print(\"Vector for the word 'in':\",pretrained[vocabulary[\"in\"]][:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Sequential input\n",
    "\n",
    "- Remember how the shape of the input data matrix had undefined number of columns\n",
    "- Now we must make it into fixed size (same for each example)\n",
    "- Padding: include zeros until you reach the correct size\n",
    "- You will hear more about this next week!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old shape: (25000,)\n",
      "New shape: (25000, 2226)\n",
      "First example: [15  1 45 ...  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "### Only needed for me, not to block the whole GPU, you don't need this stuff\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "set_session(tf.Session(config=config))\n",
    "### ---end of weird stuff\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "print(\"Old shape:\", vectorized_data.shape)\n",
    "vectorized_data_padded=pad_sequences(vectorized_data, padding='post')\n",
    "print(\"New shape:\", vectorized_data_padded.shape)\n",
    "print(\"First example:\", vectorized_data_padded[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple network with a single convolutional layer with window size of 2 words (bigrams), 50 kernels and global max pooling (only the maximum value from each kernel is preserved). We create a separate model with the CNN layer as the output. This model shares weights with the actual model and can be used in analysing the kernel activations in each time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:1213: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:2885: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 2226)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 2226, 300)         14355600  \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 2225, 50)          30050     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 14,385,752\n",
      "Trainable params: 30,152\n",
      "Non-trainable params: 14,355,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 22500 samples, validate on 2500 samples\n",
      "Epoch 1/10\n",
      "22500/22500 [==============================] - 13s 571us/step - loss: 0.5158 - acc: 0.7772 - val_loss: 0.3997 - val_acc: 0.8312\n",
      "Epoch 2/10\n",
      "22500/22500 [==============================] - 9s 391us/step - loss: 0.3462 - acc: 0.8561 - val_loss: 0.3491 - val_acc: 0.8508\n",
      "Epoch 3/10\n",
      "22500/22500 [==============================] - 9s 395us/step - loss: 0.3018 - acc: 0.8749 - val_loss: 0.3279 - val_acc: 0.8556\n",
      "Epoch 4/10\n",
      "22500/22500 [==============================] - 9s 391us/step - loss: 0.2740 - acc: 0.8888 - val_loss: 0.3125 - val_acc: 0.8656\n",
      "Epoch 5/10\n",
      "22500/22500 [==============================] - 9s 391us/step - loss: 0.2525 - acc: 0.9008 - val_loss: 0.3039 - val_acc: 0.8692\n",
      "Epoch 6/10\n",
      "22500/22500 [==============================] - 9s 394us/step - loss: 0.2340 - acc: 0.9079 - val_loss: 0.2978 - val_acc: 0.8716\n",
      "Epoch 7/10\n",
      "22500/22500 [==============================] - 9s 386us/step - loss: 0.2193 - acc: 0.9150 - val_loss: 0.2968 - val_acc: 0.8752\n",
      "Epoch 8/10\n",
      "22500/22500 [==============================] - 9s 395us/step - loss: 0.2041 - acc: 0.9230 - val_loss: 0.2900 - val_acc: 0.8768\n",
      "Epoch 9/10\n",
      "22500/22500 [==============================] - 9s 391us/step - loss: 0.1919 - acc: 0.9295 - val_loss: 0.2878 - val_acc: 0.8804\n",
      "Epoch 10/10\n",
      "22500/22500 [==============================] - 9s 396us/step - loss: 0.1798 - acc: 0.9355 - val_loss: 0.2911 - val_acc: 0.8812\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, Activation, Conv1D, GlobalMaxPooling1D\n",
    "from keras import backend as K\n",
    "from keras.layers.core import Lambda\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "\n",
    "example_count,sequence_len=vectorized_data_padded.shape\n",
    "example_count,class_count=classes_1hot.shape\n",
    "\n",
    "vector_size=pretrained.shape[1] # embedding dim (\"hidden layer\") must be the same as in the pretrained model\n",
    "kernels = 50\n",
    "window_size = 2 # How many words a kernel sees at a time\n",
    "\n",
    "inp=Input(shape=(sequence_len,))\n",
    "embeddings=Embedding(len(vocabulary), vector_size, mask_zero=False, weights=[pretrained], trainable=False)(inp)\n",
    "cnn = Conv1D(kernels,window_size,padding='valid',activation='relu',strides=1)(embeddings)\n",
    "pooling = GlobalMaxPooling1D()(cnn)\n",
    "outp=Dense(class_count, activation=\"softmax\")(pooling)\n",
    "model=Model(inputs=[inp], outputs=[outp])\n",
    "\n",
    "optimizer=Adam(lr=0.001) # define the learning rate\n",
    "model.compile(optimizer=optimizer,loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "\n",
    "# This is our model for outputting the time step wise kernel activations.\n",
    "cnn_out_model=Model(inputs=[inp], outputs=[cnn])\n",
    "# We have to compile the model, but we nerver train it directly\n",
    "cnn_out_model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# train\n",
    "hist=model.fit(vectorized_data_padded,classes_1hot,batch_size=100,verbose=1,epochs=10,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to note:\n",
    "1. We are using ReLU activation as it simplifies our life\n",
    "2. The word embeddings are now fixed, i.e. the training algorithm is not allowed to change the pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History: [0.8311999988555908, 0.8508000040054321, 0.8555999994277954, 0.8655999970436096, 0.8691999983787536, 0.8715999960899353, 0.8751999974250794, 0.8768000030517578, 0.8804000020027161, 0.8812000036239624]\n",
      "Max accuracy: 0.8812000036239624\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"History:\",hist.history[\"val_acc\"])\n",
    "print(\"Max accuracy:\",numpy.max(hist.history[\"val_acc\"]))\n",
    "plt.ylim(0.85,1.0)\n",
    "plt.plot(hist.history[\"val_acc\"],label=\"Validation set accuracy\")\n",
    "plt.plot(hist.history[\"acc\"],label=\"Training set accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make predictions for the whole training and validation data to see what type of bigrams each kernel has learnt to recognize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 1s 596us/step\n",
      "Predictions shape: (2500, 2225, 50)\n"
     ]
    }
   ],
   "source": [
    "input_data = hist.validation_data[0] # Use vectorized_data_padded if you want activations for the training data as well\n",
    "predictions = cnn_out_model.predict(input_data, verbose=1, batch_size=64)\n",
    "print(\"Predictions shape:\", predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embeddings from the model: (47852, 300)\n",
      "Kernels: (2, 300, 50)\n",
      "Kernel 0:\n",
      "heart wrenching | heart wrenching | heart change | delightful romp | delightful romp | heart gripping | superb script | Excellent movie | stunning movie | heart warmer\n",
      "Hypothetical maximum activation 0: superbly romp [0.66966677 0.4546876 ] \n",
      "\n",
      "Kernel 1:\n",
      "May 2007 | September 2007 | June 1980 | May 1934 | Jack Torrance | March 2002 | March 2005 | August 1913 | January 1991 | July 1876\n",
      "Hypothetical maximum activation 1: May Bravo [0.78071016 0.6589448 ] \n",
      "\n",
      "Kernel 2:\n",
      "incredibly unconvincing | extremely uninteresting | incredibly underwhelming | extremely lame | incredibly lame | incredibly lame | extremely forgettable | such lame | incredibly dull | equally uninteresting\n",
      "Hypothetical maximum activation 2: extraordinarily unconvincing [0.55913895 0.7739633 ] \n",
      "\n",
      "Kernel 3:\n",
      "favorite films | favorite films | favorite film | favorite film | favorite film | favorite film | favorite anime | favourite films | favourite films | favorite series\n",
      "Hypothetical maximum activation 3: favorites films [1.1387546 0.5396309] \n",
      "\n",
      "Kernel 4:\n",
      "script would | script would | actors Would | actors would | actors would | preposterous would | screenwriter would | director would | director would | director would\n",
      "Hypothetical maximum activation 4: credibility hypothetically [0.692766  0.6936389] \n",
      "\n",
      "Kernel 5:\n",
      "pretty bland | too bland | pretty disappointed | pretty disappointing | terribly disappointed | tremendously disappointing | unbelievably disappointed | huge waste | pretty forgettable | this waste\n",
      "Hypothetical maximum activation 5: pretty bland [0.60066223 0.7916678 ] \n",
      "\n",
      "Kernel 6:\n",
      "this drivel | this drivel | this drivel | this drivel | this drivel | this tripe | this tripe | stupid vapid | this lame | this lame\n",
      "Hypothetical maximum activation 6: director drivel [0.51933455 0.9159098 ] \n",
      "\n",
      "Kernel 7:\n",
      "well as | well as | well as | well as | well as | well as | well as | well as | well as | well as\n",
      "Hypothetical maximum activation 7: well well [0.5058623  0.42252144] \n",
      "\n",
      "Kernel 8:\n",
      "any credibility | any empathy | any empathy | any redeeming | any redeeming | any redeeming | any nuance | any flair | any suspense | any sense\n",
      "Hypothetical maximum activation 8: Unused gravitas [0.79511684 0.80633146] \n",
      "\n",
      "Kernel 9:\n",
      "still worth | still worth | today teaches | today uses | today It | still enjoyable | today kids | today it | today Definitely | today society\n",
      "Hypothetical maximum activation 9: today fun [1.3670956 1.0491753] \n",
      "\n",
      "Kernel 10:\n",
      "perfect and | perfect and | perfect and | perfect and | perfect as | perfect as | perfect as | perfect as | perfect as | perfect as\n",
      "Hypothetical maximum activation 10: perfect and [1.2041036  0.45006657] \n",
      "\n",
      "Kernel 11:\n",
      "superb directing | excellent cut | excellent directing | excellent My | superb direction | superb performances | superb along | superb job | superb job | superb job\n",
      "Hypothetical maximum activation 11: superb Watching [0.9774009 0.4350766] \n",
      "\n",
      "Kernel 12:\n",
      "Fontaine Fontaine | Kelly Lynch | Joan Fontaine | Romeo Diaz | Gene Tierney | Gene Tierney | Gene Tierney | Angelina Jolie | Angelina Jolie | Angelina Jolie\n",
      "Hypothetical maximum activation 12: Bette Camus [0.5411677 0.6073589] \n",
      "\n",
      "Kernel 13:\n",
      "boring boring | boring dialog | boring uninteresting | boring vapid | boring sequence | dull uninteresting | dull uninteresting | dull uninteresting | uninteresting boring | boring trite\n",
      "Hypothetical maximum activation 13: boring Manage [1.1357841  0.55306447] \n",
      "\n",
      "Kernel 14:\n",
      "is great | is great | is great | is great | is great | is great | is great | is great | is great | is great\n",
      "Hypothetical maximum activation 14: thrives great [0.585944   0.95442975] \n",
      "\n",
      "Kernel 15:\n",
      "writer was | Frankenstein was | screenplay was | screenplay was | screenplay was | scientist was | filmmaker was | film Was | rapist was | actor was\n",
      "Hypothetical maximum activation 15: screenwriter Utd [0.5885711 0.528466 ] \n",
      "\n",
      "Kernel 16:\n",
      "worst scripts | abysmal script | worst directed | worst acting | worst acting | worst acting | worst acting | worst acting | worst acting | worst directing\n",
      "Hypothetical maximum activation 16: worst script [1.4046819 1.1285478] \n",
      "\n",
      "Kernel 17:\n",
      "so poorly | so poorly | so poorly | so poorly | so poorly | so poor | so poor | so badly | so badly | so badly\n",
      "Hypothetical maximum activation 17: so inadequate [0.54746705 0.77617705] \n",
      "\n",
      "Kernel 18:\n",
      "and entertaining | and entertaining | and entertaining | and entertaining | and entertaining | and entertaining | and entertaining | and entertaining | and entertaining | and entertaining\n",
      "Hypothetical maximum activation 18: and entertaining [0.5635669 1.1568294] \n",
      "\n",
      "Kernel 19:\n",
      "only reason | only reason | only reason | only reason | only reason | only reason | only reason | only reason | only reason | only reason\n",
      "Hypothetical maximum activation 19: conceivably reason [0.54718906 0.7793425 ] \n",
      "\n",
      "Kernel 20:\n",
      "perfect job | perfect job | exquisite job | perfect performance | perfect performance | perfect choice | perfect choice | perfect leisurely | perfect setup | perfect bumbling\n",
      "Hypothetical maximum activation 20: perfect job [1.1471363  0.84628254] \n",
      "\n",
      "Kernel 21:\n",
      "strong friendship | true friendship | true friendship | close friendship | Their friendship | exciting finale | quiet comedy | romantic relationship | romantic relationship | unrelenting series\n",
      "Hypothetical maximum activation 21: tranquility friendship [0.6240178 0.9679501] \n",
      "\n",
      "Kernel 22:\n",
      "highly underrated | highly underrated | Highly recommended | Highly recommended | Highly recommended | Highly recommended | Highly recommended | Highly recommended | Highly recommended | Highly recommended\n",
      "Hypothetical maximum activation 22: Highly marvel [0.8886521 0.8831722] \n",
      "\n",
      "Kernel 23:\n",
      "loved it | loved it | loved it | loved it | loved it | loved it | loved it | loved it | loved it | loved it\n",
      "Hypothetical maximum activation 23: loved it [1.2175128  0.78080434] \n",
      "\n",
      "Kernel 24:\n",
      "atmosphere little | atmosphere second | atmosphere the | atmosphere the | atmosphere the | atmosphere of | atmosphere of | atmosphere of | atmosphere of | atmosphere of\n",
      "Hypothetical maximum activation 24: atmosphere gem [0.89403737 0.6218361 ] \n",
      "\n",
      "Kernel 25:\n",
      "nonexistent plot | nonsensical plot | No plot | ludicrous plot | no plot | no plot | no plot | no plot | no plot | no plot\n",
      "Hypothetical maximum activation 25: None plot [0.91543746 0.9115526 ] \n",
      "\n",
      "Kernel 26:\n",
      "into saved | is wasted | completely wasted | completely wasted | completely wasted | completely wasted | totally wasted | opportunity wasted | just wasted | just wasted\n",
      "Hypothetical maximum activation 26: unsuitable wasted [0.41427523 0.8673661 ] \n",
      "\n",
      "Kernel 27:\n",
      "just mess | just mess | just mess | just badly | sub par | sub par | sub par | sub par | sub par | sub par\n",
      "Hypothetical maximum activation 27: sub shambles [0.7222073 0.8799017] \n",
      "\n",
      "Kernel 28:\n",
      "flawless Cinematography | stunning cinematography | stunning film | breathtaking shots | magnificent film | dazzling visuals | stunning suspense | stunning She | beautiful cinematography | stunning widescreen\n",
      "Hypothetical maximum activation 28: breathtaking thickening [0.82254076 0.35344303] \n",
      "\n",
      "Kernel 29:\n",
      "worst flick | worst directed | worst directing | worst acting | worst acting | worst acting | worst acting | worst acting | worst acting | worst movie\n",
      "Hypothetical maximum activation 29: worst Designed [1.3719323 0.483525 ] \n",
      "\n",
      "Kernel 30:\n",
      "entire abysmal | this wretched | this wretched | this abomination | truly abysmal | truly wretched | was appalling | this appalling | is abysmal | was awful\n",
      "Hypothetical maximum activation 30: astounding abysmal [0.42597508 1.1205925 ] \n",
      "\n",
      "Kernel 31:\n",
      "ridiculous waste | redundant waste | utter waste | utter waste | complete waste | complete waste | complete waste | complete waste | complete waste | complete waste\n",
      "Hypothetical maximum activation 31: implausible waste [0.7398484 1.2413019] \n",
      "\n",
      "Kernel 32:\n",
      "complex stories | complex story | gripping tale | powerful story | intricate tale | complex prism | complex movie | complex script | layered story | riveting tale\n",
      "Hypothetical maximum activation 32: complex together [0.66597366 0.6062731 ] \n",
      "\n",
      "Kernel 33:\n",
      "very beautifully | was beautifully | was beautifully | plot beautifully | film beautifully | coincided nicely | story beautifully | often beautifully | works beautifully | movie beautifully\n",
      "Hypothetical maximum activation 33: must beautifully [0.5450721 1.355291 ] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel 34:\n",
      "favorite film | favorite film | favorite film | favorite film | lively film | lively film | lively film | intimate movie | rare film | powerful film\n",
      "Hypothetical maximum activation 34: favorites dvd [0.6831928 0.5950942] \n",
      "\n",
      "Kernel 35:\n",
      "ludicrous Under | minutes There | minutes of | minutes of | minutes of | minutes of | minutes of | minutes of | minutes of | minutes of\n",
      "Hypothetical maximum activation 35: minutes Shifting [0.8786278  0.45871338] \n",
      "\n",
      "Kernel 36:\n",
      "Oh dear | Oh dear | Oh dear | Oh forgot | Oh wait | Oh no | Oh no | Oh no | Oh no | Oh no\n",
      "Hypothetical maximum activation 36: Oh Unfortunately [1.2232612 1.0065993] \n",
      "\n",
      "Kernel 37:\n",
      "France through | American fire | American comedy | France herein | American high | American high | American Southwest | Italy Canada | French Throughout | Japan in\n",
      "Hypothetical maximum activation 37: France Irvine [0.79606336 0.46566987] \n",
      "\n",
      "Kernel 38:\n",
      "abysmal script | poor script | poor script | poor script | poor script | poor script | lousy script | awful script | awful script | awful screenplay\n",
      "Hypothetical maximum activation 38: abysmal Developed [0.85603905 0.658161  ] \n",
      "\n",
      "Kernel 39:\n",
      "really excellent | absolutely excellent | absolutely perfect | just excellent | really enjoyed | really enjoyed | really enjoyed | really enjoyed | really enjoyed | really enjoyed\n",
      "Hypothetical maximum activation 39: IS excellent [0.81529886 0.90050083] \n",
      "\n",
      "Kernel 40:\n",
      "movie ends | movie ends | movie ends | movie ends | movie ends | movie ends | movie ends | movie start | movie could | movie could\n",
      "Hypothetical maximum activation 40: movie ends [0.76194906 0.54970205] \n",
      "\n",
      "Kernel 41:\n",
      "best series | best Clear | best flicks | best DVD | best TV | best game | best movies | best movies | best movies | best movies\n",
      "Hypothetical maximum activation 41: best Shows [0.8357152 0.5164126] \n",
      "\n",
      "Kernel 42:\n",
      "incredibly dull | incredibly awful | incredibly disappointing | unbelievably boring | unbelievably terrible | unbelievably terrible | incredibly underwhelming | just dull | just dull | just dull\n",
      "Hypothetical maximum activation 42: unbelievably excruciating [0.70099056 0.9111488 ] \n",
      "\n",
      "Kernel 43:\n",
      "life They | life They | life They | life They | life They | thoughts He | lives had | lives And | lives Gideon | lives their\n",
      "Hypothetical maximum activation 43: lives Gatland [0.8002451  0.54013443] \n",
      "\n",
      "Kernel 44:\n",
      "most touching | very touching | very touching | very touching | very touching | incredibly touching | most perceptive | Very enjoyable | most haunting | Very good\n",
      "Hypothetical maximum activation 44: Very touching [0.7980056 0.8214665] \n",
      "\n",
      "Kernel 45:\n",
      "save this | save this | save this | save this | save this | save this | save this | saving this | skipping this | saved this\n",
      "Hypothetical maximum activation 45: save this [0.71757   0.5354195] \n",
      "\n",
      "Kernel 46:\n",
      "Don waste | Don waste | Don waste | Don waste | Don waste | Don waste | Don waste | Don waste | Don waste | Don waste\n",
      "Hypothetical maximum activation 46: Don commendable [0.9743862  0.82206863] \n",
      "\n",
      "Kernel 47:\n",
      "will also | will also | will also | will also | will also | will also | will also | will also | will definitely | will definitely\n",
      "Hypothetical maximum activation 47: will DVD [0.66398346 1.1047806 ] \n",
      "\n",
      "Kernel 48:\n",
      "It celebrates | It brings | It brings | It represents | It presents | It holds | It reminds | It reminds | It reminds | It reminds\n",
      "Hypothetical maximum activation 48: Its celebrates [0.6302167  0.86799926] \n",
      "\n",
      "Kernel 49:\n",
      "Why didn | Why didn | Why didn | Why didn | Why doesn | Why doesn | Why does | Why does | WHY didn | Why did\n",
      "Hypothetical maximum activation 49: Why Doesn [0.9924567  0.66978294] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_embeddings = model.layers[1].get_weights()[0]\n",
    "print(\"Word embeddings from the model:\", word_embeddings.shape)\n",
    "print(\"Kernels:\", model.layers[2].get_weights()[0].shape)\n",
    "for kernel_index in range(model.layers[2].get_weights()[0].shape[-1]):\n",
    "    kernel = model.layers[2].get_weights()[0][:,:,kernel_index]\n",
    "\n",
    "    # Hypothetical highest activations\n",
    "    activations = numpy.dot(kernel, word_embeddings.T) + model.layers[2].get_weights()[1][kernel_index] \n",
    "    best_word_indices = numpy.argmax(activations, axis=-1)\n",
    "    \n",
    "    # Highest activations seen in the validation data\n",
    "    max_time_steps = numpy.argmax(predictions[:,:,kernel_index], axis=-1)\n",
    "    max_activations = numpy.max(predictions[:,:,kernel_index], axis=-1)\n",
    "    best_sentences = numpy.argsort(-max_activations)\n",
    "    \n",
    "    best_ngrams = [input_data[best_sentences[nth]][max_time_steps[best_sentences[nth]]:max_time_steps[best_sentences[nth]]+window_size] for nth in range(10)]\n",
    "    best_ngrams = [' '.join([inversed_vocabulary[i] for i in best]) for best in best_ngrams]\n",
    "    best_ngrams = ' | '.join(best_ngrams)\n",
    " \n",
    "    print('Kernel %s:' % kernel_index)\n",
    "    print(best_ngrams)\n",
    "    print('Hypothetical maximum activation %s:' % kernel_index, ' '.join([inversed_vocabulary[wi] for wi in best_word_indices]), numpy.max(activations, axis=-1), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at some of the kernels, e.g. kernel 10:\n",
    "\n",
    "Worst script | incoherent script | worst acting | worst acting | worst acting | abysmal screenplay | worst written | poorly scripted | poorly filmed | poorly directed\n",
    "Hypothetical maximum activation 10: worst script [1.0209291 0.7113825]\n",
    "\n",
    "* The activating bigram seems to be a negative adjective and a movie related concept\n",
    "* The hypothetical maximum activation we can generate with the given vocabulary is \"worst script\", which is very close to the first actual hit, however, this is not always the case:\n",
    "\n",
    "Kernel 13:\n",
    "movie sorry | movie Sorry | movie Oh | movie Oh | movie Oh | movie oh | movie oh | movie fails | movie fails | movie fails\n",
    "\n",
    "Hypothetical maximum activation 13: porn oops [0.6134886 1.025104 ]\n",
    "\n",
    "Sometimes the kernels are uninterpretable or they make unrealistic assumptions about the the shape of the word embedding space.\n",
    "\n",
    "* Window size does not force the kernel to learn certain length n-grams (only sets an upper boundary):\n",
    "\n",
    "Kernel 19:\n",
    "Great soundtrack | Great film | Great film | great soundtrack | great soundtrack | Great movie | Great Movies | great film | great film | great film\n",
    "\n",
    "Hypothetical maximum activation 19: Great worksheets [1.0821922 0.6044347]\n",
    "\n",
    "If we look at the maximum activations for each slot in the above kernel, we notice that the first word has almost twice as high activation as the second one. This means that basically the first word has to be \"great\" and the second word can be almost anything, i.e. the kernel is only detecting unigrams.\n",
    "\n",
    "* Looking at the kernel activations does not tell us anything about the kernel importance or relatedness to a certain output (e.g. positive review). To analyze these aspects of the network we have to look into the dense layers following the convolutional layer. This, however, is not straightforward as both CNN kernel activation strengths and dense layer weights should be analyzed together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
